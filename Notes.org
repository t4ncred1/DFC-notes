#+TITLE: Digital Forensics and Cybercrime
#+OPTIONS: toc:t todo:nil date:nil \n:t H:5 tasks:done html-style:nil num:nil tags:t
#+EXPORT_FILE_NAME: index
#+LATEX_HEADER: \usepackage[margin=0.9in]{geometry} \usepackage{parskip}
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/dfc-notes.css" />
#+MACRO: under \underline{$1}
* NO Incontro con Luigi Perri (17/03/2021) :noexport:
** Prove tipiche e prove atipiche
 Prove tipiche: prove raccolte con i metodi usuali - intercettazioni (che non possono avvenire in luoghi di privata dimora, a meno che non si stia svolgendo l'attività criminale in quel momento) etc.
 Prove atipiche: può essere frutto di un mezzo di ricerca tipico con qualche funzionalità in più (vedi trojan), o addirittura essere completamente slegato dai mezzi di ricerca ordinari. Queste prove vanno sempre valutate nel caso concreto.
** Il captatore informatico (o trojan di stato)
"captatore informatico" è un termine coniato dalla corte di cassazione per identificare strumenti informatici identificativi.
Rappresentano una vera e propria panacea:
+ non mettono a rischio gli operatori, che non devono muoversi sotto copertura per piazzare cimici etc
+ riesce a coniugare in un unico strumento una molteplicità di strumenti investigativi:
  + intercettazione di audio
  + intercettazione video
  + spingere il dispositivo a comportamenti anomali
  + effettuare una perquisizione dei dati

*** Definizioni
cassazione a nazioni unite del 2016: "capta tutto il traffico dati, attiva il microfono *ovunque egli si trovi*, può attivare telecamera e altre cose, intercetta ciò che viene digitato sulla tastiera etc."
A questo potere bisogna oppore un contropotere (sotto forma di garanzie) per cui non ci sia un abuso di tale strumento

Per definizione, l'attività d'intercettazione ha come presupposto che essa sia fatta senza che la vittima ne sia a conoscenza.

Il pubblico ministero in Italia deve essere garantista: se trova elementi a discolpa dell'imputato, deve proteggerlo.

*** Problemi
- La pervasività dello strumento rende difficile una collocazione delle prove tra le prove tipiche.
  (vedi cassazione del 14 ottoble 2009)
- come sapere quando intercettare? dato che non possiamo intercettare in privata dimora, potremmo non beccare mai il crimine
  - nuova cassazione: si può basare l'inizio dell'intercettazione sulle abitudini della persona.

*** Requisiti di un captatore 
- L'attivazione di un microfono deve avvenire tramite un comando remoto, non solo con l'inserimento del captatore informatico.
- la registrazione audio può essere attivata solo da un operatore della polizia giudiziaria, con verbale
- L'attivazione del dispositivo è sempre ammessa in particolari delitti (solitamenti in casi con pene elevate)
- L'attivazione del dispositiva deve essere usata come extrema ratio.
- La trasmissione delle registrazioni deve essere effettuata solo verso i server della procura.
- Siano usati solo programmi informatici conformi a requisiti tecnici stabiliti con uno specifico decreto ministeriale (non ancora emanato sadly)
- In casi estremi, l'uso dello strumento può essere usato prima dell'ok del giudice
- Non possono essere in alcun modo rese pubbliche le intercettazioni a cui prendono parte elementi esterni all'indagine.

*** Limiti all'utilizzabilità
Sempre permesso per reati gravi contro la persona (tratta di esseri umani o riduzione in schiavitù) o reati con pena oltre i 5 anni di reclusione.
Permesso nei luoghi privati solo se si è sicuri si tratti dei luoghi in cui avviene il crimine

Nota che la prova informatica, per quanto possa sembrare la "prova regina", deve sempre essere sostenuta da altri metodi investigativi per non interpretare in modo sbagliato le prove.

*** Installazione
Dal punto di vista informatico, si è visto di tutto.
Dal punto di vista giuridico, il codice prevede le prestazioni obbligatorie: gli operatori di comunicazione devono permettere agli operatori giuridici di agevolare l'intercettazione (=> anche l'installazione).
Il decreto ministeriale ancora da definire dovrebbe specificare anche questo aspetto.

*** Il caso Exodus 
Spyware.
Raccoglie informazioni sulla scheda e, in un secondo momento, ottiene il controlo del dispositivo.
Il codice è stato sottratto e sono state realizzare delle app "clone".

Il garante si è spresso sulla preoccupazione riguardo i rischi di perdere il controllo di questi strumenti:
Invitava a valutare l'opportunità di includere nel decreto legislativo (sempre quello non ancora fatto) l'indicazione dei luoghi e del tempo della captazione.
Riguardo i requisiti tecnici il garante ha detto: va specificato i moduli del sistema di intercettazione, non bisognerebbe utilizzare software che abbassano il livello di sicurezza dei dispositivi (per evitare altri attacchi da terzi e per evitare che sia rilevata dall'utente la presenza del trojan), i canali di trasferimento dei dati dovrebbero essere il più sicuri possibile.
* DONE Cybercryme Landscape
:PROPERTIES:
:NOTER_DOCUMENT: slides/01.pdf
:NOTER_PAGE: 31
:END:
*Risks* are a statistical evaluation of the exposure to damage because of the presence of vulnerabilities and threats.
** Threat dimensions
:PROPERTIES:
:NOTER_PAGE: 3
:END:
Threats can be
- *Generic* or *Targeted*:
  + Generic threats are threats in which we incur for simply being connected to the internet.
  + Targeted threats are threats that exploit known informations about us.
- Financially or non *financially motivated*:
  + Financially motivated threats are easy to understand.
  + Non financially motivated threats can be difficult to understand
- *Internal* or *External*:
  + Internal threats are put up by some internal figure of the organization itself.
  + External threats are put up by external figures (like criminals and other organizations).

** Gartner quadrant of threats
:PROPERTIES:
:NOTER_PAGE: 4
:END:
A table showing some example of the threat categories listed above, with their relative possible financiary motivation level.
** Internal threats
:PROPERTIES:
:NOTER_PAGE: 5
:END:
Internal threats can be countered by contracts and _separation of duties_.
They can be of various kind:
- Malicious insiders (personal gain)
- Inside agents (other organizations)
- Emotional employees (revenge)
- Reckless employees (self conciousness)
- Third party users (other organization's users)
** How to manage a cyber attack
:PROPERTIES:
:NOTER_PAGE: 8
:END:
In cyberspace, private companies defend their own piece of infrastructure by themselves.
When we talk about public or semi-public agencies (see ENI, VODAFONE etc.), what should they do in case of a big scale cyber-attack? Is the jurisdiction of the attack on them or on the nation?

The NATO wrote an entire manual (the Tallin Manual) on the policy they think applies to confilcts in cyberspace.
** Financially oriented attacks
:PROPERTIES:
:NOTER_PAGE: 9
:END:
The monetization of the attacks can be either direct or indirect.
- Direct monetization: credit card / bank account fraud; ransomware; fake AVs.
- Indirect monetization: information gathering; abuse computing resources for other attacks; rent or sell botnets.

The discriminant between the two is whether the money comes directly from the victim or from the use of their computer.
** Cybercrime
:PROPERTIES:
:NOTER_PAGE: 24
:END:
Cybercrime has its own ecosystem, whit producers, enablers (that don't produce the exploits but keep them relevant) and clients
*** Identity theft
:PROPERTIES:
:NOTER_PAGE: 22
:END:
Identities are stolen because they can be abused.
American SSN is sometimes abused for authentication purposes.
*** DONE Selling kits
Various kinds of kits are sold in the cybercrime ecosystem:
Botnets, exploitation kits, viruses..

These are then used for other kinds of crimes.

Also, the selling of stolen VISA accounts is common for money laundering and scamming (e.g: the scam of buying plane tickets and sell them to poor people before the real owner of the card blocks the payment).
* DONE Abuses of cryptocurrency and forensics
:PROPERTIES:
:NOTER_DOCUMENT: slides/02. Abuses of cryptocurrency and forensics.pdf
:NOTER_PAGE: 39
:END:

** Some informations
:PROPERTIES:
:NOTER_PAGE: 4
:END:
*** Bitcoin wallet
- Manage and store keys of you bitcoin addresses
- Creates and signs transactions (receive/send BTC)
- Track the balance

*** Bitcoin address
:PROPERTIES:
:NOTER_PAGE: 5
:END:
String used to receive payments.
You usually want to use more addresses to make people unable to track your movements.

*** Bitcoin mining
:PROPERTIES:
:NOTER_PAGE: 9
:END:
"Miners" compete to solve a complex problem by bruteforce: find the next block of transactions with as much leading zeroes as possible.
The one that resolves it first gets a reward (constantly decreasing).

*** Forks
:PROPERTIES:
:NOTER_PAGE: 12
:END:
When two miners find the same solution at approximately the same time, each block becomes the new head of the blockchain for a network: the blockchain splits.
That's what is called a fork.
When other 6/7 blocks are found, we see which chain they continue and we consider that the "real" chain.

** Pseudo Anonimity
:PROPERTIES:
:NOTER_PAGE: 19
:END:
An identity can have an arbitrary number of addresses, which can be used to split a transaction into multiple ones and make the derivation of the real owner difficult.

But all the transaction data is available, so if you take enough care you can track the flow of a transaction and infer some things:
- most of the times, all the inputs of a transaction are the same user.
- New addresses are usually shadow addresses, made explicitly to cover the traces.

*** How to protect Pseudo Anonimity
The "flow tracking" described above is made difficult by malicious sites by mixing together multiple transactions from different clients. (See Silk Road, as an example).
* DONE Introduction to Digital Forensics
:PROPERTIES:
:NOTER_DOCUMENT: slides/05. Introduction to Digital Forensics.pdf
:NOTER_PAGE: 8
:END:
Forensics: the application of scientific analysis methods to reconstruct evidence.

Digital Forensics: the application of scientific analysis methods to computer systems/digital data/networks to reconstruct evidence.

** Witnesses vs experts
*Witnesses* testify about _what they personally know_. They cannot testify about something they heard from others.
*Experts* can _testify with their scientifical analysis_ even if they where not present.

Experts are witnesses with knowledge, skill, experience or education that can form an opinion.

** Daubert Standard (How to be an Expert Witness)
:PROPERTIES:
:NOTER_PAGE: 3
:END:
The *Daubert Standard* is a _rule of evidence_ regarding the _admissibility of expert witness_ testimonies in the U.S.

In the states where the standard is applied, an expert must:
- have its specialized knowledge be helpful to the trier to understand the evidence
- have his/her testimony rely on sufficient facts/data
- have his/her testimony be *scientifically valid*:
  + Must be the product of reliable principles and methods
  + Such principles and methods must have been reliably applied

*** Scientific Method
:PROPERTIES:
:NOTER_PAGE: 5
:END:
For a method to be scientific, it must be:
- *Repeatable*
  If the experiment cannot be repeated (e.g: blood drop analysis) it must be detailed enough to be understood fully.
- *Falsifiable*
  If the experiment cannot be confuted, it is not scientific (e.g: statistics cannot be considered scientific)

*** Scientific Test for Daubert
:PROPERTIES:
:NOTER_PAGE: 6
:END:
Factors to consider (not all of these must be simultaneously valid for the method to be considered scientific):
- Wheter the theory or the technique is accepted in the scientific community.
- Wheter it has been subjected to peer review.
- Wheter it has been tested (or can be).
- Wheter the rate of error is acceptable.
- Wheter the research was independent of the litigation[fn:4].

*** Four phases of investigation
:PROPERTIES:
:NOTER_PAGE: 8
:END:

The four phases of an investigation are:
1. The *acquisition* of the sources
2. The *identification* of the evidences
3. The *evaluation* of the evidences
4. The *presentation* of the evidences

* DONE Acquisition
:PROPERTIES:
:NOTER_DOCUMENT: slides/06. Acquisition.pdf
:NOTER_PAGE: 17
:END:
** Acquisition in Italy
:PROPERTIES:
:NOTER_PAGE: 2
:END:
In Italy, it is not requested to provide a report on how the acquisition was made, so the methods now presented will be overkill.

** Brittleness of digital evidence
All digital evidence, if modified, is not *tamper evident*, which means it can be modified without the modification being noticeable afterwards.
There are, though, some procedure to ensure that digital evidence becomes tamper evident.
*** Hashes
:PROPERTIES:
:NOTER_PAGE: 4
:END:
In court it is asked to prove that evidence hasn't been modified, and hashes allow you to validate that.
Its *absence does not mean that the has been modified*.

Remember that we create the hash so that we can create a record of how the evidence looks to be used later. This means that it *must be preserved in another location than the evidence* to ensure it has not been tampered with.

They are not a dogma, and their absence won't be a huge obstacle for the "jury" to surpass.
But they are useful to debunk any accusation of counterfation.

** Typical hw/sw for acquisition
- Hardware:
  + Write blocker
  + external disks (simple copy through a live usb)
  + removable HD enclosures
- Operating system:
  + Live linux distribution image

** Bitstream images
:PROPERTIES:
:NOTER_PAGE: 6
:END:
Usually, by "copying and pasting" we lose some important informations.

We can, instead, make a "bit by bit" clone _of the original media_.

Of this image I want to make a hash, to ensure it's not tampered.

** Acquisition procedure
:PROPERTIES:
:NOTER_PAGE: 7
:END:

- If possible, *disconnect the media*
  + Connect it to an analysis station, with a *write blocker* possibly (not a necessity, you can just confugure correctly your software).
  + compute the hash of the source
  + make a clone of the source and check its hash
- When media _disconnection is not possible_ (soldered memory / raid devices / other constraints)
  + *live boot the system* with a linux distribution (possibly one targeted to forensic analysis)
    - only available if the target is off, though.
      When turning off the target, _pull the plug_. Don't let it have a system shutdown.
  + if the _target is powered on and cannot be turned off_, make sure first to take all the data available in the system, and *work in volatility order*:
    - *disconnect the machine from the network*, if the network is not necessary.
      Done to avoid additional modifications.
    - dump the memory (In linux, there are /dev/mem and /dev/kmem that you may use to acquire the memory of the machine while on).
    - save runtime informations (network, processes etc)
    - make the disk acquisition
- When we think we caught the intruder, we might want to make the analysis "live":
  + check the logs (only usable if they are on a different machine than the one attacked)
  + check the network traffic (now or never)

The noerror and sync options of dd are used to not make dd stop in case of errors in the device.

The recomputation of the hash of the source and the acquisition image is made to ensure they are the same and that the source has not been modified (by comparing it with the first hash made of the device).

We often use *multiple hashing algorithms* to compute the hash for the same image.
The reason is that someone else who has analized before (or will analyze) the drive might have used a different hashing algorithm.

*** The time problem
Computing the copy of a 1TB hdd/usb key might take some time depending on the interface used by the hdd itself or by the write blocker.
It might take several ours to compute an hash and make a copy of the source.

To avoid the time waste, some softwares may automate part of the procedure by computing the source hash while copyng.

*** The size problem
In large scale investigations (or when multiple investigations are held in parallel), the sizes of the drives might make storing their clones and transfering them a real burden.
Using external media devices is a no-go, since it slows down operations by a lot if you don't use the correct interfaces (USB).

NASs and SANs are used all the times for this specific reason.

*** The encryption problem
In Italy, it might not be required for the persecuted to provide the passcode to decrypt the evidence for the analysis, since it can be seen as *testifying against oneself*.

** Forensics Duplicators
:PROPERTIES:
:NOTER_PAGE: 12
:END:
These perform the hashes and copy the hard drive into one of the others, printing a receipt with all the informations of the process.

* DONE Identification
:PROPERTIES:
:NOTER_DOCUMENT: slides/07. Identification.pdf
:NOTER_PAGE: 22
:END:

** Setup
:PROPERTIES:
:NOTER_PAGE: 2
:END:
The easyest operating system to work on when making forensic analisys is Linux, since it has/can:
- extensive native file system support
- native support for swapping drives
- mounting of disk images as drives

On a linux guest we might keep some windows vms to use soe additional tools.

*** Why not windows
:PROPERTIES:
:NOTER_PAGE: 3
:END:

Windows tampers with drives and *modifies evidence*.
It doesn't support many file systems.

Remember: Some tools are windows only, and as such you cannot use linux for your entire job.
When using these tools inside a vm, be sure that the disk drive is not writable (this is a last resort, you should first try to work on a copy or on a write blocked drive).

Be wary of proprietary and non free software.

*** Repeatibility
:PROPERTIES:
:NOTER_PAGE: 4
:END:

Since any other expert must be able to perform the same experiment, you should *avoid proprietary/paid forensic solutions*.

Moreover, if a machine is subject to a job without fully understanding (or having access to) how the job innerly works, you cannot say that its output represents truly repeatable evidence, since the expert should be (in theory) able to *perform the same analysis by hand*.

**** Law enforcement tools
:PROPERTIES:
:NOTER_PAGE: 4
:END:
Adversarial Investigation tools that *must be left hidden* to the public in order to avoid other people (e.g. criminals) finding ways to circumvent them.

They are /not really fit/ for the job, since to make an analysis scientific the tool shall be used and undestood by other experts.

*** What analysis encompasses
:PROPERTIES:
:NOTER_PAGE: 5
:END:
We will focus on tasks that only happen in forensics, but be careful: forensic analysis encompasses everything you have studied.

** Data Recovery
:PROPERTIES:
:NOTER_PAGE: 6
:END:
One of the most typical tasks of computer forensics

*** Disk Geometry
:PROPERTIES:
:NOTER_PAGE: 10
:END:
The data is read from the tracks on the platters.
The minimum part of the track that can be read is a *Sector*.
The minimum block that can be allocated for a file is a *Cluster*.
A cilinder is the set of tracks that are on the same position (on different platters) on the drive.

When a file is not exactly a multiple of clusters, the operating systems allocates the clusters anyway.

The area that is left between the file end and the end of the last cluster is called "slack space".
This chunk of data contains the *remains of previously deleted stuff*.

If this data is text or otherwise an easily recognizable file format, you can reconstruct (at least a minimal part of) a file.
Zip files, most of images and audio etc. are probably not reconstructable this way, since they rely on headers and other file sections.

But we could check if a file we are seeking for matches with the part in the slack space, to have a partial confirmation.

*** Retrieve data from the File System
:PROPERTIES:
:NOTER_PAGE: 8
:END:

The file system is the equivalent of the index of a series of folders and files.
In each *inode* you have a table of (direct | indirect) pointers to the data blocks that compose the file.

On file deletion, the file system entry is marked as free.
After some time, the file system entry (not the data itself) is freed and, after some more time, the data block might be overwritten.

If we want to access the deleted files, we either:
- *if the file entry was not deleted*: un-mark the file entry in the inode for deletion
- *if the file entry deletion has already taken place*: ignore the inode and look for the block.

*** Carving
:PROPERTIES:
:NOTER_PAGE: 12
:END:
Another method to retrieve data is the carving method, which consists in:
1. Scan the drive as a single bit stream
2. *locate MIME types* of interesting file types
3. consider anything in between as a candidate file.

As the steps above show, carving *doesn't use informations from the file system*.

The problem comes when encryption and/or compression are taken into consideration, where file types cannot be recognized anymore.

*** Free-as-in-beer software tools for data recovery :noexport:
:PROPERTIES:
:NOTER_PAGE: 13
:END:
Sleuthkit is the core (with a cli), Autopsy is the gui.
Autopsy will be used also in [[*Tool analysis: Autopsy][mobile forensics]] to inspect mobile phone images.

** Antiforensic Techniques
:PROPERTIES:
:NOTER_PAGE: 14
:END:
Aimed at circumventing the forensic analyst.
They are called transient when they just deviate the analysis, definitive when they destroy/tamper the evidence.

The *most vunerable phases* are aquisition and identification.

*Transient antiforensics* techniques interfere mostly with identification, but can be detected and reverted/stopped from happening (most of the times).
*Definitive antiforensics* techniques can sometimes be detected, too, but cannot be reverted.
*** Timeline tampering
:PROPERTIES:
:NOTER_PAGE: 17
:END:
A technique that consists in modifying the timestamp of files on the disk to make them appear not correlated one another.
It's a *definitive antiforensics* technique, since the old timestamp is not available anymore.

*** Countering file recovery
:PROPERTIES:
:NOTER_PAGE: 18
:END:
File recovery uses data remnants on the disk, so:
- secure deletion of files
- encryption
- virtual machines
Are all available methods to avoid data to be recovered.
It is a *definitive antiforensics* technique since it destroys (or negates the creation of) the evidence.

The "residual of magnetization" is a file recovery method studied during the 90es.
A 0 written where there was a 0 has a magnetization level slightly different than a 0 written where there was written a 1.
This was never shown to be practical, but it was a reasonable assumption with the technology from the 90es; Nowadays (due to the high density of the bits) it is unusable.

*** Fileless attacks
:PROPERTIES:
:NOTER_PAGE: 19
:END:
No traces are left on the disk at all.
Metasploit has this feature: it injects in memory a DLL.
Thus all traces are lost after the machine is turned off (and turning off is one of the main steps to analyze data.)

*** Filesystem insertion and subversion technologies
:PROPERTIES:
:NOTER_PAGE: 20
:END:
We place the data _where there's no reason to look for it_.
The partition table, for example, has 32KB assigned but, in real use, it occupies 1KB at most.

- Inodes for bad blocks are created by the system to not use them.
  If we manage to pass a good block as a bad one, we get some free real estate.
- You can use directory inodes to, instead, point to data blocks
- We can put data in metadata structures ignored by forensic tools (this method is weak to carving)

It is a *transient antiforensic* technique, since the evidence is hidden and not destroyed.

*** Log tampering
:PROPERTIES:
:NOTER_PAGE: 21
:END:
If an attacker has access to the log files, it can tamper them to insert fake log entries or malicious code (this last option is only useful if they are automatically analyzed).

It is a *transient antiforensics* technique, since the real evidence has not been modified.

*** Patition table tampering
:PROPERTIES:
:NOTER_PAGE: 22
:END:
- If a partition is not correctly aligned, the OS (Windows) might still use it, while forensic tools might miss them.
- Normally, there is only one extendend partition per disk. Windows and Linux can manage multiple extended partitions, but forensic analysis tools might not support them.
- A high number of logical partitions in an extended one might bring the tool to crash.
  The case was with NCase, 15 years ago. It supported at most 26 partitions (one for each letter of the alphabet).

This, too, is a *transient antiforensics* technique, since the data that composes the evidence is not altered.

* DONE SSD forensics
:PROPERTIES:
:NOTER_DOCUMENT: slides/08. SSD-forensics.pdf
:NOTER_PAGE: 46
:END:
SSDs are based on NAND based flash memory, widely used in mobile devices.
** FTL
:PROPERTIES:
:NOTER_PAGE: 5
:END:
In order to write on nand, you need to blank the block completely.
FTL (flash translation layer) chips are devices used to optimize the access to the SSD
Functionalities:
- Caching
  Avoid blanking a block with one single bit flipped
- Trimming
  When the drive is idle, start trimming (clearing) blocks. It depends on the operating system to tell which blocks to trim.
- Garbage Collection
  An advanced form of trimming not dependent on the OS
- Data compression
  Avoid writing multiple blocks when possible
- Bad block handling
  When a cell is about to fail, the ssd should stop using it
- Wear leveling
  When we have a cell that has been written many times, we try to move on it static data.

Since the FTL decides how to compress and obfuscate data and shuffles it (for wear leveling, even when the OS isn't running), it is the only one with the knowledge of the mapping between the logical structure of the data seen by the OS and the physical layout.

The FTL cannot be disabled via software. You can read the chips with external tools (extremely difficult), risking the destruction of the drive.

The FTL, moreover, is not standard: It is the main difference between different vendors (chips are usually the same) and, as such, they are intellectual property that they try to protect.

** Tests
A set of tests was developed to assess the impacts of FTL on the use of black-box tools.
*** Trimming
:PROPERTIES:
:NOTER_PAGE: 20
:END:
Trim activates after a second of the drive being IDLE, and it is very aggressive.
After ten second from the erase of the drive, it will be completely empties (looking through the FTL).

*** Garbage Collection
:PROPERTIES:
:NOTER_PAGE: 23
:END:
We didn't find Garbage collection of the drives.

*** Erasing patterns
:PROPERTIES:
:NOTER_PAGE: 26
:END:
Certain SSD controllers exhibit unexpected trimming patterns.

*** Compression
:PROPERTIES:
:NOTER_PAGE: 29
:END:
Files with High entropy (that cannot be compressed) will take more time to be written

*** Wear Leveling
:PROPERTIES:
:NOTER_PAGE: 32
:END:
We thought that wear leveling, since it would make shadow copies of the files, could help the forensic analysis. It does not.

*** Reults on file recoverability
:PROPERTIES:
:NOTER_PAGE: 35
:END:
Very detrimental. If TRIM is active, it's quite difficult to recover any file.

** Conclusions
:PROPERTIES:
:NOTER_PAGE: 40
:END:
For forensics analysts, SSD are a pain in the arse.
We can say that SSDs have an "intrinsic" secure deletion system.
* DONE Evaluation and presentation
:PROPERTIES:
:NOTER_DOCUMENT: slides/09. Evaluation and presentation.pdf
:NOTER_PAGE: 18
:END:
These phases are tightly coupled with experience and are difficult to teach generally.

** Evaluation phase
:PROPERTIES:
:NOTER_PAGE: 2
:END:
Consists in *matching the evidence elements with the required legal elements to support/negate a legal theory*.

The experts and the lawyer sit down and share their expertise, trying to match the requirements to negate or confirm an allegation.

The judge will analyze what can be said now, what cannot be said and what are the other possible experiments to find something new.
But sometimes, showing a feasible experiment to the jury can be detrimental to our own cause; There is a *risk* associated with each experiment we make.

Very often, expert witnesses work on the results of other experts (not on the evidence itself).

*** The relationship with lawyers, customers and prosecutor/police
:PROPERTIES:
:NOTER_PAGE: 4
:END:
The important thing to remember is that: "unless you are a police officer, you are not a policeman". It's *not your duty to punish* someone.
Unless you are a lawyer, it's *not your duty to protect* people either (even though lawyers and customers pay your bills).
You may be asked by the lawyer to omit a finding though (as long as it's not the same as lying).

You should never compromise the trust of the customer in their lawyer.

The process truth is not the same as historical truth: The law may not support incriminating someone that may be guilty historically.

It is super important to stick to facts and science, we're *not fighting for justice*, and your thoughts must not be shaped by it.

In Italy, a super-partes kind of experts are available: the judge experts, requested by the judge to review the evidence.

*** Analyzing the documents
:PROPERTIES:
:NOTER_PAGE: 7
:END:
You always need to analyze what can be said and /what can not/, possibly specifying *what further experiments would be needed* to say more.

This last analysis must be perfomed to be prepared on what experiments the counterpart will perform and what will be the repercussions if out part asks to make such experiments.

It's also very important to *review previous documents and evidences*, to look for technical/factual errors, suggestive writing and opinions treated as facts.

** Presentation phase
During the presentatiion phase, all experts must testify with objective facts (without interpretation or twisting) but they are not required to be completely non-sided to the matter (so they might want to avoid certain tests etc.)
But be wary, since omission of truth is persecutable in Italy *experts cannot*, when asked, *claim professional secrecy*.

After each analysis, the expert is asked a series of question called "quesito peritale". One of the question is "riferisca quant'altro può essere utile ai fini di giustizia".
This implies that, should you find another crime evidence during your analysis, you are forced to say so.

*** Typical errors found in reports and analyses and presentation errors
:PROPERTIES:
:NOTER_PAGE: 8
:END:
If the theory is that "a supernatural/incredibly powerful being did something" and that cannot be confuted, it is a "trojan defense".
(You can never exclude a trojan virus that deletes itself put the files on my computer, but it is not *falsifiable* so not *scientific*)
We can provide additional explanations and alternative theories to these.

Many court cases drag over a long time, so having a good written report (presentation) can be lifesaving to gather back the informations.
The report you signed is the only thing you can bring with you in a court.

**** What to look for
- *Acquisition errors*
  + missing links in the chain of custody
  + missing/mismatched serial numbers
  + errors during hashing/cloning procedures (missing write lockers)
- *Analysis errors*
  + steps where the hash is not verified
  + use of proprietary programs
  + technical mistakes.
- *Presentation errors*
  + the presentation is biased
  + counter examples for an assumption can be found
  + alternative theories not explored

In Italy it is _not enough to demonstrate that an analysis was not conducted under complete observance of the chain of custody_, but if you can raise questions and _show that other results are feasible_ with the same set of informations and another analysis method, you can bring the jury to your side.
That's why, during the presentation phase, you must be meticolous and list all possible counter examples.

On the other side, if you cannot dispute the facts that the opposition is saying about your client, you can dispute their presentation.

*** What to do when your client is in the wrong
You can avoid to present the informations about your client that aren't on your favor.
But if the prosecutor asks, you must respond (unless you "didn't touch" the topic in your analysis)

*** Writing your report
:PROPERTIES:
:NOTER_PAGE: 10
:END:
You want to explain the situation in a simple way, but not a simplistic way.
The judge won't like to be treated like a child, but he will want to understand everything (so all the technical terminology will have to be explained).
You will also have to explain why certain things are relevant.

*** Structure of a report
:PROPERTIES:
:NOTER_PAGE: 11
:END:
Always explain the reasons behind an analysis and its results.

Try to write "obstacles" in the way to get your client sentenced:
- "the opposition did this"
- "By doing this, they actually ruled out this"
- "Even ignoring this, the evidence could be explained better with this"

Always write in the introduction what is your very conclusion.

The conclusion is, most of the times, the only things the judge considers.
Give a fast write up of what was written in the report, then use a strong ending phrase.
*Stay factual*.

** Testimony as a witness
:PROPERTIES:
:NOTER_PAGE: 16
:END:
In many jurisdiction, the expert may be called as a witness or may only just have to submit a report.
In Italy, if you are working in a criminal procedure, you must be called as a witness.

In Italy, you are asked to know you duty as a witness: answer truthfully and not hide anything you know.

** Direct and cross examination
:PROPERTIES:
:NOTER_PAGE: 17
:END:
- *Direct examination*
  you are /first/ called by your side and proceed to a friendly direct examination.
  In this examination you must:
  + be as helpful as possible
  + be as clear as possible (make sure you explain everything to the judge)
  + check previous records of the jusdge to prepare for possible questions

- *Cross examination*
  you are called by the opposing side to testify. This is usually much more difficult than its direct counterpart.
  In this examination you want to:
  + be court if you can, and if you can not be very complex and difficult to understand (you can take you time talking by looking at your report)
  + If a question is positive for your side, be extremely clear and helpful
  + Don't get personal on the things they say and don't get angry

In civil court, witnesses are expected to provide answers to questions that were listed to the judge, in the form of "is it true that..".

* DONE Fraud analysis and detection :Carminati:

What is a *fraud*? It's a wrongful or criminal deception intended for financial or personal gain.
In particular, it is:

- *uncommon*
  Only a minority of cases concerns fraud, which makes it difficult to detect them and to learn from historical cases.
- *well considered and imperceptibly concealed*
  Fraudsters remain unnoticed and covered by planning ahead their actions.
- *time evolving*
  fraud techniques evolve in time, ahead of fraud detection systems.
- *carefully organized*
  Fraudsters do not operate independently, they involve complex and organized structures.

** Why people commit fraud
The main reason is the _potential monetary gain_.
But we have an abstact model that tries to explain the drivers of a fraud, the *fraud triangle*, composed of:
- motivation
- opportunity
- rationalization

** Fraud categories

- Banking and credit card frauds
  Has two subtypes:
  + application fraud: obtain new credit cards from issuing companies by using false data and spend as much money as possible in a short time.
  + behvioral fraud: detail of legit cards are obtained fraudolently. Does not necessarily require stealing the physical card, but the credentials.
- Insurance fraud
  Can be either:
  + from the side of the seller, if we
    - sell policies for nonexistent companies
    - setting up multiple policies to create commissions
  + from the side of the buyer, if we
    - exaggerate claims
    - falsify medical history
    - fake death/kidnapping etc
    - fake damage to our vehichle
- Corruption
  Misuse of entrusted power for personal gain.
- Counterfition
  A counterfeit is an imitation intended to be passes off fraudulently or deceptively.
  It is usually done on valuable objects like money, credit cards, popular products etc.
- Product warranty fraud
  Fraudently claiming compensation or remuneration based on a product warranty.
- Healthcare fraud
  Filling dishonest healthcare claims to make profit.
- Telecommunication fraud
  Theft/use of communication services to commit other frauds.
  + cloning fraud: clone a number and the related call credit.
  + superimposition fraud: fraudolent usage is added to the legit use of an account.
- Money laundering
  Transform illegal money into legit funds.
- Click frauds
  Illegal clicks on a website advertisement to increase the payable number of clicks to the advertiser.
- Identity theft
  Obtain the financial/personal informations of another person for the purpose of assuming that person's identity to make purchases.
- Tax evasion
  Illegal act or practice of not paying (or paying partially) taxes that are owed.
- Plagiarism
  Use another's production without crediting the source
  It involves both stealing someone's work and lying about it afterwards.
- Sim swap attacks
  The attacker contacts your phone operator, asks for a new sim, get control of it, get access to your authentication method (if your phone is the secure point).
  The second factor authentication based on the sim introduced by banks caused this kind of frauds.

** Anti-fraud stategies

*** Anti fraud mechanisms
Reduce losses due to frauds:
- Prevents and detect part of the frauds.
- hinder fraudsters who will look for other easier opportunities. (go on other organizations)
*** Fraud detection and Fraud prevention
_Fraud detection_ mechanisms recognize fraudolent activities after they have happened (ex-post approach)
They usually provide the analyst with an index risk of fraud, depending on the past transaction (behavior) of the user

_Fraud prevention_ mechanisms avoid or reduce the frauds that will happen (ex-ante approach)

They are *complementary* and *not independent*: if a fraud adapts to a detection mechanism, it will also impact prevention mechanisms and vice-versa.

**** Example of fraud prevention: Strong customer authentication
Two authentication methods are required to make a payment in the European Economic Area.

But each security measure impacts the cost and usability of a system and, for this reason, in this case payments below 30 euros or low risk transactions in general are exempted.
*** Strategies for Fraud detection and prevention
**** Expert-based approach
This approach to fraud analysis is built on the domain knowledge of the fraud analyst.
It involves *manual investigation* of a suspicious case to understand the fraud mechanism.

It may find *new fraud mechanisms*.

They are usually implemented with if-then-else rules engine.
For example: If the amount of claim is above the threshold or if there is a severe accident but no police report etc, then flag it as suspicious.

***** Rule based engines
Rudimental (but quite functional) fraud detection systems, but expensive to build.

They *must be kept secret* from fraudsters, which can learn the rules and circumvent them.
Moreover, new /fraud patterns are not automatically signaled/: you must first make new rules for them.

**** Automated fraud detection systems
An automated system for detecting fraud requires less human involvement and could lead to a more efficient system, *based on data analysis*.
_Expert knowledge remains, in any case, crucial to build the system_.

***** Data driven fraud detection
Based on machine learning.
It is *precise*, due to the increased detection power w.r.t. classic approaches and the massive amount of informations available from previous frauds.
It is *efficient*, because it costs much less to automate the analysis than expert-based fraud detection systems.

*** Fraud management
When a fraud is detected, it must be
 - *corrected*, by providing a compensation for example. Note that you can be required to look at the past to be sure it didn't happen before.
 - *prevented* from happening again.

 A fraud becomes easier to detect the more time has passed, due to copycats using the same fraud over and over.

** Frauds as a dynamic phenomenon
Frauds remain hard and complex to detect.

A fraudster may think about sending fraudolent transactions that may try to *shift the model of fraud detection systems* of an institution.
Unsupervised learning technique must be still monitored by experts.
** Techniques to detect a fraud automatically
New techniques able to _adapt to new frauds_ are needed.
They can either be
- *Unsupervised learning* (or descriptive) analytics techniques
- *Supervised learning* (or predictive) analytics techniques

*** Unsupervised learning analytics techniques
They do *not require labeled observations*. They learn from past observations by *detecting anomalies*.
They can detect novel fraud patterns.

**** Telecommunication example
I can see a fraud is in act if I see /multiple short calls/, /during night hours/ and /with little time between one another/.
But note that there can be multiple false negatives.

**** Limitations
Unsupervised learning techniques are *prone to deception* by camouflage-like fraud strategies.
They need to be complemented by other tools.

*** Supervised learning techniques
Learn from *labeled* historical observations, where the fraud was exposed.
They can find known alarms that fraudsters cannot hide.

**** Limitations
- Low detection power against new fraud types
- Need a labeled set to learn from

** Developing a fraud detection system
1. Start with an Expert-based rule engine
2. use a unsupervised learning system
3. use a supervised learning system once you have build your labeled history
The exact order of adoption depends from case to case.

** Social Network Analysis
Extends the abilities of fraud detection systems by detecting _characteristics of frauds between linked entities_.

** Fraud management cycle
you have to put together the following steps:
1. fraud *detection* : applying detection models on new observations
2. fraud *investigation* : human expert investigates on a flagged fraud
3. fraud *confirmation* : determining the kind (label) of fraud
4. fraud *prevention* : preventing frauds to be committed in the future by marking them as frauds faster and faster.
5. Finally, you need to put an *automated detection algorithm* to create and update the detection model with the confirmed frauds.

*** Regular update of the model
The *frequency* of update of your model depends on:
- the _volatility_ of the fraud behavior
- the _detection power_ of the model
- amount of _similar confirmed case available_
- the _rate of new cases_ being confirmed
- the _required effort_ to retain the model

**** Reinforcement learning
Instead of waiting for a window to update the model, continuously update it as soon as new data is available.
*** Example: Credit card fraud
*Outlier detection* is made by analyzing clusters of common transaction based on position and time.
If a transaction happens outside of a group (it's an outlier), they might be a fraud.

Users are analyzed in the same way at a system level, based on their age and income.
An outlier might be a fraudster or a victim.

** Fraud analytical process
How to develop a *fraud analysis model*.

The process is split in three main parts:
- preprocessing (the most important and time consuming)
  The performance of your model will strictly depend on this step.
- analytics
- post processing

*** Preprocessing
- identify the business problem
- identify the data sources
- select the data
- clean the data (gets rid of inconsistencies)
- transform the data (extract additional informations from the data)

*** Analytics
- Analyze the data. Here the *model is built* based on the data preprocessed.

**** Possible analysis outputs
- Find known easy frauds, that ensure the system is working
- Find unknown patterns, that provide added insight and detection power.

In any case, you're going to work on *clusters*, and will be trying to extract knowledge from them.

*** Post processing phase
Validate the model created with experts.

*** Key characteristics of successful fraud analtics models
To understand if your system is working I must monitor:
- statistical accuracy and significance
  Your system must generalize well and _must not be overfitted to the historical data set_.
- Interpretability
  You can put in place the state of art deep learning approach, but if the result of the analysis cannot be interpreted because the model is too complex (it tells us that a particular case might be a fraud, but it won't say why) it is unuseful.
  Such a non interpretable system is called *black-box*, while a system that can be interpreted is a *white-box* system.
- Operational efficiency
  The time and effort that is required to obtain a result and evaluate it is important, expecially on /real time system/.
*** Fraud management as risk management
  Every time we have to deploy a fraud management system, we must consider
  - the value of the asset we want to protect
  - the vulnerabilities
  - the threats
  - the cost of the system (both direct and _indirect_)
    Indirect costs are mainly
    + less usability for the user
    + slower performance
    + less privacy
    + reduced productivity (users are slower)
    Direct costs are the equipment, its management and its operation.

**** Economical cost
Developing and implementing a fraud-detection model involves a significant cost to an organization.

A cost-benefit analysis to understand the returns on investment that you gain with a fraud detection system.

Moreover, now that the fraud-detection model should go under the _privacy regulations_, it's really difficult to put up a dataset big enough.

** Challenges of developing fraud-detection models
- Dynamic nature of frauds
  As previously seen, fraudsters will keep on trying to beat detection and prevention systems by developing new strategies and methods.
  We will need _adaptive_ models for detection and prevention.
- *Accuracy*
  You don't want to miss on too many frauds, but you want to keep a low false alarm rate.
  All in all, the cost of missing a fraudolent case will probably be higher than marking a legit one as fraudolent.
- *Skewness[fn:1]* of the data
  The number of fraudolent cases is small w.r.t. the number of legit ones.
  An analytical technique might have some difficulties in learning an accurate model.
- *Time efficiency*
  The model must be fast enough to reach a decision (fraudolent or not) in the time window before the next batch of transactions arrive.
- *Big data* management
  The model must be able to deal with massive amounts of data.

** Red flags of frauds
What we want to extract from an analysis are the " _patterns_ " for frauds, to be used as the grounding truth for new fraud detection systems.

This means translating the typical anomalies (called "red flags" here) of each kind of fraud into expert rules (after being documented) for rule based engines.

* DONE Machine Learning for Fraud Detection :Carminati:
:PROPERTIES:
:NOTER_DOCUMENT: slides/04. Machine Learning for Fraud Detection.pdf
:NOTER_PAGE: 137
:END:

In the previous section we focused on the fraud analisys and detection management part, where we studied how to counteract frauds.
Let's now focus on how we can apply machine learning techniques in automatic fraud detection. (the more analytical part).
** Notice
:PROPERTIES:
:NOTER_PAGE: 2
:END:
During the years, many techniques have been developed for fraud detection with ML from different disciplines.
The main focus won't be on the technicalities of these techniques but on the fraud detection perspective.
** Data preprocessing
:PROPERTIES:
:NOTER_PAGE: 3
:END:
This part is where the experts lose 70% of their time.

*** Real data problems
:PROPERTIES:
:NOTER_PAGE: 6
:END:
When you're working on the theory, the more data you have the better.
When we move to the real world though, this sentence is not so true anymore.

The main motivation relies on the phrase "garbage in, garbage out".
It means that, if you have _messy data in your inputs, your analysis will yeld a messy model_.

We need to *filter our data accordingly*. Even the slightest mistake can lead to invalid results.

*** Types of sources
:PROPERTIES:
:NOTER_PAGE: 7
:END:
To fulfill an analysis, you need to know what data sources to acquire from.

Data can be either *structured* (fits neatly in fixed fields) or *unstructured* (like data lakes).

The main objective is to *find correlations between data sources*.

**** Transactional Data
:PROPERTIES:
:NOTER_PAGE: 8
:END:
One kind of data source.
It's composed of structured informations capturing the characteristics of a transaction from a customer.

This kind of data is usually summarized to extract the *RFM value* (recency, frequency and monetary factors):
- the Recency factor focuses on the time passed from a transaction to the one before
- the Frequency factor focuses on the number of transactions made in the past
- the Monetary factorfocuses on the amount of each transaction.

These features can be used individually or jointly, and their interaction can be used to detect frauds.

*** Types of data elements
:PROPERTIES:
:NOTER_PAGE: 9
:END:
You can either have continuous data or categorical data:
- *Continuous* data
  data elements are defined on an _interval_ (limited or unlimited) (the amount of a transaction or its timestamp is an example)
- *Categorical* data
  + _Nominal_: data elements that are _limited on a set of values_ without ordering (iban; IP; motivation; region)
  + _Ordinal_: data elements _limited on a set_ _with an ordering_
  + _Binary_: data elements that _can only take two values_.

*** Sampling
:PROPERTIES:
:NOTER_PAGE: 10
:END:
Sampling consists in taking a subset of the dataset available to build our data model.
This step is needed because we need to *generalize* and *model the future*, and to do so we need to *focus more on newer data* (by taking more samples from newer time frames). A good sample must be _representative for the future_.

When selecting a sample, you have to select the optimal time window, with a tradeoff between quantity of data and how recent it is.

Your *average period* (the time window you selected) must also be as unbiased as possible, even if it's not straightforward.

**** Bias example
:PROPERTIES:
:NOTER_PAGE: 13
:END:
In holidays, users change their spending pattern.
Not only that, but also the types of goods bought are different.

Each single month might deviate from the average model.

To mitigate this issue, we can
- build different models /for each month/.
  This is a complex and demanding solution, that does not scale well, but you have an updated and precise model of the customer.
- Sample observations over a period covering a full business cycle and build a single model instead.

Sampling has a direct impact on the fraud detection power.

**** Stratified sampling
:PROPERTIES:
:NOTER_PAGE: 18
:END:
To make a /stratified sample/ means to *keep some properties* (found in the data) *valid* in the sample taken.

When doing sampling, you might want to extract samples taking into consideration:
- a target for an indicator (/bank example/: private customer or company have different variability in their destination ibans; we might want to keep this variability intact after our sampling; /general example/: keep the percentage of fraudolent and non fraudolent transactions the same)
- a variable for a predictor

*** Visual data exploration
:PROPERTIES:
:NOTER_PAGE: 19
:END:
First informal step after sampling.
You basically analyze the distribution of data visually (through charts) to find its properties.

*** Exploratory statistical Analysis
:PROPERTIES:
:NOTER_PAGE: 20
:END:
Some *statistical measurements* (average, standard deviation etc.) can be made on the data to extract some properties.

Some fitting of the distribution of the data can help to understand other characteristics about it.

*** Dealing with missing values
:PROPERTIES:
:NOTER_PAGE: 23
:END:
Missing values can either have been omitted (due to information being non applicable or undisclosed) or simply be missing due to an error.

When an observation with missing values is encountered you can:
- _Replace_ the missing value with a default one.
- _Delete_ it, if the number of missing values is too high.
- _Keep_ the missing values, since they might have a relation with frauds.
  + In this case, it should be tested wether the missing info is related to a variable (e.g: two factor authentication) or not.
    If it's not the case, another of the two methods can be applied.

*** Outliers
:PROPERTIES:
:NOTER_PAGE: 26
:END:
Outliers are extreme values that are dissimilar to the rest of the population.
Some of these values might be legitimate (or they might be the result of invalid observations).
The methods to find them will be described in more depth later on (see the sections on [[*Graphical outliers detection][Outliers detection]])

They can be either:
- _Univariate_, if they are outlying on one dimension.
  *Visual data exploration* is able to find out most of this kind of outliers, through different views (histograms, box plots).
  One additional method is looking at *Z-scores*, an index that measure how many standard deviations an observation lies away from the mean.

- _Multivariate_, if they are outlying on multiple dimensions.
  Other methods (namely fitting regression lines and mahalanobis distance) are used to find this kind of outlying values.

**** Outlier treatment
:PROPERTIES:
:NOTER_PAGE: 36
:END:
If an outlier is an invalid observation, you can treat it as a missing value.
For valid observation, you can impose a range of values that do not modify your mean too much and put the outlier at one of the extremes.

*** When invalid data is not outlying
:PROPERTIES:
:NOTER_PAGE: 37
:END:
Sometimes, invalid values are not outliers though.

For example: a customer with birth date 01/01/1980 and classified as a child is not an outlier (there might be many child customers and many customers born the same day), but it is clearly an invalid value.

To remove such inconsistencies, a set of checks is made to find wether your data is _coherent_ or not.

To impose these checks you need the help of experts.

*** Conclusion on outliers and invalid values
:PROPERTIES:
:NOTER_PAGE: 39
:END:
Every single time you have to treat outliers and invalid values you must be really cautious when using the previous techniques, since these methods will impact the performance of your system (by removing the outliers, for example, you could lose some frauds).

*** Standardization
:PROPERTIES:
:NOTER_PAGE: 40
:END:
Standardizatoin consists in *scaling variables to a similar range*. This step is _heavily affected by outliers_.
You must always use common standardization methods.

*** Categorization
:PROPERTIES:
:NOTER_PAGE: 41
:END:
To confront /[[*Types of data elements][categorical values]]/ , they must first be _transformed_ to reduce their number of categories.
For example, IBANs and IPs could be categorized by their frequency (this process would make them comparable).

*** Variable Selection
:PROPERTIES:
:NOTER_PAGE: 42
:END:
A dataset is composed by hundreds of features.
On a detection model, there are usually 10-15 of them.
Which features to select in a model is a challenging task by itself.

**** Filters
:PROPERTIES:
:NOTER_PAGE: 43
:END:
Filters are used to _understand the informations each variable gives to the model_.
They are standardized (pearson correlation, fisher score etc.), but they are not meant to be your only analysis step.

Their main limitation is that you usually work variable by variable, without considering possible correlations between them.

**** Wrapper
Instead of having to select my features at the beginning, I only give in input different set of features and see what the more promising sets are.

**** Principal Components Analysis
:PROPERTIES:
:NOTER_PAGE: 45
:END:
Try to reduce the number of variables by computing new variables, called *principal components*, that are _not correlated one another_ and are _linear correlations of the original variables_ .

This transformation is extremely helpful for your analysis because they keep the informations of the variables while reducing the number of features to analyze.
Moreover, even if they do not reduce the number of variables, they can bring out some more interesting features.

PCA can help to make variables more robust.
But the new variables made might be not as interpretable than the original ones.

*** Example :noexport:
:PROPERTIES:
:NOTER_PAGE: 51
:END:

**** Dataset analysis
:PROPERTIES:
:NOTER_PAGE: 52
:END:
Using Visual data exploration, we can see that
- the amount exchanged and number of transactions are aligned with eachother, meaning that the amount per transaction is somewhat constant.
- There's a gap between march and april
  Our dataset was, in fact, corrupted
The peak on july is due to company closing before vacation, and a lot of duplicates were present.

The amount distribution (next page) shows that the users are unbalanced: the majority of them transfer low amounts of money.

The hierachical clustering (next page) shows us that the majority of the users gets clustered together.

The transaction and fraud distributions (next page) can highlight that the second happen mostly at night. Why so? Because it's more difficult to contact the victims.

The transaction amount distribution between fraudolent and legit transactions is different, too.

** Descriptive analytics for fraud detection
:PROPERTIES:
:NOTER_PAGE: 58
:END:
*Unsupervised learning techniques* are used to _find anomalies_ deviating from the norm. The main challenge is defining the norm; To do so, we use *descriptive analytics*.
Two possibilities (with different levels of granularity):
- Behavior of the average customer (global perspective)
- average behavior of a given customer (local perspective)

The *supervised learning technique* (based on /predictive analytics/), on the other hand, assumes you have labels available and can only detect known fraud patterns.
Besides these limitations, they are usually useful to _understand the anomalies you found_ on unsupervised analyses.

*** Relevant environments for Unsupervised learning
:PROPERTIES:
:NOTER_PAGE: 59
:END:
The use of Unsupervised learning techniques is particularly useful:
- In case of organizations _starting_ to do fraud detection, with no data set available.
- When you have a dataset, but it is not labeled yet (the labeling process might take time).
- When fraud patterns change fast and are not reused commonly.

*** Defining the norm
:PROPERTIES:
:NOTER_PAGE: 60
:END:
/The norm/ *depends on the context* you are analyzing.
It is a boundary (a threshold) that, due to the nature of frauds (continuously changing), will have to adapt.
Moreover, the boundary is not a clear cut: some anomalies might be legit transaction, while some apparently normal transactions might be frauds.

Even if you obtain good results on the tests, you must be able to make your system evolve - and the norm will change with it.

*** Graphical outliers detection
:PROPERTIES:
:NOTER_PAGE: 61
:END:
Ideal tools to explore the data and get preliminary insights.

It has some disadvantages though:
- Unformal.
- Not easily automatable.
- Limited to few dimensions.

*** Statistical outliers detection
:PROPERTIES:
:NOTER_PAGE: 63
:END:
Some statistical methods are applied to detect frauds:
- *Z-score*
  Seen before when we talked about [[*Outliers][outliers]].
- *Break point analysis*
  Detects _intra-account_ (in the same account) frauds
- *Peer group analysis*
  Detects _inter account_ frauds
- *Association rule*
  Detects _single transaction_ frauds
  Belongs mainly to the data mining world.

These techniques are differentiated mainly by the granularity with wich you want to make the analysis.

**** Break point analysis
:PROPERTIES:
:NOTER_PAGE: 64
:END:
Detects sudden changes in the account behavior (called *Break point*).
The method is quite simple:
1. define a fixed time window
2. split the parts into "old" and "new"
3. compare them
   This comparation is usually made with /t-score/, a metric that measures how much (and how fast) a value changed in a time window.

**** Peer Group analysis
:PROPERTIES:
:NOTER_PAGE: 68
:END:
The main goal is to define the _peer group_ (group of *similarly behaving accounts*) of an account.

When the behavior of the target deviates from his peer group, an anomaly is detected.

It is _more computational intensive_ than break point analysis.

Peer group analysis *can help with new accounts*, by approximating their spending profile with their peer group.

The update of the patterns is usually done weekly or monthly, due to the fraudolent pattern changing in a couple of months.


***** Identifying, sizing and comparing a peer group
:PROPERTIES:
:NOTER_PAGE: 69
:END:
To identify a peer group we can use 2 methods:
- exploit business knowledge.
- Define a statistical metric to define the peers

How many peers should you consider?
- few peers: more scalable (the performance loss is quadratic to the number of peers), but sensitive to noise.
- many peers: less scalable, but less sensitive to noide (a group too broad can lead to insensitivity to the deviations).

How do you compare the behavior of the target w.r.t. the peers?
- statistical test
- distance metric

***** Example :noexport:
:PROPERTIES:
:NOTER_PAGE: 70
:END:
Each of the y corresponds to the amount spent by a user in an instance of time.

To understand if a particular expense is anomalous, we:
- identify the peers of the target (in this case graphically)
- compare the behavior of the target wrt its peer group

**** Break point analysis vs peer group analysis
:PROPERTIES:
:NOTER_PAGE: 73
:END:
The two are complementary: you must use both at different times.
E.g. for the holidays, break point analysis performs poorly: people spend more, resulting in an anomaly.
With Peer group analysis, instead, all peers will shift to higher amounts, not causing an anomaly.

Both these analyses, though, will _detect only local modifications_ (local to an account/peer group).

**** Association rule analysis
:PROPERTIES:
:NOTER_PAGE: 74
:END:
Detects frequent occurring *relationships between items*.
An association rule is an implication X \Rightarrow Y, where both X and Y are subsets of data from the same set with _no common elements_.
X is called /antecedent/ and Y is called /consequent/.

This kind of analysis was initially used for basket market[fn:2] analysis, to understand which items were bough together.
Supermarkets would decide which items to put near each other in an isle this way.

***** Support

The frequency of an item set is measured by means of its *support*, which is the percentage of total transaction in the database that contains the item set.
\begin{equation*}
support(x): \frac{\text{number of transactions that support } x}{\text{total number of transactions}}
\end{equation*}

Based on this function, we can identify the *frequent item set* , which will be then useful to derive the association rules.

***** Confidence
:PROPERTIES:
:NOTER_PAGE: 81
:END:
Measures the _strength of the association_.
It's defined as the probability of the rule consequent given the rule antecedent.
\begin{equation*}
confidence(x \Rightarrow y): \frac{support(x \cup y)}{support (x)}
\end{equation*}
*** Clustering
:PROPERTIES:
:NOTER_PAGE: 84
:END:
The goal of this analysis method is to *group the observations to find the norm*.
These groups should maximize the _homogeneity between elements in the same group_ and maximize the _etherogeneity between different groups_.

The general idea is that the norm will be characterized by big dense clusters, while anomalies will be small clusters far from the normal ones.

**** Kinds of clusters
:PROPERTIES:
:NOTER_PAGE: 87
:END:
Clusters can be either:
- Hierarchical
  + Agglomerative
  + Divisive
- Nonhierarchical
  + k-means
  + Self Organizing Maps

**** Measure the similarity of elements
:PROPERTIES:
:NOTER_PAGE: 88
:END:
To measure the similarity of elements *distance metrics* are used.
There are many of them and it should be used whichever suits the dataset best.

Euclidean distance is used commonly at the beginning for its simplicity.

**** Hierarchical clustering
:PROPERTIES:
:NOTER_PAGE: 94
:END:
In *divisive clustering* techniques, the dataset is initially considered as a _unique cluster_, to be divided later on.
In *agglomerative clustering* techniques, every element is considered as a _single point cluster_, to be aggregated with other clusters later on.

***** Distance between clusters
:PROPERTIES:
:NOTER_PAGE: 96
:END:
There are different ways to compute the *distance between clusters*, too.
- _single linkage_: select the nearest points of two clusters and compute the distance.
- _complete linkage_: select the farthest points of two clusters and compute the distance.
- _average linkage_: average the distance of all the points of the two clusters.
- _centroid linkage_: compute the distance of the centroid of the two clusters.
- _$d_{ward}$ distance_: compare the difference between the similarity of having the two clusters separated and having the two clusters joined.

Depending on this selection, all your results will be different.

***** Select the number of clusters
:PROPERTIES:
:NOTER_PAGE: 97
:END:
The selection of the number of clusters is *made through visualization*. Two techniques are used:
- _dendograms_: temporal timeline of the construction of your clusters. You can cut the tree at the similarity level you want to have to generate your clusters.
- _screen plot_: plot the distance at which clusters are merged and the number of clusters, then find the "elbow" of the curve: that point is where to stop.

***** Advantages and disadvantages
:PROPERTIES:
:NOTER_PAGE: 99
:END:
Advantages:
- the number of clusters does not need to be specified

Disadvantages:
- the interpretation of the clusters must be made with knowledge of the business logic.
- these techniques do not scale really well with large clusters.

**** Nonhierarchical clustering
:PROPERTIES:
:NOTER_PAGE: 106
:END:

***** k-means
:PROPERTIES:
:NOTER_PAGE: 107
:END:
Follow these steps:
- select k random observations ("seeds") as "centroids" of the clusters you are going to create
  + It is already evident a /problem/: how much is k? You have to choose it beforehand.
- assign each observation to the cluster with the closest centroid
- when all observations are assigned, recalculate the centroids of each cluster and repeat the assignment.
- repeat until the centroids are stable or a limit is reached.

This method is sensitive to outliers.

***** Self organizing maps
:PROPERTIES:
:NOTER_PAGE: 116
:END:
Feed forward neural network with two layers (input and output).
Allows to _visualize and cluster high dimensional nets on 2 layer neural networks_.

Each input is connected to every possible output.
When a training vector X is presented, it is compared to each neuron's training vector.
The most similar neuron is the Best Matching Unit; It and its "neighbors" are "adapted".
The neighbors are defined with a function ($h_{ci}$).

You're technically trying to update the network and aggregate the nearest points to the best matching unit.
As always, you continue until your BMU remains stable or for a fixed number of iteration.

They are quite helpful because:
- Once you have selected the output, they are basically automatic
- They allow you to represent the results you have obtained with two techniques:
  + Unified distance Matrix (also called U-Matrix)
    visualizes the distance between a neuron and its neighbors; Large distances (darker colors) can be interpreted a cluster boundaries.
  + Component plane
    visualizes the contribution of each input attribute to each neuron.

**** Semi-Supervised clustering
:PROPERTIES:
:NOTER_PAGE: 127
:END:
Incorporates background knowledge to guide the clustering, by putting some constraints on how the clusters are formed.
These can be put at different levels:
- observation-level constraints: put constraints between single entities (these entities must/mustn't link together)
- Cluster level constraints: impose a certain level of similarity between the clusters
- other constraints

**** One-class SVM
:PROPERTIES:
:NOTER_PAGE: 132
:END:
Try to maximize the distance between norm and anomalies: try to separate theme with a linear hyperplane (the anomalies are then the ones near the origin of your graph).

**** Evaluation of clustering solutions
:PROPERTIES:
:NOTER_PAGE: 134
:END:
There's _no universal criterion_ to evaluate which clustering is better, but a commonly used solution is the *sum of Squared Errors*.

Another one is to analyze them graphically and confront them.

Finally, another one is to train a supervised learning method on the basis of the results of the unsupervised learning one.
The unsupervised one will tell you the clustering, the supervised might lead you to the reasons behind those clusters.

** Predictive analytics for fraud detection
:PROPERTIES:
:NOTER_PAGE: 137
:END:
The aim of these analytics is to build a model to *predict a variable of interest* (it will be called _target variable_ from now on).
The real value that the target assumes from our prediction is then used to steer the learning process.

This target variable is usually a fraud indicator (so the resulting model is trained to recognize frauds); This means it is inherently hard to obtain and determine.

Two kinds of predictive analysis can be distinguished depending on the type of variable we want to predict:
- *Regression*: used for _continuous_ variables (with a possibly unlimited set of values).
- *Classification*: used for _categorical_ variables (but with a limited set of values).

*** Linear regression
One of the many kinds of regression.

The target variable is seen as a combination of *explanatory variables*, with a certain weigth $\beta_{i}$ assigned to each of them that measures the impact of the explanatory variable on the target variable.

These parameters $\beta_{i}$ must be estimated through the _minimization of squared error function_, a function that gives you an indication of how wrong your prediction was w.r.t. the actual value of the target variable.

It has some limitation though:
- The target variable is considered to be a continuous variable normally distributed, but it might not be (for example, it might be a boolean variable with a bernoully distribution)
- We might not have enough informations about the variable to move it to a continuous range (in the bernoulli case covered above, we could interpret it as a probability if we had enough informations about it).

*** Logistic regression
:PROPERTIES:
:NOTER_PAGE: 149
:END:
Another kind of regression.

A *logistic regression* is just the _combination of a linear regression and a bounding function_ (a function that limits the prediction values to a smaller interval).

The parameters of a logistic regression model are estimated using a maximum likelihood optimization.

With a logistic regression model we are able to predict boolean variables, such as a variable that represents the question "/is this observation fraudolent?/".

To decide wether a response is positive or not we use an *activation function*, that maps our obtained prediction (already bounded between 0 and 1 thanks to the bunding function) to a positive or a negative answer.

By training our model through logistic regression on a labeled set, we can find the combinatoin of variables that gives us a response to the question accurately enough.

*** Decision trees
:PROPERTIES:
:NOTER_PAGE: 156
:END:
A classification method of training.
We use a *tree like structure* to _label our observations_.
In the leaf nodes you have the assignment of labels (fraud/not fraud).
In each node you have a testing condition to move to lower nodes.

Decision trees are defined by three "decisions" (/sorry for the play on words/):
1. _splitting decision_ (which variable do we split? at which value?)
2. _stopping decision_ (when do we add a leaf node?)
3. _assignment decision_ (which label do you assign to the group in the current leaf?)

**** Splitting decision
First of all, we define *impurity* as the diversity on our dataset.
When our dataset is composed of half/half (of a specific condition), we have maximal impurity.
When out dataset is composed of only one kind, we have minimal impurity.

The variable to do the splitting decision on is chosen by looking at the _highest reduction of impurity_.

**** Stopping decision
:PROPERTIES:
:NOTER_PAGE: 161
:END:
If we split too much, we tend to _overfit_ (consider, other than the data we are interested in, also noise).

To avoid overfitting and find the best spot to stop splitting, our dataset should be divided in:
- training set (on which we make the splitting decisions)
- validation set (a labeled sample to monitor the misclassification error)
- testing set (a independent sample to test our decision tree)

You can then plot the misclassification error on the validation set wrt the number of tree nodes.
Once the misclassification error is at its minimum, we can then say to stop the creation of new nodes at that point and, instead, start the creation of leaves.

**** Advantages
:PROPERTIES:
:NOTER_PAGE: 166
:END:
Decision trees are useful because they are _easy to build_.
Moreover, they are a _white-box method_: you can convert a decision tree into a set of [[*Rule based engines][decision rules]] easily (the ones that fraud detection expert based systems use), since you have the conditions on each node.

**** Disadvantages
:PROPERTIES:
:NOTER_PAGE: 174
:END:
Decision trees tends to overfit the data, but we could use cross validation to reduce this.

*** Regression trees
:PROPERTIES:
:NOTER_PAGE: 169
:END:
You can also predict continuous targets with decision trees (for example, you can give the /probability/ of a transaction being a fraud) and transform them into a _regression method_.

*** Neural Networks
:PROPERTIES:
:NOTER_PAGE: 176
:END:
Generalization of existing statistical models.
The basic element of a Neural network is the *neuron*: it takes an input, multiplies it by a weight and puts it into a /transformation function/ (can be a logistic regression).

**** Layers
:PROPERTIES:
:NOTER_PAGE: 179
:END:
The neural networks presented during lesson are composed of 3 layers:
- _Input layer_
- _Hidden layer_, which combines the inputs into features.
- _Output layer_, which linearly transforms the features given by the hidden layer.

Usually, each layer has _its own transformation function_ (common to all the nodes in the layer).
Neural networks can be used both as a _regression analysis_ method and a _classification analysis_ method, depending on the transformation function used in the output layer.

**** Weigth learning
:PROPERTIES:
:NOTER_PAGE: 184
:END:
To optimize a neural network, we use an iterative algorithm that optimizes a *cost function* to find the best assignments to the weights of each neuron.

The cost function used might have _multiple minimas_, that could get you stuck on a result that is not optimal.
To avoid this, we usually do the optimization with _multiple initial random set of weigths_ and select only the one with the global minimum after some steps.

**** How many hidden neurons?
:PROPERTIES:
:NOTER_PAGE: 186
:END:
The number of hidden neurons to use depends on the non linearity of the dataset.
The more complex are the patterns we need to model, the more neurons we will need.

The procedure to select the number of neurons is basically the same seen to select the number of nodes in Decision trees (called, in that context, the [[*Stopping decision][stopping decision]]):
1. Split the data into _training_, _validation_ and _test_ set
2. train multiple neural networks on the training set with different numbers of neurons.
3. measure the performance of each network on the validation set.
4. choose the most performant neural network
5. measure its actual performance on the independent test set.

**** The overfitting problem
:PROPERTIES:
:NOTER_PAGE: 187
:END:
To avoid overfitting, we can use two techniques
- _Weigth regularization_: we put an upper bound on the weigths of the neural net.
- The usual method: we estimate the weigth and use independent data sets of the same pool to decide when to stop training to avoid overfitting.

**** Neural Networks lack interpretability
:PROPERTIES:
:NOTER_PAGE: 188
:END:
It is extremely difficult to find out why a certain output is given from certain inputs, which makes the _extraction of rules complex_.

They are, though, generally more performant than the other methods seen.

***** Variable selection in Neural Networks
:PROPERTIES:
:NOTER_PAGE: 189
:END:
To find out which variables contribute actively to the outputs of the neural network, we must visualize the interaction between the inputs (our variables, like "the age of the customer" and "the amount claimed by the insurance company") and the rest of the network.

To do so, we use _Hinton Diagrams_, where we visualize the weigths between inputs and hidden neurons as squares and interpret them.

Another way is _Backward variable selection_:
We build a neural network with all the variables in input, then we recreate the network with one variable less to see how much the performance is impacted (those variables that don't hinder the performance of the network can be removed, since they add complexity).

***** Extracting rules from Neural Networks
:PROPERTIES:
:NOTER_PAGE: 195
:END:
To extract the rules to be fed to a rule based engine, we can use two techniques:
- _Decompositional rule extraction_, where we find the activation values of the hidden neurons (with clustering, for example) and join them in a single boolean rule.
- Pedagogical rule extraction: use the labels produced by the Neural Network as the training set for a white box method (like decision trees), where the rules are simpler to extract.

**** Two stage model setup
:PROPERTIES:
:NOTER_PAGE: 200
:END:
Instead of directly using a Neural network, we can estimate a simpler model with a more interpretable method (like linear/logistic regression) and, then, use a neural network to predict the errors made by the model and adjust the parameters of the linear model.

*** Support Vector Machines
:PROPERTIES:
:NOTER_PAGE: 202
:END:
Based on linear programming[fn:3] (define an objective function and put some constraints on it).
It's a _classification method_, but it can also be applied as a regression method.

**** Benefits
:PROPERTIES:
:NOTER_PAGE: 205
:END:
In linear programming, it's _easy to introduce business knowledge_ (simply add constraints).
**** Problem
:PROPERTIES:
:NOTER_PAGE: 206
:END:
1. It can estimate _multiple optimal decision boundaries_ for a linear separable case.
   We can avoid this problem by selecting the boundary that is maximally distant from the two classes.

2. The system might be *non-separable* (we might not be able to find a linear boundary between two classes).
   In this case, we can introduce a _misclassification error_, which allows for wrong classification labels to happen.

**** Rule extraction and Variable selection
:PROPERTIES:
:NOTER_PAGE: 215
:END:
To extract variables and rules from SVMs, we can use the same approaches seen for Neural Networks:
- for _variable selection_ , the [[*Variable selection in Neural Networks][backward variable selection]] procedure can be used to reduce the input variables.
- for _rule extraction_ , the SVM can be interpreted as a neural network and the [[*Extracting rules from Neural Networks][same methods]] can be applied.

*** Ensemble methods
:PROPERTIES:
:NOTER_PAGE: 219
:END:
Ensembe methods aim at estimating *multiple analytical models* instead of only one; The models created can then be used to cover different parts of the data input.

**** Bagging
:PROPERTIES:
:NOTER_PAGE: 220
:END:
The Baggin method is an ensemble method. It consists of two steps:
1. Take N samples from your dataset.
2. Build a model (also called _classifier_ ) for each of these samples.

A _classification_ model is then built by letting the classifiers "vote" on the label to give.
A _regression_ model is built by averaging the outcome of the N models.

**** Boosting
:PROPERTIES:
:NOTER_PAGE: 222
:END:
The Boosting method is an ensemble method. It estimates multiple models using a _weighted data sample_.

The weights applied on the data change according to the classification errors made by the models, to allow difficult observations to get more attention.
But this calls for a *drawback*: the models might become overfitted on the difficult observations.

The final model used is a combination of all the individual models.

**** Random Forest :missing_informations:
:PROPERTIES:
:NOTER_PAGE: 225
:END:
We create a "forest" of decision trees, with random splitting decision variables for each tree.

It's not clear how the final model is built from the set of decision trees.

*** Evaluating a fraud detection model
:PROPERTIES:
:NOTER_PAGE: 230
:END:
Two key decisions determine the effectiveness of the predictive models shown above:
- how to split the data set
- how we choose our performance metrics.

**** Splitting the data set
:PROPERTIES:
:NOTER_PAGE: 233
:END:
The training data set and the test dataset must be completely separated.
The decision on how we split the set *depends on the size* of the dataset itself.

When present, the validation sample (seen for [[*Stopping decision][decision trees]] and [[*How many hidden neurons?][neural networks]]) should be separated, too, but the requirement is less strict.

Sometimes, having the _same percentage of fraudsters_ in each set can be useful; Such split-up is called a *stratified split-up*.

***** Small data sets
When the data set is not big enough, two methods can be adopted to make the split:
- *Cross-validation*:
  The data is split in K groups, then the model is trained on K-1 groups and tested on the remaining group.
  The process is then repeated for every possible validation group, resulting in K _performance estimates_ (/aren't they also different models?/).
- *Leave-one-out cross validation*:
  Every observation is left out in turn and a model is made from the remaining ones.

The selection of the model can then be performed in different ways:
- randomly (common for leave-one-out cross validation, since every model changes by only an observation)
- a final model on all observation is built (taking into consideration the performances coming out of the cross validation process)
- an ensemble model is built with a voting procedure (similarly to what we have seen for [[*Bagging][bagging ensemble models]])

**** Performance metrics
:PROPERTIES:
:NOTER_PAGE: 242
:END:
The main performance metrics used to evaluate our analytical model are:
- *classification accuracy* : $\frac{\text{true positive } + \text{ true negative}}{\text{true positive }+\text{ false positive }+\text{ false negative }+\text{ true negative}}$, or the percentage of correctly classified observations.
- *classification error* : $\frac{\text{false positive } + \text{ false negative}}{\text{true positive }+\text{ false positive }+\text{ false negative }+\text{ true negative}}$, or the percentage of wrongly classified observations.
- *sensitivity* (also called recall or hit rate) : $\frac{\text{true positive}}{\text{true positive }+\text{ false negative}}$, or the percentage of fraudsters correctly labeled.
- *specificity* : $\frac{\text{true negative}}{\text{false positive }+\text{ true negative}}$, or the percentage of non-fraudsters correctly labeled.
- *precision* : $\frac{\text{true positive}}{\text{false positive }+\text{ true positive}}$, or the percentage of labeled fraudsters that are actually fraudsters.


**** Managing skewed datasets
:PROPERTIES:
:NOTER_PAGE: 251
:END:
With a skewed[fn:1] dataset it might become difficult to make a valid model due to the missing observations labeled as frauds.
Two transformations can be made to the dataset to make it less skewed:
- *Oversampling* : replicate frauds to make the distribution less skewed.
- *Undersampling* : remove some observations that aren't frauds.

The two can also be combined, but usually undersampling yelds better results (since we don't put in the set forged observations).

In general, it's suggested to *stay as close as possible to the original distribution* to avoid unnecessary bias.

* DONE Mobile Forensics :guest_lecture:
Mobile devices use has increased between people and, in turn, mobile forensics investigation has gained importance.

Mobile forensics is a branch of digital forensics, related to the recovery of digital evidence from a mobile device under *forensically sound conditions*.

** Forensical soundness
Forensically sound is a term used to justify the use of particular forensic technology or methodology.

It doesn't have a specific definition ("/it depends/"), but we can say that a method is forensically sound when it _doesn't alter or destroy the evidence_ and has been shown to be _consistently reliable_.

For example, in computer forensics we use various ways to avoid altering the data on the system:
On computers you are typically able to remove the hard drive, and if this option is not available you usually have a way to boot a live distribution to mount the hard drive on a read-only way (from a phisical perspective, we are able to have a 100% forensically sound approach).

On mobile devices, this is extremely difficult to do, mostly because we are _limited in the use of our phone_ (unless we are root, which is usually not the case) and because most elements (like memory) is soldered.
Moreover, the memory in the phone is most of the time encrypted on some key stored on the motherboard or another chipset (see iOS devices and their enclave).

When the acquisition of data is not possible without changing the configuration of the device (even booting the phone might change some things), the _procedure must be documented_ and the _changes must be tested beforehand_.

*** Example :noexport:unuseful:
We have to find interaction between two people that has happened on an instant messaging application.
We can extract those data without having impact on *that* data (but having an impact in other parts of the OS).

If we, instead, have to check what has happened to the phone in the last X days, we have to be really careful to ensure the data is not altered in any way (or as little as possible).

*** Low Level Exploits
In some phones, it's possible to obtain the best acquisition (full, unaltered) with *low level exploits*, which allow us to _obtain root privileges before the phone boots_; Such acquisitions are the nearest to forensically sound in mobile forensics.
It's more common on Android devices.

*** Documentation is key
The key to forensic soundness is *documentation*. The acquisition process should change the original evidence as little as possible and any changes should be documented and assessed.

** Challenges of mobile forensics
In the mobile world we have a *big market fragmentation*, with new devices added daily.

Each and every device uses some kind of chipset (qualcomm, exynos, kirin etc.), and most exploits are available at the chipset level (sometimes also on software level, but rarely), which means we have to *undestand exactly the carachteristics of the device* in front of us.

Digital forensic analysts must also *overcome difficult security measures* (e.g: limited tries pin codes) brought up by the phone manufacturers, sometimes without the help of the incrimined person (s/he might be dead or unwilling to help).

Moreover, the *data of interest* for forensic analysts has *expanded to multiple applications* (where previously it was mostly sms and, sometimes, images).
The *amount of memory* to analyze in a smartphone has increased a lot (up to 500 gigs as of now) which implies the need for new analysis methodologies (e.g: AI recognition).

Finally, for some apps the data is stored not only on the phone but on the *cloud*, too, and to analyze those data you need access to the cloud account of the person, which:
1) is difficult to do
2) you must first get permission to do it

** Operating system diversity
In mobile, the most used OSes nowadays are _Android_ and _iOS_, with the only additional (still being developed) OS being _KaiOS_.
In Italy we use mostly Android, while in America iOS is dominant.
As you can understand, most of the commercial companies are US based.

*** Android versions diversity
Android has multiple versions still being used by a wide audience, with the security patches providing an additional layer of diversification.

When it comes to software level exploits, having knowledge of the version and which security patch is applied on the phone is the key point to choose your extraction methodology.

*** iOS versions diversity
Since iOS forces the updates on the phones, there's not the same diversity that you can find in the android market share.

** Guidelines to follow
There are various guidelines documented online to follow.
The one we will analyze is [[https://drive.google.com/file/d/1sVko_Uo7o6iootWwn9IoLJ3mrMVXqTDg/view][one from SWGDE]].

It's organized in sections:

*** Evidence collection and preservation
Tipically done by law enforcement.

**** Preparation
You need to have the proper tools to do and document the steps you will take, and you need to have proper legal authority to collect the evidence

**** Documentation
Take notes of the collection location and the device state and characteristics at the time of collection.
You have different things to identify and take as evidence, such as cables, phone boxes etc.

**** What to do first
Based on the state of the phone and its type, you have two options for the *preservation process* (what to do to preserve the integrity of the evidence and to work in a _forensically sound_ way):
- If on:
  + Keep it on. Making it turn off will almost certainly encrypt the phone
  + If the phone is on and the passcode was not inserted since boot, the phone won't have unencrypted its data and won't have used its ram (true mostly for iOS).
  + If we can access the settings, engage airplane mode, disable wifi, disable bluetooth and extend the display auto-lock.
  + If the system cannot be accessed, put it in a faraday bag to _avoid outside connections_ from happening.
- If off:
  + Don't turn it on
  + Remove the battery if possible
- In both cases, collect the device identifiers.

**** Check periferals
Check for any paired or linked devices, which might lead to backups or additional informations.

*** Evidence Handling
The steps to extract the data from your device without loss of digital or physical data (e.g: fingerprints).

**** Access devices
Frequently, phones can be unlocked if you have access to a safe place of the owner or another smart tool (a smartwatch) or the body of the person itself.
Be careful: don't try to guess the password, which might call procedures of the phone to provide additional security measures (like formatting the data partition of the phone).

**** Devices powered on and unlocked
Document as much as possible the content of the phone (also by taking pictures) without locking it accidentally.

If the phone is an organization's device, an MDM (mobile device management) system might be in place which would require to seek help from the system administrator of the organization to extract data.

**** Encryption
Most of the devices nowadays use some form of encryption.
iOS devices (mostly, but not only) have backup passwords.
There are ways to bypass and reset these kind of passwords but this modifies the content of the phone, and as such must be documented and extensively tested.

**** Network Isolation
Any kind of connection can be dangerous for the phone.

*** Evidence acquisition

**** Preparation
Prepare all the software applications, cables etc. to perform the acquisition.

There are various tools (and there is a [[https://www.nist.gov/itl/ssd/software-quality-group/computer-forensics-tool-testing-program-cftt/cftt-technical/mobile][website]]) to test and review various type of forensics tools.
The number of tool vendors available is limited nowadays, and there's no single tool perfect for all scopes: we have to _use different tools for different devices_, and sometimes manual investigation is mandatory.

Sometimes, exploit are not available at the time of the analysis, but they might become available later on (for example, Epifani told us about a time when the exploit was made available during a trial and they were able to analyze the phone at that point).

***** Tools for law enforcement and acquisition services
Some of these tools are only *meant for law enforcement*.
Most of the times though, police analysts use unlocking and decryption mechanisms *provided as a service*, where you send the phone to a lab and they unlock it through zero-days exploit that are not yet available to the public (and not yet tested).

This methods must be carefully reviewed by a court of law, since the methods used are not reliable.

**** Device identification
To identify a device, you can use:
- its *IMEI*, a number to univocally identify it worldwide
- the model number
- the serial number

Sometimes, the IMEI is written on the back of the phone, sometimes it is written in the simcard tray, sometimes on the packaging box of the phone, but it should always be accessible (on an unlocked and functioning device) by dialing =*#06#=.

Once the IMEI is identified, you need to search and understand what characteristics the phone has based on it. You can use [[https://imei.info][this website]] to find informations about it.
Most importantly, the chipset must be known to understand which tool/technique to use to extract data from the phone.

Another option is to _check the coverage of the warranty_ of the phone (mainly for apple devices) through the serial number. This way you can undestrand wether the phone was recently purchased and, based on the informations acquired, you can ask apple (as a public prosecutor) to provide you informations about that phone.

**** Extraction methods
As a general rule, you can obtain different level of extraction based on the kind of devices and the patches applied.

***** Physical acquisition
Our goal is generally to obtain a physical, non invasive acquisition, which means we would use an exploit to obtain an image of the entire phone without phisically handling the phone (except for the insertion of a cable).

On most Samsung, encryption is done using full disk encryption (and not file based encryption). In this cases, we can change the boot loader (the part of the OS responsible of starting the OS) to and "engineering bootloader" to be able to access the trusted zone of the phone and obtain the encryption keys.

These engeneering bootloader must be signed by Samsung and be valid for the phone.

***** Logical acquisition

When a physical acquisition is not possible we rely on smaller acquisitions or, sometimes, simple logical acquisitions (which means that we only take what is available to us as non-root users).

Whit a logical aquisition we can tipically obtain native applications data but not third parti applications data (whatsapp, facebook etc.)

***** Partial filesystem aquisition
Since we are mostly interested on third party applications, sometimes we might try some (software) invasive method to get those data, for example to downgrade the application to have a viable exploit to make.
Take note that *this method is invasive*, since you are changing the state of the phone to do it.

***** Invasive acquisition
You can remove the chip from the device and try to analyze it, but most of the times nowadays you will get encrypted data.
This is still a _great option for IoT devices_.

On some android devices you can also simply remove external memories (sd cards and sim cards), even though sim cards don't contain much infos except for carrier informations.

**** Data extraction :noexport:unuseful:
You must try to have as little impact as possible during your data extraction.

** Tool analysis: Autopsy
Autopsy is an open source tool to analyze machines (calls itself the "premium forensic platform").
For mobile forensics, it will need an image to analyze.
It is centralized (in the organization, not globally), so its users users can share content.

*** Android analysis on Autopsy
Once you unzip the android file, you get two files:
- a 30gb file containing the dump of the rom memory of the file. That's a full _filesystem_ image, with the partitioning schema included.
- another 4mb file

Let's analyze the image by, first, creating a /case/ and adding our image to it. The type of source should be DiskImage (not LogicalFiles, since we have available a filesystem with partitions).

Then you select the timezone (UTC, we guess) and the tools to run on the image.
The tools we are going to use are:
- File Type identification
- Extension mismatch detector
- Embedded files extractor (allows to check if there is a file containing other files, like zip files, documents with images etc.)
- Picture analyzer (checks internal metadata for pictures)
- Android analyzer

The tool will start adding the data source to your case.

**** Image extraction

The extraction of the image must usually be done with commercial tools, like UFED for PC (from Cellebrite).
The same company makes a commercial analyzer (like autopsy, but a bit more advanced).

Image extraction on a locked phone is based on an exploit, and as usual this is risky.
That's why you should know what are the risks of each image extraction method (there are multiple, that can extract different kinds of informations)

**** Image Analysis
After having loaded the image, you can look at its contents through Autopsy.
You can see, by looking at the data sources, the huge number of partitions in an android device.
The most important ones are:
- The *system partition*, where the stock OS resides.
  + The app folder in the system partition contains pre-installed apps, in particular the apk files to run them.
  + This partition should not contain user data (unless the phone is rooted)
  + The =build.prop= file in the root of the file system contains the the properties of this build of android (like versions).
- The userdata partition.
  + Contains user data, settings, applications installed via the play store etc
  + You have an app folder here too, containing the apk files of the  applications installed by the user.
  + Under the data folder, we have a folder for each package (com.whatsapp, for example) and this folder is the only one to which the application can write data to.
    The data organization in this folder is highly dependant on the application.
- The misc folder.
  + Contains mainly network configurations, which can tell us more on the locations the target visited.

The results of the analysis are in the "Extracted Content" submenu.
We can see:
- Call logs, organized as databases, with cellular calls, facebook calls etc.
  To extract its contents we need to understand how its data is organized.
- Messages, organized in databases too, with SMS, whatsapp messages etc.
  These might not be all the messages saved on the phone! These are just the ones the tool was able to extract.
- Pictures, which can also be cached pictures.
- The list of installed applications

** Android analysis with Physical analyzer (commercial tool)
Built for mobile only.

The unpacking of the image is done through layers: you start with the filesystem layer, then go to the volume layer, then to the file layer

The difference with Autopsy is the number of applications data layouts recognized.
For example, if we go to look at the call logs, they are many more than the ones we found in Autopsy, because it was able to fetch calls from more applications.
You can also see the file where the information was extracted from, and the specific point of extraction.

When you see a red number next to an entry you know that number of items where deleted by the user and recovered by the tool.

Through the timeline, you can see every item with the timestamp of the last access/creation, with a graph showing the usage of the phone based on them.

Moreover, you can also see the account tokens used in the phone (potentially having access to the account).

*** How to have a forensically resilient phone :in_class_question:
To have a forensically resilient phone, the producer must limit the costumers on their use and set restrictions on the things they can do with the phone.

* NO Guest_lecture_glorioso :noexport:
:PROPERTIES:
:NOTER_DOCUMENT: slides/Guest_lecture_glorioso.pdf
:NOTER_PAGE: 27
:END:
We are assisting to a true "fourth revolution".

** Cyber space
:PROPERTIES:
:NOTER_PAGE: 4
:END:
We have many categories of illegal activities in this sphere.
These are very different and different are the the ways to combat them.

*** Definition of cyber space
:PROPERTIES:
:NOTER_PAGE: 6
:END:
"Schizophrenic interconnection of data" by Gibson.
Another version from the Pentagon.

*** Example of Cyber warfare
:PROPERTIES:
:NOTER_PAGE: 7
:END:
In Estonia, banks were disabled for a certain amount of time.

Cyber attacks are often connected to their political contexts (example: Stuxnet).

*** UNGGE
:PROPERTIES:
:NOTER_PAGE: 11
:END:
A group of governamental experts to study the field of information and telecommunications.
It created the International law (the "charter of the UN").

*** Legal framework of Cyber Operations
:PROPERTIES:
:NOTER_PAGE: 14
:END:

*** Nato position on cyber attacks
:PROPERTIES:
:NOTER_PAGE: 15
:END:
The attacked country has the possibility to react with firearms.
Only once it was used, against Afghanistan.

Two important exercises are made yearly by the NATO to test their offensive/defensive capabilities.

*** Cyber warfare in the scope of the conflict law
If a cyber attack is made to a bank system, is it considered an armed attack/ and attack that requires a reaction?
You can considering the attack "kinetic" when it has victims or injuried.
*** Qualification of a cyber attack
:PROPERTIES:
:NOTER_PAGE: 21
:END:
*** Ethics on cyber conflict
:PROPERTIES:
:NOTER_PAGE: 22
:END:
A workshop was organized with technical experts to define what is not defined yet in this context.
*** The cyber coalition
:PROPERTIES:
:NOTER_PAGE: 25
:END:
Huge execise on Nato cyber defence.
** The problem now
We don't have a state practice. But in case of an attack we will probably use article 5 to promote a kinetic answer.
* DONE Malware Analysis :missing_informations:guest_lecture:
There are two kinds of analysis (we will use both in the demo):
- static:
  The code is not executed; Avoids malicious behaviors, but might be slow.
- dynamic:
  Usually made through a debugger: You run the program and check its runtime behavior.
  _Can_ be much faster than static analysis (but the malware might recognize it's being dynamically analyzed, or be dormiant)

The *best strategy is doing both*.

On windows, register entries are used by malwares to get persistency and stay hidden.

* TODO Cloud forensics
Digital forensics meets a plethora of problems when confronted with cloud infrastructures.
In the following, the focus will mainly be on public clouds, since they are the ones affected by these problems.

** Acquisition issues
In general, no control is given to the user on hw and storage space.
Investigators cannot really access the metal[fn:5], at most they can have dumps of the vm hosting the client's storage.

All our concepts about [[*Data Recovery][data remnants recovery]] are unuseful in this context, since the stuff you deallocate is lost on a virtual drive.

Depending on the service, we have different levels of access:
- SaaS:
  The cloud service provider has logs for application and network. This data can only be seized with a plenaria[fn:6] from the judge, but it may not be available (maybe the provider doesn't keep them).
- PaaS
- IaaS

*** Data existence
In the cloud world, it is _not always true that data exists_.
Most data exists only in the scope of a transaction; For example, the comments to a deleted video on youtube might be unfeasible to check.
This is a very difficult concept to explain to a court.

**** Experience
The court once asked an internet giant to retrieve the contents of a deleted page.
The giant responded that it was "too costly", and it was in fact true, but the answer was rejected.
It's difficult for non technical people to understand the complexity of a system that allows billions of people to see the same thing simultaneously.

Another example of lack of data is when we try to get the number of people that interacted with a page/an element.

*** Acquisition problems
How do you acquire a web page?

Problems:
- Dynamic contents
  How can you be sure that is what the victim was seeing? Everything the user see might be based on something he has done.
- Due to encryption, we cannot use the old method of using a packet sniffer to capture the data.
- Visualization is different from data. What is the status of things that are imported from the outside?
- Who is the couprit of an offensive advertisement?
- The attribution problem
  The structure of the internet changes daily, and you want to retrieve the data at the time of the victim's visit. This data consists in:
  + Whois data
  + DNS resolution
  + Connectivity and provider identification
  + geolocation of hoster (in particular, this is the most uncertain since is given by the provider).

** Analysis issues
The _retrieval of deleted data_ (the most expected work by forensics experts) is basically *impossible on cloud environments*.

If you are trying to investigate any compromise that extends to the hypervisor, it will be almost impossible to investigate, unless the cloud provider wants to demonstrate such compromise with you (quite unusual, since then they'll have to admit the security breach).

** Attrubution issue
In cyberspace, attribution is diffcult: IPs can be taken, but linking them to a real person is the real deal.

In cloud forensics, the problem is even worse: Anyone can pay with someone else's payment card the cloud instance fee.

** Legal issues
The geographic location of the IP address changes drastically the law system aroud the case.

The location of data in cloud services may be difficult to prove or the data might be on multiple locations altogether.
What happens if the data centers storing each part of the data are on different jurisdiction with different laws?

*** Clouds of clouds of clouds
Some cloud systems use other cloud providers to store their data.
This add other layers of indirection that would complicate even more the matter.

** Forensically enabled clouds :noexport:missing_informations:
Some clouds supports investigation (are used by investigators):
- Data location (to allow companies to have their data stay in a certain location, other than the reasons seen above)
- Proof of past data possession
[...]

*** Dual considerations
- Pros
  + data storage size is constantly increasing
  + analysis of large amounts of data might be unfeasible on local hardware
- Cons
  + Repeatability of the act is limited
  + loss of control on evidence
  + chain of custody must be preserved

* Should companies be more helpful to companies to support justice :noexport:

** Shooting of San Bernardino
FBI asked Apple to write some code to avoid having the phone wiped after too many wrong code attempts

Apple declined, mostly for a moral principle: the first amendement forbits the government to mandate speech

** Charged question
Justice is a very broad term, and the questions seems charged: is justice always represented by the government?

The right decision is the one that follows the decision that we, as a society, ha   d.

* Exam informations :noexport:
The exam is going to be a written one, except:
- If you are abroad (there's a checkbox to be flagged on subscription)
- All requests to make the exam online are going to be accepted, but be considerate of the number of people.
  Remember to enroll to the exam any way, since you must be enrolled to have your exam evaluated.

For this course specifically, you have received a link to make an oral exam. That oral exam is going to be remote, you won't have to give justifications.
The exam is going to be basically the same, there's going to be 3/4 questions.
Keep looking at the registration since the class or the time of the day will probably change, also look on the day of the exam itself (valid for both the written and the oral exam).

All the answers can be given in italian, too.

The time for the exam will be aroud 1 and a half hour (depending on the number of questions in exam)

** Topics
- all the topics Stefano taught
- all the topics Carminati taught
- all the topics Epifani taught
- About Bellante's classes, we won't be asked about details, but some things might be asked:
  - what malware analysis can achieve
  - what kinds of analysis can be made

All the other lectures aren't going to be on exam (but, if cited, they will be accepted).

* Footnotes

[fn:6] a plenaria is the definitive approvation of an action.

[fn:5] "metal" in this context means the effective machine on which the cloud instance is running.

[fn:4] litigation can be translated in italian with "fatto in esame".

[fn:3] If you have followed the course "Foundations of Operation Research", you are already familiar with this concept.

[fn:2] Basket market can be translated with "vendita al dettaglio" in Italian.

[fn:1] Skewness, in this context, can be read as *asymmetry*
