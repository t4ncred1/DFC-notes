<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2021-06-10 gio 19:40 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Digital Forensics and Cybercrime</title>
<meta name="author" content="Tancredi Covioli" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="css/dfc-notes.css" />
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Digital Forensics and Cybercrime</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org2fb3d05">Cybercryme Landscape</a>
<ul>
<li><a href="#org4ca7adc">Threat dimensions</a></li>
<li><a href="#org03f3c53">Gartner quadrant of threats</a></li>
<li><a href="#orgd5c3d3f">Internal threats</a></li>
<li><a href="#orgf212f1d">How to manage a cyber attack</a></li>
<li><a href="#orga32a54f">Financially oriented attacks</a></li>
<li><a href="#org4eda8ca">Cybercrime</a>
<ul>
<li><a href="#orge4995bf">Identity theft</a></li>
<li><a href="#org20a0740">Selling kits</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org7e95d5b">Abuses of cryptocurrency and forensics</a>
<ul>
<li><a href="#org0092255">Some informations</a>
<ul>
<li><a href="#org191cb3a">Bitcoin wallet</a></li>
<li><a href="#org99ac6bb">Bitcoin address</a></li>
<li><a href="#org35e2f35">Bitcoin mining</a></li>
<li><a href="#orga7b6299">Forks</a></li>
</ul>
</li>
<li><a href="#orgf4f7802">Pseudo Anonimity</a>
<ul>
<li><a href="#orgcac0bf8">How to protect Pseudo Anonimity</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org63763e6">Introduction to Digital Forensics</a>
<ul>
<li><a href="#org915808b">Witnesses vs experts</a></li>
<li><a href="#org51ec928">Daubert Standard (How to be an Expert Witness)</a>
<ul>
<li><a href="#org55865b8">Scientific Method</a></li>
<li><a href="#org61b0f43">Scientific Test for Daubert</a></li>
<li><a href="#org5af9f43">Four phases of investigation</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgc4f5c99">Acquisition</a>
<ul>
<li><a href="#org57426ce">Acquisition in Italy</a></li>
<li><a href="#org3ae451b">Brittleness of digital evidence</a>
<ul>
<li><a href="#org3e0fb07">Hashes</a></li>
</ul>
</li>
<li><a href="#org25c4019">Typical hw/sw for acquisition</a></li>
<li><a href="#org5895e5b">Bitstream images</a></li>
<li><a href="#org2e34e5e">Acquisition procedure</a>
<ul>
<li><a href="#org5f107c9">The time problem</a></li>
<li><a href="#org63c7dc3">The size problem</a></li>
<li><a href="#orgb861072">The encryption problem</a></li>
</ul>
</li>
<li><a href="#org5962c1b">Forensics Duplicators</a></li>
</ul>
</li>
<li><a href="#orgbb5d387">Identification</a>
<ul>
<li><a href="#org6801421">Setup</a>
<ul>
<li><a href="#org0c6359b">Why not windows</a></li>
<li><a href="#orgdf68618">Repeatibility</a>
<ul>
<li><a href="#orgb339cdd">Law enforcement tools</a></li>
</ul>
</li>
<li><a href="#org93313d0">What analysis encompasses</a></li>
</ul>
</li>
<li><a href="#org2abe872">Data Recovery</a>
<ul>
<li><a href="#org0b39e94">Disk Geometry</a></li>
<li><a href="#orgc4b439c">File system</a></li>
<li><a href="#orgfc2f9fe">Carving</a></li>
</ul>
</li>
<li><a href="#org4a6306a">Antiforensic Techniques</a>
<ul>
<li><a href="#orgb7e44b8">Timeline tampering</a></li>
<li><a href="#org57bd544">Countering file recovery</a></li>
<li><a href="#org83ccbd4">Fileless attacks</a></li>
<li><a href="#orgd500d54">Filesystem insertion and subversion technologies</a></li>
<li><a href="#orgd51732c">Log tampering</a></li>
<li><a href="#org25559b3">Patition table tampering</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgf5e9be3">SSD-forensics</a>
<ul>
<li><a href="#org64a622c">FTL</a></li>
<li><a href="#org4d4992f">Tests</a>
<ul>
<li><a href="#org4d242b5">Trimming</a></li>
<li><a href="#org38764db">Garbage Collection</a></li>
<li><a href="#org79013c0">Erasing patterns</a></li>
<li><a href="#org3c166b3">Compression</a></li>
<li><a href="#orgc9e02eb">Wear Leveling</a></li>
<li><a href="#org69fc5ae">Reults on file recoverability</a></li>
</ul>
</li>
<li><a href="#org4a1149a">Conclusions</a></li>
</ul>
</li>
<li><a href="#org956e5e3">Evaluation and presentation</a>
<ul>
<li><a href="#org6168e17">Evaluation phase</a>
<ul>
<li><a href="#orgeb6da01">The relationship with lawyers, customers and prosecutor/police</a></li>
<li><a href="#orgb383f9f">Analyzing the documents</a></li>
</ul>
</li>
<li><a href="#orga3822eb">Presentation phase</a>
<ul>
<li><a href="#orgcd19c2a">Typical errors found in reports and analyses and presentation errors</a>
<ul>
<li><a href="#org704549c">What to look for</a></li>
</ul>
</li>
<li><a href="#org6739e6d">What to do when your client is in the wrong</a></li>
<li><a href="#orgbfc5c12">Writing your report</a></li>
<li><a href="#org1849306">Structure of a report</a></li>
</ul>
</li>
<li><a href="#orgddd4942">Testimony as a witness</a></li>
<li><a href="#orgbb13833">Direct and cross examination</a></li>
</ul>
</li>
<li><a href="#org61a9671">Fraud analysis and detection&#xa0;&#xa0;&#xa0;<span class="tag"><span class="Carminati">Carminati</span></span></a>
<ul>
<li><a href="#org59d7dc9">Why people commit fraud</a></li>
<li><a href="#orgf9f5d36">Fraud categories</a></li>
<li><a href="#orgbbe48e1">Anti-fraud stategies</a>
<ul>
<li><a href="#orga6259ed">Anti fraud mechanisms</a></li>
<li><a href="#org98c80e1">Fraud detection and Fraud prevention</a>
<ul>
<li><a href="#orga2c5d51">Example of fraud prevention: Strong customer authentication</a></li>
</ul>
</li>
<li><a href="#orga97c033">Strategies for Fraud detection and prevention</a>
<ul>
<li><a href="#org6a5e276">Expert-based approach</a>
<ul>
<li><a href="#org8903fc1">Rule based engines</a></li>
</ul>
</li>
<li><a href="#org2c947a4">Automated fraud detection system</a>
<ul>
<li><a href="#orgc6b3688">Data driven fraud detection</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgc0d4b44">Fraud management</a></li>
</ul>
</li>
<li><a href="#orgd8bd481">Frauds as a dynamic phenomenon</a></li>
<li><a href="#orgeec1f98">Techniques to detect a fraud automatically</a>
<ul>
<li><a href="#org3dd54d6">Unsupervised learning analytics techniques</a>
<ul>
<li><a href="#org6a96605">Telecommunication example</a></li>
<li><a href="#org416a749">Limitations</a></li>
</ul>
</li>
<li><a href="#orgfaa11fa">Supervised learning techniques</a>
<ul>
<li><a href="#org8886152">Limitations</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org9f1b132">Developing a fraud detection system</a></li>
<li><a href="#org0334a0e">Social Network Analysis</a></li>
<li><a href="#org928d904">Fraud management cycle</a>
<ul>
<li><a href="#org4365282">Regular update of the model</a>
<ul>
<li><a href="#orgc8206a6">Reinforcement learning</a></li>
</ul>
</li>
<li><a href="#orgfefb530">Example: Credit card fraud</a></li>
</ul>
</li>
<li><a href="#org298112a">Fraud analytical process</a>
<ul>
<li><a href="#org854d252">Preprocessing</a></li>
<li><a href="#org042fd67">Analytics</a>
<ul>
<li><a href="#org772c9ab">Possible analysis outputs</a></li>
</ul>
</li>
<li><a href="#orgcf31102">Post processing phase</a></li>
<li><a href="#orgdb051eb">Key characteristics of successful fraud analtics models</a></li>
<li><a href="#org5df9df5">Fraud management as risk management</a>
<ul>
<li><a href="#orgcb48a3c">Economical cost</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orga23917b">Challenges of developing fraud-detection models</a></li>
<li><a href="#org6173ac9">Red flags of frauds</a></li>
</ul>
</li>
<li><a href="#org78090d1">Machine Learning for Fraud Detection&#xa0;&#xa0;&#xa0;<span class="tag"><span class="Carminati">Carminati</span></span></a>
<ul>
<li><a href="#orgdeab08f">Notice</a></li>
<li><a href="#org9d9f0a7">Data preprocessing</a>
<ul>
<li><a href="#org28b0f1d">Real data problems</a></li>
<li><a href="#org1e8381d">Types of sources</a>
<ul>
<li><a href="#org9ef3772">Transactional Data</a></li>
</ul>
</li>
<li><a href="#org6576fa0">Types of data elements</a></li>
<li><a href="#org46ee181">Sampling</a>
<ul>
<li><a href="#org4292a15">Bias example</a></li>
<li><a href="#orgb2cd4a1">Stratified sampling</a></li>
</ul>
</li>
<li><a href="#org6482603">Visual data exploration</a></li>
<li><a href="#org5ec6e13">Exploratory statistical Analysis</a></li>
<li><a href="#org4edb166">Dealing with missing values</a></li>
<li><a href="#orgf0d1baf">Outliers</a>
<ul>
<li><a href="#orga9b448b">Outlier treatment</a></li>
</ul>
</li>
<li><a href="#org0ae3f95">When invalid data is not outlying</a></li>
<li><a href="#org12ce6c8">Conclusion on outliers and invalid values</a></li>
<li><a href="#org5663310">Standardization</a></li>
<li><a href="#orgf957aad">Categorization</a></li>
<li><a href="#org8ba1d01">Variable Selection</a>
<ul>
<li><a href="#orge86d461">Filters</a></li>
<li><a href="#orgc73e210">Wrapper</a></li>
<li><a href="#org58e392b">Principal Components Analysis</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgc8541b9">Descriptive analytics for fraud detection</a>
<ul>
<li><a href="#org3f48fe8">Relevant environments for Unsupervised learning</a></li>
<li><a href="#org3cdc1d4">Defining the norm</a></li>
<li><a href="#org4990014">Graphical outliers detection</a></li>
<li><a href="#org6c0a026">Statistical outliers detection</a>
<ul>
<li><a href="#orgf53bb67">Break point analysis</a></li>
<li><a href="#org6b1b419">Peer Group analysis</a>
<ul>
<li><a href="#org6459af1">Identifying, sizing and comparing a peer group</a></li>
</ul>
</li>
<li><a href="#org66617a6">Break point analysis vs peer group analysis</a></li>
<li><a href="#orgdd5d78b">Association rule analysis</a>
<ul>
<li><a href="#org057958d">Support</a></li>
<li><a href="#orga783a0a">Confidence</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org74119c4">Clustering</a>
<ul>
<li><a href="#orgc8c3c45">Kinds of clusters</a></li>
<li><a href="#orgdab6fad">Measure the similarity of elements</a></li>
<li><a href="#org5aa9585">Hierarchical clustering</a>
<ul>
<li><a href="#org8d00bf7">Distance between clusters</a></li>
<li><a href="#orgd7e3dca">Select the number of clusters</a></li>
<li><a href="#orge4d58f3">Advantages and disadvantages</a></li>
</ul>
</li>
<li><a href="#org337bb49">Nonhierarchical clustering</a>
<ul>
<li><a href="#org96c7640">k-means</a></li>
<li><a href="#org8cd194e">Self organizing maps</a></li>
</ul>
</li>
<li><a href="#org6329caf">Semi-Supervised clustering</a></li>
<li><a href="#org5cb7fcd">One-class SVM</a></li>
<li><a href="#orgc6eae08">Evaluation of clustering solutions</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orga913516">Predictive analytics for fraud detection</a>
<ul>
<li><a href="#orgb0a85f6">Linear regression</a></li>
<li><a href="#org653a6f9">Logistic regression</a></li>
<li><a href="#orgb5b5c7a">Decision trees</a>
<ul>
<li><a href="#org41f0e05">Splitting decision</a></li>
<li><a href="#org5f80c15">Stopping decision</a></li>
<li><a href="#orgd2cc20b">Advantages</a></li>
<li><a href="#org3cf328a">Disadvantages</a></li>
</ul>
</li>
<li><a href="#org70d8417">Regression trees</a></li>
<li><a href="#org4bd7d25">Neural Networks</a>
<ul>
<li><a href="#org9968353">Layers</a></li>
<li><a href="#orge25e6e2">Weigth learning</a></li>
<li><a href="#org023a6dc">How many hidden neurons?</a></li>
<li><a href="#org1dd4255">The overfitting problem</a></li>
<li><a href="#org82070ba">Neural Networks lack interpretability</a>
<ul>
<li><a href="#org4e52c4e">Variable selection in Neural Networks</a></li>
<li><a href="#org8429ad9">Extracting rules from Neural Networks</a></li>
</ul>
</li>
<li><a href="#org7de3f9e">Two stage model setup</a></li>
</ul>
</li>
<li><a href="#org5b137bd">Support Vector Machines</a>
<ul>
<li><a href="#org0b0a67b">Benefits</a></li>
<li><a href="#orgcc3e8e5">Problem</a></li>
<li><a href="#org219bd6e">Rule extraction and Variable selection</a></li>
</ul>
</li>
<li><a href="#org7b1981e">Ensemble methods</a>
<ul>
<li><a href="#org7cf8775">Bagging</a></li>
<li><a href="#org4d1b083">Boosting</a></li>
<li><a href="#orgbd5ef72">Random Forest&#xa0;&#xa0;&#xa0;<span class="tag"><span class="missing_informations">missing_informations</span></span></a></li>
</ul>
</li>
<li><a href="#orgfd499bf">Evaluating a fraud detection model</a>
<ul>
<li><a href="#org8f16125">Splitting the data set</a>
<ul>
<li><a href="#org04e20b5">Small data sets</a></li>
</ul>
</li>
<li><a href="#orgbc3870f">Performance metrics</a></li>
<li><a href="#orgccf91c6">Managing skewed datasets</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgf8d74bb">Mobile Forensics&#xa0;&#xa0;&#xa0;<span class="tag"><span class="guest_lecture">guest_lecture</span></span></a>
<ul>
<li><a href="#org8135907">Forensical soundness</a>
<ul>
<li><a href="#org709cc0c">Low Level Exploits</a></li>
<li><a href="#org8ea43cb">Documentation is key</a></li>
</ul>
</li>
<li><a href="#orgd3e9ed7">Challenges of mobile forensics</a></li>
<li><a href="#org7f0a7bf">Operating system diversity</a>
<ul>
<li><a href="#org6f55508">Android versions diversity</a></li>
<li><a href="#orgd3ae339">iOS versions diversity</a></li>
</ul>
</li>
<li><a href="#org09410d8">Guidelines to follow</a>
<ul>
<li><a href="#orgdd28150">Evidence collection and preservation</a>
<ul>
<li><a href="#orge0507c1">Preparation</a></li>
<li><a href="#org67798ee">Documentation</a></li>
<li><a href="#org40572f1">What to do first</a></li>
<li><a href="#org5da814a">Check periferals</a></li>
</ul>
</li>
<li><a href="#orga49290a">Evidence Handling</a>
<ul>
<li><a href="#orga613415">Access devices</a></li>
<li><a href="#orgca7ea28">Devices powered on and unlocked</a></li>
<li><a href="#org38aab61">Encryption</a></li>
<li><a href="#org5edd1dd">Network Isolation</a></li>
</ul>
</li>
<li><a href="#orgbe88cbc">Evidence acquisition</a>
<ul>
<li><a href="#org74359f6">Preparation</a>
<ul>
<li><a href="#org28b14b0">Tools for law enforcement and acquisition services</a></li>
</ul>
</li>
<li><a href="#org36aa2bf">Device identification</a></li>
<li><a href="#orge568fd1">Extraction methods</a>
<ul>
<li><a href="#org739e4d5">Physical acquisition</a></li>
<li><a href="#org2e51c09">Logical acquisition</a></li>
<li><a href="#org5059dd1">Partial filesystem aquisition</a></li>
<li><a href="#orgb3249b3">Invasive acquisition</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#org9114a02">Tool analysis: Autopsy</a>
<ul>
<li><a href="#org8f8d80f">Android analysis on Autopsy</a>
<ul>
<li><a href="#orgc8c7172">Image extraction</a></li>
<li><a href="#org60e3c85">Image Analysis</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org528091d">Android analysis with Physical analyzer (commercial tool)</a>
<ul>
<li><a href="#org9d4ab62">How to have a forensically resilient phone&#xa0;&#xa0;&#xa0;<span class="tag"><span class="in_class_question">in_class_question</span></span></a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org129779e">Malware Analysis&#xa0;&#xa0;&#xa0;<span class="tag"><span class="missing_informations">missing_informations</span>&#xa0;<span class="guest_lecture">guest_lecture</span></span></a></li>
</ul>
</div>
</div>
<div id="outline-container-org2fb3d05" class="outline-2">
<h2 id="org2fb3d05">Cybercryme Landscape</h2>
<div class="outline-text-2" id="text-org2fb3d05">
<p>
<b>Risks</b> are a statistical evaluation of the exposure to damage because of the presence of vulnerabilities and threats.<br />
</p>
</div>
<div id="outline-container-org4ca7adc" class="outline-3">
<h3 id="org4ca7adc">Threat dimensions</h3>
<div class="outline-text-3" id="text-org4ca7adc">
<p>
Threats can be<br />
</p>
<ul class="org-ul">
<li><b>Generic</b> or <b>Targeted</b>:<br />
<ul class="org-ul">
<li>Generic threats are threats in which we incur for simply being connected to the internet.<br /></li>
<li>Targeted threats are threats that exploit known informations about us.<br /></li>
</ul></li>
<li>Financially or non <b>financially motivated</b>:<br />
<ul class="org-ul">
<li>Financially motivated threats are easy to understand.<br /></li>
<li>Non financially motivated threats can be difficult to understand<br /></li>
</ul></li>
<li><b>Internal</b> or <b>External</b>:<br />
<ul class="org-ul">
<li>Internal threats are put up by some internal figure of the organization itself.<br /></li>
<li>External threats are put up by external figures (like criminals and other organizations).<br /></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org03f3c53" class="outline-3">
<h3 id="org03f3c53">Gartner quadrant of threats</h3>
<div class="outline-text-3" id="text-org03f3c53">
<p>
A table showing some example of the threat categories listed above, with their relative possible financiary motivation level.<br />
</p>
</div>
</div>
<div id="outline-container-orgd5c3d3f" class="outline-3">
<h3 id="orgd5c3d3f">Internal threats</h3>
<div class="outline-text-3" id="text-orgd5c3d3f">
<p>
Internal threats can be countered by contracts and <span class="underline">separation of duties</span>.<br />
They can be of various kind:<br />
</p>
<ul class="org-ul">
<li>Malicious insiders (personal gain)<br /></li>
<li>Inside agents (other organizations)<br /></li>
<li>Emotional employees (revenge)<br /></li>
<li>Reckless employees (self conciousness)<br /></li>
<li>Third party users (other organization&rsquo;s users)<br /></li>
</ul>
</div>
</div>
<div id="outline-container-orgf212f1d" class="outline-3">
<h3 id="orgf212f1d">How to manage a cyber attack</h3>
<div class="outline-text-3" id="text-orgf212f1d">
<p>
In cyberspace, private companies defend their own piece of infrastructure by themselves.<br />
When we talk about public or semi-public agencies (see ENI, VODAFONE etc.), what should they do in case of a big scale cyber-attack? Is the jurisdiction of the attack on them or on the nation?<br />
</p>

<p>
The NATO wrote an entire manual (the Tallin Manual) on the policy they think applies to confilcts in cyberspace.<br />
</p>
</div>
</div>
<div id="outline-container-orga32a54f" class="outline-3">
<h3 id="orga32a54f">Financially oriented attacks</h3>
<div class="outline-text-3" id="text-orga32a54f">
<p>
The monetization of the attacks can be either direct or indirect.<br />
</p>
<ul class="org-ul">
<li>Direct monetization: credit card / bank account fraud; ransomware; fake AVs.<br /></li>
<li>Indirect monetization: information gathering; abuse computing resources for other attacks; rent or sell botnets.<br /></li>
</ul>

<p>
The discriminant between the two is whether the money comes directly from the victim or from the use of their computer.<br />
</p>
</div>
</div>
<div id="outline-container-org4eda8ca" class="outline-3">
<h3 id="org4eda8ca">Cybercrime</h3>
<div class="outline-text-3" id="text-org4eda8ca">
<p>
Cybercrime has its own ecosystem, whit producers, enablers (that don&rsquo;t produce the exploits but keep them relevant) and clients<br />
</p>
</div>
<div id="outline-container-orge4995bf" class="outline-4">
<h4 id="orge4995bf">Identity theft</h4>
<div class="outline-text-4" id="text-orge4995bf">
<p>
Identities are stolen because they can be abused.<br />
American SSN is sometimes abused for authentication purposes.<br />
</p>
</div>
</div>
<div id="outline-container-org20a0740" class="outline-4">
<h4 id="org20a0740">Selling kits</h4>
<div class="outline-text-4" id="text-org20a0740">
<p>
Various kinds of kits are sold in the cybercrime ecosystem:<br />
Botnets, exploitation kits, viruses..<br />
</p>

<p>
These are then used for other kinds of crimes.<br />
</p>

<p>
Also, the selling of stolen VISA accounts is common for money laundering and scamming (e.g: the scam of buying plane tickets and sell them to poor people before the real owner of the card blocks the payment).<br />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org7e95d5b" class="outline-2">
<h2 id="org7e95d5b">Abuses of cryptocurrency and forensics</h2>
<div class="outline-text-2" id="text-org7e95d5b">
</div>

<div id="outline-container-org0092255" class="outline-3">
<h3 id="org0092255">Some informations</h3>
<div class="outline-text-3" id="text-org0092255">
</div>
<div id="outline-container-org191cb3a" class="outline-4">
<h4 id="org191cb3a">Bitcoin wallet</h4>
<div class="outline-text-4" id="text-org191cb3a">
<ul class="org-ul">
<li>Manage and store keys of you bitcoin addresses<br /></li>
<li>Creates and signs transactions (receive/send BTC)<br /></li>
<li>Track the balance<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org99ac6bb" class="outline-4">
<h4 id="org99ac6bb">Bitcoin address</h4>
<div class="outline-text-4" id="text-org99ac6bb">
<p>
String used to receive payments.<br />
You usually want to use more addresses to make people unable to track your movements.<br />
</p>
</div>
</div>

<div id="outline-container-org35e2f35" class="outline-4">
<h4 id="org35e2f35">Bitcoin mining</h4>
<div class="outline-text-4" id="text-org35e2f35">
<p>
&ldquo;Miners&rdquo; compete to solve a complex problem by bruteforce: find the next block of transactions with as much leading zeroes as possible.<br />
The one that resolves it first gets a reward (constantly decreasing).<br />
</p>
</div>
</div>

<div id="outline-container-orga7b6299" class="outline-4">
<h4 id="orga7b6299">Forks</h4>
<div class="outline-text-4" id="text-orga7b6299">
<p>
When two miners find the same solution at approximately the same time, each block becomes the new head of the blockchain for a network: the blockchain splits.<br />
That&rsquo;s what is called a fork.<br />
When other 6/7 blocks are found, we see which chain they continue and we consider that the &ldquo;real&rdquo; chain.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orgf4f7802" class="outline-3">
<h3 id="orgf4f7802">Pseudo Anonimity</h3>
<div class="outline-text-3" id="text-orgf4f7802">
<p>
An identity can have an arbitrary number of addresses, which can be used to split a transaction into multiple ones and make the derivation of the real owner difficult.<br />
</p>

<p>
But all the transaction data is available, so if you take enough care you can track the flow of a transaction and infer some things:<br />
</p>
<ul class="org-ul">
<li>most of the times, all the inputs of a transaction are the same user.<br /></li>
<li>New addresses are usually shadow addresses, made explicitly to cover the traces.<br /></li>
</ul>
</div>

<div id="outline-container-orgcac0bf8" class="outline-4">
<h4 id="orgcac0bf8">How to protect Pseudo Anonimity</h4>
<div class="outline-text-4" id="text-orgcac0bf8">
<p>
The &ldquo;flow tracking&rdquo; described above is made difficult by malicious sites by mixing together multiple transactions from different clients. (See Silk Road, as an example).<br />
</p>
</div>
</div>
</div>
</div>
<div id="outline-container-org63763e6" class="outline-2">
<h2 id="org63763e6">Introduction to Digital Forensics</h2>
<div class="outline-text-2" id="text-org63763e6">
<p>
Forensics: the application of scientific analysis methods to reconstruct evidence.<br />
</p>

<p>
Digital Forensics: the application of scientific analysis methods to computer systems/digital data/networks to reconstruct evidence.<br />
</p>
</div>

<div id="outline-container-org915808b" class="outline-3">
<h3 id="org915808b">Witnesses vs experts</h3>
<div class="outline-text-3" id="text-org915808b">
<p>
<b>Witnesses</b> testify about <span class="underline">what they personally know</span>. They cannot testify about something they heard from others.<br />
<b>Experts</b> can <span class="underline">testify with their scientifical analysis</span> even if they where not present.<br />
</p>

<p>
Experts are witnesses with knowledge, skill, experience or education that can form an opinion.<br />
</p>
</div>
</div>

<div id="outline-container-org51ec928" class="outline-3">
<h3 id="org51ec928">Daubert Standard (How to be an Expert Witness)</h3>
<div class="outline-text-3" id="text-org51ec928">
<p>
The <b>Daubert Standard</b> is a <span class="underline">rule of evidence</span> regarding the <span class="underline">admissibility of expert witness</span> testimonies in the U.S.<br />
</p>

<p>
In the states where the standard is applied, an expert must:<br />
</p>
<ul class="org-ul">
<li>have its specialized knowledge be helpful to the trier to understand the evidence<br /></li>
<li>have his/her testimony rely on sufficient facts/data<br /></li>
<li>have his/her testimony be <b>scientifically valid</b>:<br />
<ul class="org-ul">
<li>Must be the product of reliable principles and methods<br /></li>
<li>Such principles and methods must have been reliably applied<br /></li>
</ul></li>
</ul>
</div>

<div id="outline-container-org55865b8" class="outline-4">
<h4 id="org55865b8">Scientific Method</h4>
<div class="outline-text-4" id="text-org55865b8">
<p>
For a method to be scientific, it must be:<br />
</p>
<ul class="org-ul">
<li><b>Repeatable</b><br />
If the experiment cannot be repeated (e.g: blood drop analysis) it must be detailed enough to be understood fully.<br /></li>
<li><b>Falsifiable</b><br />
If the experiment cannot be confuted, it is not scientific (e.g: statistics cannot be considered scientific)<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org61b0f43" class="outline-4">
<h4 id="org61b0f43">Scientific Test for Daubert</h4>
<div class="outline-text-4" id="text-org61b0f43">
<p>
Factors to consider (not all of these must be simultaneously valid for the method to be considered scientific):<br />
</p>
<ul class="org-ul">
<li>Wheter the theory or the technique is accepted in the scientific community.<br /></li>
<li>Wheter it has been subjected to peer review.<br /></li>
<li>Wheter it has been tested (or can be).<br /></li>
<li>Wheter the rate of error is acceptable.<br /></li>
<li>Wheter the research was independent of the litigation<sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>.<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org5af9f43" class="outline-4">
<h4 id="org5af9f43">Four phases of investigation</h4>
<div class="outline-text-4" id="text-org5af9f43">
<p>
The four phases of an investigation are:<br />
</p>
<ol class="org-ol">
<li>The <b>acquisition</b> of the sources<br /></li>
<li>The <b>identification</b> of the evidences<br /></li>
<li>The <b>evaluation</b> of the evidences<br /></li>
<li>The <b>presentation</b> of the evidences<br /></li>
</ol>
</div>
</div>
</div>
</div>

<div id="outline-container-orgc4f5c99" class="outline-2">
<h2 id="orgc4f5c99">Acquisition</h2>
<div class="outline-text-2" id="text-orgc4f5c99">
</div>
<div id="outline-container-org57426ce" class="outline-3">
<h3 id="org57426ce">Acquisition in Italy</h3>
<div class="outline-text-3" id="text-org57426ce">
<p>
In Italy, it is not requested to provide a report on how the acquisition was made, so the methods now presented will be overkill.<br />
</p>
</div>
</div>

<div id="outline-container-org3ae451b" class="outline-3">
<h3 id="org3ae451b">Brittleness of digital evidence</h3>
<div class="outline-text-3" id="text-org3ae451b">
<p>
All digital evidence, if modified, is not <b>tamper evident</b>, which means it can be modified without the modification being noticeable afterwards.<br />
There are, though, some procedure to ensure that digital evidence becomes tamper evident.<br />
</p>
</div>
<div id="outline-container-org3e0fb07" class="outline-4">
<h4 id="org3e0fb07">Hashes</h4>
<div class="outline-text-4" id="text-org3e0fb07">
<p>
In court it is asked to prove that evidence hasn&rsquo;t been modified, and hashes allow you to validate that.<br />
Its <b>absence does not mean that the has been modified</b>.<br />
</p>

<p>
Remember that we create the hash so that we can create a record of how the evidence looks to be used later. This means that it <b>must be preserved in another location than the evidence</b> to ensure it has not been tampered with.<br />
</p>

<p>
They are not a dogma, and their absence won&rsquo;t be a huge obstacle for the &ldquo;jury&rdquo; to surpass.<br />
But they are useful to debunk any accusation of counterfation.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org25c4019" class="outline-3">
<h3 id="org25c4019">Typical hw/sw for acquisition</h3>
<div class="outline-text-3" id="text-org25c4019">
<ul class="org-ul">
<li>Hardware:<br />
<ul class="org-ul">
<li>Write blocker<br /></li>
<li>external disks (simple copy through a live usb)<br /></li>
<li>removable HD enclosures<br /></li>
</ul></li>
<li>Operating system:<br />
<ul class="org-ul">
<li>Live linux distribution image<br /></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org5895e5b" class="outline-3">
<h3 id="org5895e5b">Bitstream images</h3>
<div class="outline-text-3" id="text-org5895e5b">
<p>
Usually, by &ldquo;copying and pasting&rdquo; we lose some important informations.<br />
</p>

<p>
We can, instead, make a &ldquo;bit by bit&rdquo; clone <span class="underline">of the original media</span>.<br />
</p>

<p>
Of this image I want to make a hash, to ensure it&rsquo;s not tampered.<br />
</p>
</div>
</div>

<div id="outline-container-org2e34e5e" class="outline-3">
<h3 id="org2e34e5e">Acquisition procedure</h3>
<div class="outline-text-3" id="text-org2e34e5e">
<ul class="org-ul">
<li>If possible, <b>disconnect the media</b><br />
<ul class="org-ul">
<li>Connect it to an analysis station, with a <b>write blocker</b> possibly (not a necessity, you can just confugure correctly your software).<br /></li>
<li>compute the hash of the source<br /></li>
<li>make a clone of the source and check its hash<br /></li>
</ul></li>
<li>When media <span class="underline">disconnection is not possible</span> (soldered memory / raid devices / other constraints)<br />
<ul class="org-ul">
<li><b>live boot the system</b> with a linux distribution (possibly one targeted to forensic analysis)<br />
<ul class="org-ul">
<li>only available if the target is off, though.<br />
When turning off the target, <span class="underline">pull the plug</span>. Don&rsquo;t let it have a system shutdown.<br /></li>
</ul></li>
<li>if the <span class="underline">target is powered on and cannot be turned off</span>, make sure first to take all the data available in the system, and <b>work in volatility order</b>:<br />
<ul class="org-ul">
<li><b>disconnect the machine from the network</b>, if the network is not necessary.<br />
Done to avoid additional modifications.<br /></li>
<li>dump the memory (In linux, there are /dev/mem and /dev/kmem that you may use to acquire the memory of the machine while on).<br /></li>
<li>save runtime informations (network, processes etc)<br /></li>
<li>make the disk acquisition<br /></li>
</ul></li>
</ul></li>
<li>When we think we caught the intruder, we might want to make the analysis &ldquo;live&rdquo;:<br />
<ul class="org-ul">
<li>check the logs (only usable if they are on a different machine than the one attacked)<br /></li>
<li>check the network traffic (now or never)<br /></li>
</ul></li>
</ul>

<p>
The noerror and sync options of dd are used to not make dd stop in case of errors in the device.<br />
</p>

<p>
The recomputation of the hash of the source and the acquisition image is made to ensure they are the same and that the source has not been modified (by comparing it with the first hash made of the device).<br />
</p>

<p>
We often use <b>multiple hashing algorithms</b> to compute the hash for the same image.<br />
The reason is that someone else who has analized before (or will analyze) the drive might have used a different hashing algorithm.<br />
</p>
</div>

<div id="outline-container-org5f107c9" class="outline-4">
<h4 id="org5f107c9">The time problem</h4>
<div class="outline-text-4" id="text-org5f107c9">
<p>
Computing the copy of a 1TB hdd/usb key might take some time depending on the interface used by the hdd itself or by the write blocker.<br />
It might take several ours to compute an hash and make a copy of the source.<br />
</p>

<p>
To avoid the time waste, some softwares may automate part of the procedure by computing the source hash while copyng.<br />
</p>
</div>
</div>

<div id="outline-container-org63c7dc3" class="outline-4">
<h4 id="org63c7dc3">The size problem</h4>
<div class="outline-text-4" id="text-org63c7dc3">
<p>
In large scale investigations (or when multiple investigations are held in parallel), the sizes of the drives might make storing their clones and transfering them a real burden.<br />
Using external media devices is a no-go, since it slows down operations by a lot if you don&rsquo;t use the correct interfaces (USB).<br />
</p>

<p>
NASs and SANs are used all the times for this specific reason.<br />
</p>
</div>
</div>

<div id="outline-container-orgb861072" class="outline-4">
<h4 id="orgb861072">The encryption problem</h4>
<div class="outline-text-4" id="text-orgb861072">
<p>
In Italy, it might not be required for the persecuted to provide the passcode to decrypt the evidence for the analysis, since it can be seen as <b>testifying against oneself</b>.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org5962c1b" class="outline-3">
<h3 id="org5962c1b">Forensics Duplicators</h3>
<div class="outline-text-3" id="text-org5962c1b">
<p>
These perform the hashes and copy the hard drive into one of the others, printing a receipt with all the informations of the process.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orgbb5d387" class="outline-2">
<h2 id="orgbb5d387">Identification</h2>
<div class="outline-text-2" id="text-orgbb5d387">
</div>

<div id="outline-container-org6801421" class="outline-3">
<h3 id="org6801421">Setup</h3>
<div class="outline-text-3" id="text-org6801421">
<p>
The easyest operating system to work on when making forensic analisys is Linux, since it has/can:<br />
</p>
<ul class="org-ul">
<li>extensive native file system support<br /></li>
<li>native support for swapping drives<br /></li>
<li>mounting of disk images as drives<br /></li>
</ul>

<p>
On a linux guest we might keep some windows vms to use soe additional tools.<br />
</p>
</div>

<div id="outline-container-org0c6359b" class="outline-4">
<h4 id="org0c6359b">Why not windows</h4>
<div class="outline-text-4" id="text-org0c6359b">
<p>
Windows tampers with drives and <b>modifies evidence</b>.<br />
It doesn&rsquo;t support many file systems.<br />
</p>

<p>
Remember: Some tools are windows only, and as such you cannot use linux for your entire job.<br />
When using these tools inside a vm, be sure that the disk drive is not writable (this is a last resort, you should first try to work on a copy or on a write blocked drive).<br />
</p>

<p>
Be wary of proprietary and non free software.<br />
</p>
</div>
</div>

<div id="outline-container-orgdf68618" class="outline-4">
<h4 id="orgdf68618">Repeatibility</h4>
<div class="outline-text-4" id="text-orgdf68618">
<p>
Since any other expert must be able to perform the same experiment, you should <b>avoid proprietary/paid forensic solutions</b>.<br />
</p>

<p>
Moreover, if a machine is subject to a job without fully understanding (or having access to) how the job innerly works, you cannot say that its output represents truly repeatable evidence, since the expert should be (in theory) able to <b>perform the same analysis by hand</b>.<br />
</p>
</div>

<div id="outline-container-orgb339cdd" class="outline-5">
<h5 id="orgb339cdd">Law enforcement tools</h5>
<div class="outline-text-5" id="text-orgb339cdd">
<p>
Adversarial Investigation tools that <b>must be left hidden</b> to the public in order to avoid other people (e.g. criminals) finding ways to circumvent them.<br />
</p>

<p>
They are <i>not really fit</i> for the job, since to make an analysis scientific the tool shall be used and undestood by other experts.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org93313d0" class="outline-4">
<h4 id="org93313d0">What analysis encompasses</h4>
<div class="outline-text-4" id="text-org93313d0">
<p>
We will focus on tasks that only happen in forensics, but be careful: forensic analysis encompasses everything you have studied.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org2abe872" class="outline-3">
<h3 id="org2abe872">Data Recovery</h3>
<div class="outline-text-3" id="text-org2abe872">
<p>
One of the most typical tasks of computer forensics<br />
</p>
</div>

<div id="outline-container-org0b39e94" class="outline-4">
<h4 id="org0b39e94">Disk Geometry</h4>
<div class="outline-text-4" id="text-org0b39e94">
<p>
The data is read from the tracks on the platters.<br />
The minimum part of the track that can be read is a <b>Sector</b>.<br />
The minimum block that can be allocated for a file is a <b>Cluster</b>.<br />
A cilinder is the set of tracks that are on the same position (on different platters) on the drive.<br />
</p>

<p>
When a file is not exactly a multiple of clusters, the operating systems allocates the clusters anyway.<br />
</p>

<p>
The area that is left between the file end and the end of the last cluster is called &ldquo;slack space&rdquo;.<br />
This chunk of data contains the <b>remains of previously deleted stuff</b>.<br />
</p>

<p>
If this data is text or otherwise an easily recognizable file format, you can reconstruct (at least a minimal part of) a file.<br />
Zip files, most of images and audio etc. are probably not reconstructable this way, since they rely on headers and other file sections.<br />
</p>

<p>
But we could check if a file we are seeking for matches with the part in the slack space, to have a partial confirmation.<br />
</p>
</div>
</div>

<div id="outline-container-orgc4b439c" class="outline-4">
<h4 id="orgc4b439c">File system</h4>
<div class="outline-text-4" id="text-orgc4b439c">
<p>
The file system is the equivalent of the index of a series of folders and files.<br />
In each <b>inode</b> you have a table of (direct | indirect) pointers to data blocks in the hard drive.<br />
</p>

<p>
On file deletion, the file system entry is marked as free.<br />
After some time, the file system entry (not the data itself) is freed and, after some more time, the data block might be overwritten.<br />
</p>

<p>
If we want to access the deleted files, we either:<br />
</p>
<ul class="org-ul">
<li><b>if the file entry was not deleted</b>: un-mark the file entry in the inode for deletion<br /></li>
<li><b>if the file entry deletion has already taken place</b>: ignore the inode and look for the block.<br /></li>
</ul>
</div>
</div>

<div id="outline-container-orgfc2f9fe" class="outline-4">
<h4 id="orgfc2f9fe">Carving</h4>
<div class="outline-text-4" id="text-orgfc2f9fe">
<p>
Another method to retrieve data is the carving method, which consists in:<br />
</p>
<ol class="org-ol">
<li>Scan the drive as a single bit stream<br /></li>
<li><b>locate MIME types</b> of interesting file types<br /></li>
<li>consider anything in between as a candidate file.<br /></li>
</ol>

<p>
As the steps above show, carving <b>doesn&rsquo;t use informations from the file system</b>.<br />
</p>

<p>
The problem comes when encryption and/or compression are taken into consideration, where file types cannot be recognized anymore.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org4a6306a" class="outline-3">
<h3 id="org4a6306a">Antiforensic Techniques</h3>
<div class="outline-text-3" id="text-org4a6306a">
<p>
Aimed at circumventing the forensic analyst.<br />
They are called transient when they just deviate the analysis, definitive when they destroy/tamper the evidence.<br />
</p>

<p>
The <b>most vunerable phases</b> are aquisition and identification.<br />
</p>

<p>
<b>Transient antiforensics</b> techniques interfere mostly with identification, but can be detected and reverted/stopped from happening (most of the times).<br />
<b>Definitive antiforensics</b> techniques can sometimes be detected, too, but cannot be reverted.<br />
</p>
</div>
<div id="outline-container-orgb7e44b8" class="outline-4">
<h4 id="orgb7e44b8">Timeline tampering</h4>
<div class="outline-text-4" id="text-orgb7e44b8">
<p>
A technique that consists in modifying the timestamp of files on the disk to make them appear not correlated one another.<br />
It&rsquo;s a <b>definitive antiforensics</b> technique, since the old timestamp is not available anymore.<br />
</p>
</div>
</div>

<div id="outline-container-org57bd544" class="outline-4">
<h4 id="org57bd544">Countering file recovery</h4>
<div class="outline-text-4" id="text-org57bd544">
<p>
File recovery uses data remnants on the disk, so:<br />
</p>
<ul class="org-ul">
<li>secure deletion of files<br /></li>
<li>encryption<br /></li>
<li>virtual machines<br /></li>
</ul>
<p>
Are all available methods to avoid data to be recovered.<br />
It is a <b>definitive antiforensics</b> technique since it destroys (or negates the creation of) the evidence.<br />
</p>

<p>
The &ldquo;residual of magnetization&rdquo; is a file recovery method studied during the 90es.<br />
A 0 written where there was a 0 has a magnetization level slightly different than a 0 written where there was written a 1.<br />
This was never shown to be practical, but it was a reasonable assumption with the technology from the 90es; Nowadays (due to the high density of the bits) it is unusable.<br />
</p>
</div>
</div>

<div id="outline-container-org83ccbd4" class="outline-4">
<h4 id="org83ccbd4">Fileless attacks</h4>
<div class="outline-text-4" id="text-org83ccbd4">
<p>
No traces are left on the disk at all.<br />
Metasploit has this feature: it injects in memory a DLL.<br />
Thus all traces are lost after the machine is turned off (and turning off is one of the main steps to analyze data.)<br />
</p>
</div>
</div>

<div id="outline-container-orgd500d54" class="outline-4">
<h4 id="orgd500d54">Filesystem insertion and subversion technologies</h4>
<div class="outline-text-4" id="text-orgd500d54">
<p>
We place the data <span class="underline">where there&rsquo;s no reason to look for it</span>.<br />
The partition table, for example, has 32KB assigned but, in real use, it occupies 1KB at most.<br />
</p>

<ul class="org-ul">
<li>Inodes for bad blocks are created by the system to not use them.<br />
If we manage to pass a good block as a bad one, we get some free real estate.<br /></li>
<li>You can use directory inodes to, instead, point to data blocks<br /></li>
<li>We can put data in metadata structures ignored by forensic tools (this method is weak to carving)<br /></li>
</ul>

<p>
It is a <b>transient antiforensic</b> technique, since the evidence is hidden and not destroyed.<br />
</p>
</div>
</div>

<div id="outline-container-orgd51732c" class="outline-4">
<h4 id="orgd51732c">Log tampering</h4>
<div class="outline-text-4" id="text-orgd51732c">
<p>
If an attacker has access to the log files, it can tamper them to insert fake log entries or malicious code (this last option is only useful if they are automatically analyzed).<br />
</p>

<p>
It is a <b>transient antiforensics</b> technique, since the real evidence has not been modified.<br />
</p>
</div>
</div>

<div id="outline-container-org25559b3" class="outline-4">
<h4 id="org25559b3">Patition table tampering</h4>
<div class="outline-text-4" id="text-org25559b3">
<ul class="org-ul">
<li>If a partition is not correctly aligned, the OS (Windows) might still use it, while forensic tools might miss them.<br /></li>
<li>Normally, there is only one extendend partition per disk. Windows and Linux can manage multiple extended partitions, but forensic analysis tools might not support them.<br /></li>
<li>A high number of logical partitions in an extended one might bring the tool to crash.<br />
The case was with NCase, 15 years ago. It supported at most 26 partitions (one for each letter of the alphabet).<br /></li>
</ul>

<p>
This, too, is a <b>transient antiforensics</b> technique, since the data that composes the evidence is not altered.<br />
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgf5e9be3" class="outline-2">
<h2 id="orgf5e9be3">SSD-forensics</h2>
<div class="outline-text-2" id="text-orgf5e9be3">
<p>
SSDs are based on NAND based flash memory, widely used in mobile devices.<br />
</p>
</div>
<div id="outline-container-org64a622c" class="outline-3">
<h3 id="org64a622c">FTL</h3>
<div class="outline-text-3" id="text-org64a622c">
<p>
In order to write on nand, you need to blank the block completely.<br />
FTL (flash translation layer) chips are devices used to optimize the access to the SSD<br />
Functionalities:<br />
</p>
<ul class="org-ul">
<li>Caching<br />
Avoid blanking a block with one single bit flipped<br /></li>
<li>Trimming<br />
When the drive is idle, start trimming (clearing) blocks. It depends on the operating system to tell which blocks to trim.<br /></li>
<li>Garbage Collection<br />
An advanced form of trimming not dependent on the OS<br /></li>
<li>Data compression<br />
Avoid writing multiple blocks when possible<br /></li>
<li>Bad block handling<br />
When a cell is about to fail, the ssd should stop using it<br /></li>
<li>Wear leveling<br />
When we have a cell that has been written many times, we try to move on it static data.<br /></li>
</ul>

<p>
Since the FTL decides how to compress and obfuscate data and shuffles it (for wear leveling, even when the OS isn&rsquo;t running), it is the only one with the knowledge of the mapping between the logical structure of the data seen by the OS and the physical layout.<br />
</p>

<p>
The FTL cannot be disabled via software. You can read the chips with external tools (extremely difficult), risking the destruction of the drive.<br />
</p>

<p>
The FTL, moreover, is not standard: It is the main difference between different vendors (chips are usually the same) and, as such, they are intellectual property that they try to protect.<br />
</p>
</div>
</div>

<div id="outline-container-org4d4992f" class="outline-3">
<h3 id="org4d4992f">Tests</h3>
<div class="outline-text-3" id="text-org4d4992f">
<p>
A set of tests was developed to assess the impacts of FTL on the use of black-box tools.<br />
</p>
</div>
<div id="outline-container-org4d242b5" class="outline-4">
<h4 id="org4d242b5">Trimming</h4>
<div class="outline-text-4" id="text-org4d242b5">
<p>
Trim activates after a second of the drive being IDLE, and it is very aggressive.<br />
After ten second from the erase of the drive, it will be completely empties (looking through the FTL).<br />
</p>
</div>
</div>

<div id="outline-container-org38764db" class="outline-4">
<h4 id="org38764db">Garbage Collection</h4>
<div class="outline-text-4" id="text-org38764db">
<p>
We didn&rsquo;t find Garbage collection of the drives.<br />
</p>
</div>
</div>

<div id="outline-container-org79013c0" class="outline-4">
<h4 id="org79013c0">Erasing patterns</h4>
<div class="outline-text-4" id="text-org79013c0">
<p>
Certain SSD controllers exhibit unexpected trimming patterns.<br />
</p>
</div>
</div>

<div id="outline-container-org3c166b3" class="outline-4">
<h4 id="org3c166b3">Compression</h4>
<div class="outline-text-4" id="text-org3c166b3">
<p>
Files with High entropy (that cannot be compressed) will take more time to be written<br />
</p>
</div>
</div>

<div id="outline-container-orgc9e02eb" class="outline-4">
<h4 id="orgc9e02eb">Wear Leveling</h4>
<div class="outline-text-4" id="text-orgc9e02eb">
<p>
We thought that wear leveling, since it would make shadow copies of the files, could help the forensic analysis. It does not.<br />
</p>
</div>
</div>

<div id="outline-container-org69fc5ae" class="outline-4">
<h4 id="org69fc5ae">Reults on file recoverability</h4>
<div class="outline-text-4" id="text-org69fc5ae">
<p>
Very detrimental. If TRIM is active, it&rsquo;s quite difficult to recover any file.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org4a1149a" class="outline-3">
<h3 id="org4a1149a">Conclusions</h3>
<div class="outline-text-3" id="text-org4a1149a">
<p>
For forensics analysts, SSD are a pain in the arse.<br />
We can say that SSDs have an &ldquo;intrinsic&rdquo; secure deletion system.<br />
</p>
</div>
</div>
</div>
<div id="outline-container-org956e5e3" class="outline-2">
<h2 id="org956e5e3">Evaluation and presentation</h2>
<div class="outline-text-2" id="text-org956e5e3">
<p>
These phases are tightly coupled with experience and are difficult to teach generally.<br />
</p>
</div>

<div id="outline-container-org6168e17" class="outline-3">
<h3 id="org6168e17">Evaluation phase</h3>
<div class="outline-text-3" id="text-org6168e17">
<p>
Consists in <b>matching the evidence elements with the required legal elements to support/negate a legal theory</b>.<br />
</p>

<p>
The experts and the lawyer sit down and share their expertise, trying to match the requirements to negate or confirm an allegation.<br />
</p>

<p>
The judge will analyze what can be said now, what cannot be said and what are the other possible experiments to find something new.<br />
But sometimes, showing a feasible experiment to the jury can be detrimental to our own cause; There is a <b>risk</b> associated with each experiment we make.<br />
</p>

<p>
Very often, expert witnesses work on the results of other experts (not on the evidence itself).<br />
</p>
</div>

<div id="outline-container-orgeb6da01" class="outline-4">
<h4 id="orgeb6da01">The relationship with lawyers, customers and prosecutor/police</h4>
<div class="outline-text-4" id="text-orgeb6da01">
<p>
The important thing to remember is that: &ldquo;unless you are a police officer, you are not a policeman&rdquo;. It&rsquo;s <b>not your duty to punish</b> someone.<br />
Unless you are a lawyer, it&rsquo;s <b>not your duty to protect</b> people either (even though lawyers and customers pay your bills).<br />
You may be asked by the lawyer to omit a finding though (as long as it&rsquo;s not the same as lying).<br />
</p>

<p>
You should never compromise the trust of the customer in their lawyer.<br />
</p>

<p>
The process truth is not the same as historical truth: The law may not support incriminating someone that may be guilty historically.<br />
</p>

<p>
It is super important to stick to facts and science, we&rsquo;re <b>not fighting for justice</b>, and your thoughts must not be shaped by it.<br />
</p>

<p>
In Italy, a super-partes kind of experts are available: the judge experts, requested by the judge to review the evidence.<br />
</p>
</div>
</div>

<div id="outline-container-orgb383f9f" class="outline-4">
<h4 id="orgb383f9f">Analyzing the documents</h4>
<div class="outline-text-4" id="text-orgb383f9f">
<p>
You always need to analyze what can be said and <i>what can not</i>, possibly specifying <b>what further experiments would be needed</b> to say more.<br />
</p>

<p>
This last analysis must be perfomed to be prepared on what experiments the counterpart will perform and what will be the repercussions if out part asks to make such experiments.<br />
</p>

<p>
It&rsquo;s also very important to <b>review previous dovuments and evidences</b>, to look for technical/factual errors, suggestive writing and opinions treated as facts.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orga3822eb" class="outline-3">
<h3 id="orga3822eb">Presentation phase</h3>
<div class="outline-text-3" id="text-orga3822eb">
<p>
During the presentatiion phase, all experts must testify with objective facts (without interpretation or twisting) but they are not required to be completely non-sided to the matter (so they might want to avoid certain tests etc.)<br />
But be wary, since omission of truth is persecutable in Italy <b>experts cannot</b>, when asked, <b>claim professional secrecy</b>.<br />
</p>

<p>
After each analysis, the expert is asked a series of question called &ldquo;quesito peritale&rdquo;. One of the question is &ldquo;riferisca quant&rsquo;altro pu essere utile ai fini di giustizia&rdquo;.<br />
This implies that, should you find another crime evidence during your analysis, you are forced to say so.<br />
</p>
</div>

<div id="outline-container-orgcd19c2a" class="outline-4">
<h4 id="orgcd19c2a">Typical errors found in reports and analyses and presentation errors</h4>
<div class="outline-text-4" id="text-orgcd19c2a">
<p>
If the theory is that &ldquo;a supernatural/incredibly powerful being did something&rdquo; and that cannot be confuted, it is a &ldquo;trojan defense&rdquo;.<br />
(You can never exclude a trojan virus that deletes itself put the files on my computer, but it is not <b>falsifiable</b> so not <b>scientific</b>)<br />
We can provide additional explanations and alternative theories to these.<br />
</p>

<p>
Many court cases drag over a long time, so having a good written report (presentation) can be lifesaving to gather back the informations.<br />
The report you signed is the only thing you can bring with you in a court.<br />
</p>
</div>

<div id="outline-container-org704549c" class="outline-5">
<h5 id="org704549c">What to look for</h5>
<div class="outline-text-5" id="text-org704549c">
<ul class="org-ul">
<li><b>Acquisition errors</b><br />
<ul class="org-ul">
<li>missing links in the chain of custody<br /></li>
<li>missing/mismatched serial numbers<br /></li>
<li>errors during hashing/cloning procedures (missing write lockers)<br /></li>
</ul></li>
<li><b>Analysis errors</b><br />
<ul class="org-ul">
<li>steps where the hash is not verified<br /></li>
<li>use of proprietary programs<br /></li>
<li>technical mistakes.<br /></li>
</ul></li>
<li><b>Presentation errors</b><br />
<ul class="org-ul">
<li>the presentation is biased<br /></li>
<li>counter examples for an assumption can be found<br /></li>
<li>alternative theories not explored<br /></li>
</ul></li>
</ul>

<p>
In Italy it is <span class="underline">not enough to demonstrate that an analysis was not conducted under complete observance of the chain of custody</span>, but if you can raise questions and <span class="underline">show that other results are feasible</span> with the same set of informations and another analysis method, you can bring the jury to your side.<br />
That&rsquo;s why, during the presentation phase, you must be meticolous and list all possible counter examples.<br />
</p>

<p>
On the other side, if you cannot dispute the facts that the opposition is saying about your client, you can dispute their presentation.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org6739e6d" class="outline-4">
<h4 id="org6739e6d">What to do when your client is in the wrong</h4>
<div class="outline-text-4" id="text-org6739e6d">
<p>
You can avoid to present the informations about your client that aren&rsquo;t on your favor.<br />
But if the prosecutor asks, you must respond (unless you &ldquo;didn&rsquo;t touch&rdquo; the topic in your analysis)<br />
</p>
</div>
</div>

<div id="outline-container-orgbfc5c12" class="outline-4">
<h4 id="orgbfc5c12">Writing your report</h4>
<div class="outline-text-4" id="text-orgbfc5c12">
<p>
You want to explain the situation in a simple way, but not a simplistic way.<br />
The judge won&rsquo;t like to be treated like a child, but he will want to understand everything (so all the technical terminology will have to be explained).<br />
You will also have to explain why certain things are relevant.<br />
</p>
</div>
</div>

<div id="outline-container-org1849306" class="outline-4">
<h4 id="org1849306">Structure of a report</h4>
<div class="outline-text-4" id="text-org1849306">
<p>
Always explain the reasons behind an analysis and its results.<br />
</p>

<p>
Try to write &ldquo;obstacles&rdquo; in the way to get your client sentenced:<br />
</p>
<ul class="org-ul">
<li>&ldquo;the opposition did this&rdquo;<br /></li>
<li>&ldquo;By doing this, they actually ruled out this&rdquo;<br /></li>
<li>&ldquo;Even ignoring this, the evidence could be explained better with this&rdquo;<br /></li>
</ul>

<p>
Always write in the introduction what is your very conclusion.<br />
</p>

<p>
The conclusion is, most of the times, the only things the judge considers.<br />
Give a fast write up of what was written in the report, then use a strong ending phrase.<br />
<b>Stay factual</b>.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orgddd4942" class="outline-3">
<h3 id="orgddd4942">Testimony as a witness</h3>
<div class="outline-text-3" id="text-orgddd4942">
<p>
In many jurisdiction, the expert may be called as a witness or may only just have to submit a report.<br />
In Italy, if you are working in a criminal procedure, you must be called as a witness.<br />
</p>

<p>
In Italy, you are asked to know you duty as a witness: answer truthfully and not hide anything you know.<br />
</p>
</div>
</div>

<div id="outline-container-orgbb13833" class="outline-3">
<h3 id="orgbb13833">Direct and cross examination</h3>
<div class="outline-text-3" id="text-orgbb13833">
<ul class="org-ul">
<li><b>Direct examination</b><br />
you are <i>first</i> called by your side and proceed to a friendly direct examination.<br />
In this examination you must:<br />
<ul class="org-ul">
<li>be as helpful as possible<br /></li>
<li>be as clear as possible (make sure you explain everything to the judge)<br /></li>
<li>check previous records of the jusdge to prepare for possible questions<br /></li>
</ul></li>

<li><b>Cross examination</b><br />
you are called by the opposing side to testify. This is usually much more difficult than its direct counterpart.<br />
In this examination you want to:<br />
<ul class="org-ul">
<li>be court if you can, and if you can not be very complex and difficult to understand (you can take you time talking by looking at your report)<br /></li>
<li>If a question is positive for your side, be extremely clear and helpful<br /></li>
<li>Don&rsquo;t get personal on the things they say and don&rsquo;t get angry<br /></li>
</ul></li>
</ul>

<p>
In civil court, witnesses are expected to provide answers to questions that were listed to the judge, in the form of &ldquo;is it true that..&rdquo;.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org61a9671" class="outline-2">
<h2 id="org61a9671">Fraud analysis and detection&#xa0;&#xa0;&#xa0;<span class="tag"><span class="Carminati">Carminati</span></span></h2>
<div class="outline-text-2" id="text-org61a9671">
<p>
What is a <b>fraud</b>? It&rsquo;s a wrongful or criminal deception intended for financial or personal gain.<br />
In particular, it is:<br />
</p>

<ul class="org-ul">
<li><b>uncommon</b><br />
Only a minority of cases concerns fraud, which makes it difficult to detect them and to learn from historical cases.<br /></li>
<li><b>well considered and imperceptibly concealed</b><br />
Fraudsters remain unnoticed and covered by planning ahead their actions.<br /></li>
<li><b>time evolving</b><br />
fraud techniques evolve in time, ahead of fraud detection systems.<br /></li>
<li><b>carefully organized</b><br />
Fraudsters do not operate independently, they involve complex and organized structures.<br /></li>
</ul>
</div>

<div id="outline-container-org59d7dc9" class="outline-3">
<h3 id="org59d7dc9">Why people commit fraud</h3>
<div class="outline-text-3" id="text-org59d7dc9">
<p>
The main reason is the <span class="underline">potential monetary gain</span>.<br />
But we have an abstact model that tries to explain the drivers of a fraud, the <b>fraud triangle</b>, composed of:<br />
</p>
<ul class="org-ul">
<li>motivation<br /></li>
<li>opportunity<br /></li>
<li>rationalization<br /></li>
</ul>
</div>
</div>

<div id="outline-container-orgf9f5d36" class="outline-3">
<h3 id="orgf9f5d36">Fraud categories</h3>
<div class="outline-text-3" id="text-orgf9f5d36">
<ul class="org-ul">
<li>Banking and credit card frauds<br />
Has two subtypes:<br />
<ul class="org-ul">
<li>application fraud: obtain new credit cards from issuing companies by using false data and spend as much money as possible in a short time.<br /></li>
<li>behvioral fraud: detail of legit cards are obtained fraudolently. Does not necessarily require stealing the physical card, but the credentials.<br /></li>
</ul></li>
<li>Insurance fraud<br />
Can be either:<br />
<ul class="org-ul">
<li>from the side of the seller, if we<br />
<ul class="org-ul">
<li>sell policies for nonexistent companies<br /></li>
<li>setting up multiple policies to create commissions<br /></li>
</ul></li>
<li>from the side of the buyer, if we<br />
<ul class="org-ul">
<li>exaggerate claims<br /></li>
<li>falsify medical history<br /></li>
<li>fake death/kidnapping etc<br /></li>
<li>fake damage to our vehichle<br /></li>
</ul></li>
</ul></li>
<li>Corruption<br />
Misuse of entrusted power for personal gain.<br /></li>
<li>Counterfition<br />
A counterfeit is an imitation intended to be passes off fraudulently or deceptively.<br />
It is usually done on valuable objects like money, credit cards, popular products etc.<br /></li>
<li>Product warranty fraud<br />
Fraudently claiming compensation or remuneration based on a product warranty.<br /></li>
<li>Healthcare fraud<br />
Filling dishonest healthcare claims to make profit.<br /></li>
<li>Telecommunication fraud<br />
Theft/use of communication services to commit other frauds.<br />
<ul class="org-ul">
<li>cloning fraud: clone a number and the related call credit.<br /></li>
<li>superimposition fraud: fraudolent usage is added to the legit use of an account.<br /></li>
</ul></li>
<li>Money laundering<br />
Transform illegal money into legit funds.<br /></li>
<li>Click frauds<br />
Illegal clicks on a website advertisement to increase the payable number of clicks to the advertiser.<br />
Identity theft<br />
Obtain the financial/personal informations of another person for the purpose of assuming that person&rsquo;s identity to make purchases.<br /></li>
<li>Tax evasion<br />
Illegal act or practice of not paying (or paying partially) taxes that are owed.<br /></li>
<li>Plagiarism<br />
Use another&rsquo;s production without crediting the source<br />
It involves both stealing someone&rsquo;s work and lying about it afterwards.<br /></li>
<li>Sim swap attacks<br />
The attacker contacts your phone operator, asks for a new sim, get control of it, get access to your authentication method (if your phone is the secure point).<br />
The second factor authentication based on the sim introduced by banks caused this kind of frauds.<br /></li>
</ul>
</div>
</div>

<div id="outline-container-orgbbe48e1" class="outline-3">
<h3 id="orgbbe48e1">Anti-fraud stategies</h3>
<div class="outline-text-3" id="text-orgbbe48e1">
</div>
<div id="outline-container-orga6259ed" class="outline-4">
<h4 id="orga6259ed">Anti fraud mechanisms</h4>
<div class="outline-text-4" id="text-orga6259ed">
<p>
Reduce losses due to frauds:<br />
</p>
<ul class="org-ul">
<li>Prevents and detect part of the frauds.<br /></li>
<li>hinder fraudsters who will look for other easier opportunities. (go on other organizations)<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org98c80e1" class="outline-4">
<h4 id="org98c80e1">Fraud detection and Fraud prevention</h4>
<div class="outline-text-4" id="text-org98c80e1">
<p>
<span class="underline">Fraud detection</span> mechanisms recognize fraudolent activities after they have happened (ex-post approach)<br />
They usually provide the analyst with an index risk of fraud, depending on the past transaction (behavior) of the user<br />
</p>

<p>
<span class="underline">Fraud prevention</span> mechanisms avoid or reduce the frauds that will happen (ex-ante approach)<br />
</p>

<p>
They are <b>complementary</b> and <b>not independent</b>: if a fraud adapts to a detection mechanism, it will also impact prevention mechanisms and vice-versa.<br />
</p>
</div>

<div id="outline-container-orga2c5d51" class="outline-5">
<h5 id="orga2c5d51">Example of fraud prevention: Strong customer authentication</h5>
<div class="outline-text-5" id="text-orga2c5d51">
<p>
Two authentication methods are required to make a payment in the European Economic Area.<br />
</p>

<p>
But each security measure impacts the cost and usability of a system and, for this reason, in this case payments below 30 euros or low risk transactions in general are exempted.<br />
</p>
</div>
</div>
</div>
<div id="outline-container-orga97c033" class="outline-4">
<h4 id="orga97c033">Strategies for Fraud detection and prevention</h4>
<div class="outline-text-4" id="text-orga97c033">
</div>
<div id="outline-container-org6a5e276" class="outline-5">
<h5 id="org6a5e276">Expert-based approach</h5>
<div class="outline-text-5" id="text-org6a5e276">
<p>
This approach to fraud analysis is built on the domain knowledge of the fraud analyst.<br />
It involves <b>manual investigation</b> of a suspicious case to understand the fraud mechanism.<br />
</p>

<p>
It may find <b>new fraud mechanisms</b>.<br />
</p>

<p>
They are usually implemented with if-then-else rules engine.<br />
If the amount of claim is above the threshold, if there is a severe accident but no police/doctor report etc, then flag it as suspicious.<br />
</p>
</div>

<div id="outline-container-org8903fc1" class="outline-6">
<h6 id="org8903fc1">Rule based engines</h6>
<div class="outline-text-6" id="text-org8903fc1">
<p>
Rudimental (but quite functional) fraud detection systems, but expensive to build.<br />
</p>

<p>
They <b>must be kept secret</b> from fraudsters, which can learn the rules and circumvent them.<br />
Moreover, new <i>fraud patterns are not automatically signaled</i>: you must first make new rules for them.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org2c947a4" class="outline-5">
<h5 id="org2c947a4">Automated fraud detection system</h5>
<div class="outline-text-5" id="text-org2c947a4">
<p>
An automated system for detecting fraud requires less human involvement and could lead to a more efficient system, <b>based on data analysis</b>.<br />
<span class="underline">Expert knowledge remains, in any case, crucial to build the system</span>.<br />
</p>
</div>

<div id="outline-container-orgc6b3688" class="outline-6">
<h6 id="orgc6b3688">Data driven fraud detection</h6>
<div class="outline-text-6" id="text-orgc6b3688">
<p>
Based on machine learning.<br />
It is <b>precise</b>, due to the increased detection power than classic approaches and the massive amount of informations available from previous frauds used to uncover frauds that are not apparent.<br />
It is <b>efficient</b>, because it cost much less to automate the analysis than expert-based fraud detection systems.<br />
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgc0d4b44" class="outline-4">
<h4 id="orgc0d4b44">Fraud management</h4>
<div class="outline-text-4" id="text-orgc0d4b44">
<p>
When a fraud is detected, it must be<br />
</p>
<ul class="org-ul">
<li><b>corrected</b>, by providing a compensation for example. Note that you can be required to look at the past to be sure it didn&rsquo;t happen before.<br /></li>
<li><b>prevented</b> from happening again.<br /></li>
</ul>

<p>
A fraud becomes easier to detect the more time has passed, due to copycats using the same fraud over and over.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orgd8bd481" class="outline-3">
<h3 id="orgd8bd481">Frauds as a dynamic phenomenon</h3>
<div class="outline-text-3" id="text-orgd8bd481">
<p>
Frauds remain hard and complex to detect.<br />
</p>

<p>
A fraudster may think about sending fraudolent transactions that may try to <b>shift the model of fraud detection systems</b> of an institution.<br />
Unsupervised learning technique must be still monitored by experts.<br />
</p>
</div>
</div>
<div id="outline-container-orgeec1f98" class="outline-3">
<h3 id="orgeec1f98">Techniques to detect a fraud automatically</h3>
<div class="outline-text-3" id="text-orgeec1f98">
<p>
New techniques able to <span class="underline">adapt to new frauds</span> are needed.<br />
They can either be<br />
</p>
<ul class="org-ul">
<li><b>Unsupervised learning</b> (or descriptive) analytics techniques<br /></li>
<li><b>Supervised learning</b> (or predictive) analytics techniques<br /></li>
</ul>
</div>

<div id="outline-container-org3dd54d6" class="outline-4">
<h4 id="org3dd54d6">Unsupervised learning analytics techniques</h4>
<div class="outline-text-4" id="text-org3dd54d6">
<p>
They do not require labeled observations. They learn from past observations by <b>detecting anomalies</b>.<br />
They can detect novel fraud patterns.<br />
</p>
</div>

<div id="outline-container-org6a96605" class="outline-5">
<h5 id="org6a96605">Telecommunication example</h5>
<div class="outline-text-5" id="text-org6a96605">
<p>
I can see a fraud is in act if I see <i>multiple short calls</i>, <i>during night hours</i> and <i>with little time between one another</i>.<br />
But note that there can be multiple false negatives.<br />
</p>
</div>
</div>

<div id="outline-container-org416a749" class="outline-5">
<h5 id="org416a749">Limitations</h5>
<div class="outline-text-5" id="text-org416a749">
<p>
Unsupervised learning techniques are <b>prone to deception</b> by camouflage-like fraud strategies.<br />
They need to be complemented by other tools.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orgfaa11fa" class="outline-4">
<h4 id="orgfaa11fa">Supervised learning techniques</h4>
<div class="outline-text-4" id="text-orgfaa11fa">
<p>
learn from <b>labeled</b> historical observations, where the fraud was exposed.<br />
They can find known alarms that fraudsters cannot hide.<br />
</p>
</div>

<div id="outline-container-org8886152" class="outline-5">
<h5 id="org8886152">Limitations</h5>
<div class="outline-text-5" id="text-org8886152">
<ul class="org-ul">
<li>Low detection power against new fraud types<br /></li>
<li>Need a labeled set to learn from<br /></li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-org9f1b132" class="outline-3">
<h3 id="org9f1b132">Developing a fraud detection system</h3>
<div class="outline-text-3" id="text-org9f1b132">
<ol class="org-ol">
<li>Start with an Expert-based rule engine<br /></li>
<li>use a unsupervised learning system<br /></li>
<li>use a supervised learning system once you have build your labeled history<br /></li>
</ol>
<p>
The exact order of adoption depends from case to case.<br />
</p>
</div>
</div>

<div id="outline-container-org0334a0e" class="outline-3">
<h3 id="org0334a0e">Social Network Analysis</h3>
<div class="outline-text-3" id="text-org0334a0e">
<p>
Extends the abilities of fraud detection systems by detecting <span class="underline">characteristics of frauds between linked entities</span>.<br />
</p>
</div>
</div>

<div id="outline-container-org928d904" class="outline-3">
<h3 id="org928d904">Fraud management cycle</h3>
<div class="outline-text-3" id="text-org928d904">
<p>
you have to put together the following steps:<br />
</p>
<ol class="org-ol">
<li>fraud <b>detection</b> : applying detection models on new observations<br /></li>
<li>fraud <b>investigation</b> : human expert investigates on a flagged fraud<br /></li>
<li>fraud <b>confirmation</b> : determining the kind (label) of fraud<br /></li>
<li>fraud <b>prevention</b> : preventing frauds to be committed in the future by marking them as frauds faster and faster.<br /></li>
<li>Finally, you need to put an <b>automated detection algorithm</b> to create and update the detection model with the confirmed frauds.<br /></li>
</ol>
</div>

<div id="outline-container-org4365282" class="outline-4">
<h4 id="org4365282">Regular update of the model</h4>
<div class="outline-text-4" id="text-org4365282">
<p>
The <b>frequency</b> of update of your model depends on:<br />
</p>
<ul class="org-ul">
<li>the <span class="underline">volatility</span> of the fraud behavior<br /></li>
<li>the <span class="underline">detection power</span> of the model<br /></li>
<li>amount of <span class="underline">similar confirmed case available</span><br /></li>
<li>the <span class="underline">rate of new cases</span> being confirmed<br /></li>
<li>the <span class="underline">required effort</span> to retain the model<br /></li>
</ul>
</div>

<div id="outline-container-orgc8206a6" class="outline-5">
<h5 id="orgc8206a6">Reinforcement learning</h5>
<div class="outline-text-5" id="text-orgc8206a6">
<p>
Instead of waiting for a window to update the model, continuously update it as soon as new data is available.<br />
</p>
</div>
</div>
</div>
<div id="outline-container-orgfefb530" class="outline-4">
<h4 id="orgfefb530">Example: Credit card fraud</h4>
<div class="outline-text-4" id="text-orgfefb530">
<p>
<b>Outlier detection</b> is made by analyzing clusters of common transaction based on position and time.<br />
If a transaction happens outside of a group (it&rsquo;s an outlier), they might be a fraud.<br />
</p>

<p>
Users are analyzed in the same way at a system level, based on their age and income.<br />
An outlier might be a fraudster or a victim.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org298112a" class="outline-3">
<h3 id="org298112a">Fraud analytical process</h3>
<div class="outline-text-3" id="text-org298112a">
<p>
How to develop a <b>fraud analysis model</b>.<br />
</p>

<p>
The process is split in three main parts:<br />
</p>
<ul class="org-ul">
<li>preprocessing (the most important and time consuming)<br />
The performance of your model will strictly depend on this step.<br /></li>
<li>analytics<br /></li>
<li>post processing<br /></li>
</ul>
</div>

<div id="outline-container-org854d252" class="outline-4">
<h4 id="org854d252">Preprocessing</h4>
<div class="outline-text-4" id="text-org854d252">
<ul class="org-ul">
<li>identify the business problem<br /></li>
<li>identify the data sources<br /></li>
<li>select the data<br /></li>
<li>clean the data (gets rid of inconsistencies)<br /></li>
<li>transform the data (extract additional informations from the data)<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org042fd67" class="outline-4">
<h4 id="org042fd67">Analytics</h4>
<div class="outline-text-4" id="text-org042fd67">
<ul class="org-ul">
<li>Analyze the data. Here the <b>model is built</b> based on the data preprocessed.<br /></li>
</ul>
</div>

<div id="outline-container-org772c9ab" class="outline-5">
<h5 id="org772c9ab">Possible analysis outputs</h5>
<div class="outline-text-5" id="text-org772c9ab">
<ul class="org-ul">
<li>Find known easy frauds, that ensure the system is working<br /></li>
<li>Find unknown patterns, that provide added insight and detection power.<br /></li>
</ul>

<p>
In any case, you&rsquo;re going to work on <b>clusters</b>, and will be trying to extract knowledge from them.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orgcf31102" class="outline-4">
<h4 id="orgcf31102">Post processing phase</h4>
<div class="outline-text-4" id="text-orgcf31102">
<p>
Validate the model created with experts.<br />
</p>
</div>
</div>

<div id="outline-container-orgdb051eb" class="outline-4">
<h4 id="orgdb051eb">Key characteristics of successful fraud analtics models</h4>
<div class="outline-text-4" id="text-orgdb051eb">
<p>
To understand if your system is working I must monitor:<br />
</p>
<ul class="org-ul">
<li>statistical accuracy and significance<br />
Your system must generalize well and <span class="underline">must not be overfitted to the historical data set</span>.<br /></li>
<li>Interpretability<br />
You can put in place the state of art deep learning approach, but if the result of the analysis cannot be interpreted because the model is too complex (it tells us that a particular case might be a fraud, but it won&rsquo;t say why) it is unuseful.<br />
Such a non interpretable system is called <b>black-box</b>, while a system that can be interpreted is a <b>white-box</b> system.<br /></li>
<li>Operational efficiency<br />
The time and effort that is required to obtain a result and evaluate it is important, expecially on <i>real time system</i>.<br /></li>
</ul>
</div>
</div>
<div id="outline-container-org5df9df5" class="outline-4">
<h4 id="org5df9df5">Fraud management as risk management</h4>
<div class="outline-text-4" id="text-org5df9df5">
<p>
Every time we have to deploy a fraud management system, we must consider<br />
</p>
<ul class="org-ul">
<li>the value of the asset we want to protect<br /></li>
<li>the vulnerabilities<br /></li>
<li>the threats<br /></li>
<li><p>
the cost of the system (both direct and <span class="underline">indirect</span>)<br />
Indirect costs are mainly<br />
</p>
<ul class="org-ul">
<li>less usability for the user<br /></li>
<li>slower performance<br /></li>
<li>less privacy<br /></li>
<li>reduced productivity (users are slower)<br /></li>
</ul>
<p>
Direct costs are the equipment, its management and its operation.<br />
</p></li>
</ul>
</div>

<div id="outline-container-orgcb48a3c" class="outline-5">
<h5 id="orgcb48a3c">Economical cost</h5>
<div class="outline-text-5" id="text-orgcb48a3c">
<p>
Developing and implementing a fraud-detection model involves a significant cost to an organization.<br />
</p>

<p>
A cost-benefit analysis to understand the returns on investment that you gain with a fraud detection system.<br />
</p>

<p>
Moreover, now that the fraud-detection model should go under the <span class="underline">privacy regulations</span>, it&rsquo;s really difficult to put up a dataset big enough.<br />
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orga23917b" class="outline-3">
<h3 id="orga23917b">Challenges of developing fraud-detection models</h3>
<div class="outline-text-3" id="text-orga23917b">
<ul class="org-ul">
<li>Dynamic nature of frauds<br />
As previously seen, fraudsters will keep on trying to beat detection and prevention systems by developing new strategies and methods.<br />
We will need <span class="underline">adaptive</span> models for detection and prevention.<br /></li>
<li><b>Accuracy</b><br />
You don&rsquo;t want to miss on too many frauds, but you want to keep a low false alarm rate.<br />
All in all, the cost of missing a fraudolent case will probably be higher than marking a legit one as fraudolent.<br /></li>
<li><b>Skewness<sup><a id="fnr.2" class="footref" href="#fn.2">2</a></sup></b> of the data<br />
The number of fraudolent cases is small w.r.t. the number of legit ones.<br />
An analytical technique might have some difficulties in learning an accurate model.<br /></li>
<li><b>Time efficiency</b><br />
The model must be fast enough to reach a decision (fraudolent or not) in the time window before the next batch of transactions arrive.<br /></li>
<li><b>Big data</b> management<br />
The model must be able to deal with massive amounts of data.<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org6173ac9" class="outline-3">
<h3 id="org6173ac9">Red flags of frauds</h3>
<div class="outline-text-3" id="text-org6173ac9">
<p>
What we want to extract from an analysis are the &ldquo; <span class="underline">patterns</span> &rdquo; for frauds, to be used as the grounding truth for new fraud detection systems.<br />
</p>

<p>
This means translating the typical anomalies (called &ldquo;red flags&rdquo; here) of each kind of fraud into expert rules (after being documented) for rule based engines.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org78090d1" class="outline-2">
<h2 id="org78090d1">Machine Learning for Fraud Detection&#xa0;&#xa0;&#xa0;<span class="tag"><span class="Carminati">Carminati</span></span></h2>
<div class="outline-text-2" id="text-org78090d1">
<p>
In the previous section we focused on the fraud analisys and detection management part, where we studied how to counteract frauds.<br />
Let&rsquo;s now focus on how we can apply machine learning techniques in automatic fraud detection. (the more analytical part).<br />
</p>
</div>
<div id="outline-container-orgdeab08f" class="outline-3">
<h3 id="orgdeab08f">Notice</h3>
<div class="outline-text-3" id="text-orgdeab08f">
<p>
During the years, many techniques have been developed for fraud detection with ML from different disciplines.<br />
The main focus won&rsquo;t be on the technicalities of these techniques but on the fraud detection perspective.<br />
</p>
</div>
</div>
<div id="outline-container-org9d9f0a7" class="outline-3">
<h3 id="org9d9f0a7">Data preprocessing</h3>
<div class="outline-text-3" id="text-org9d9f0a7">
<p>
This part is where the experts lose 70% of their time.<br />
</p>
</div>

<div id="outline-container-org28b0f1d" class="outline-4">
<h4 id="org28b0f1d">Real data problems</h4>
<div class="outline-text-4" id="text-org28b0f1d">
<p>
When you&rsquo;re working on the theory, the more data you have the better.<br />
When we move to the real world though, this sentence is not so true anymore.<br />
</p>

<p>
The main motivation relies on the phrase &ldquo;garbage in, garbage out&rdquo;.<br />
It means that, if you have <span class="underline">messy data in your inputs, your analysis will yeld a messy model</span>.<br />
</p>

<p>
We need to <b>filter our data accordingly</b>. Even the slightest mistake can lead to invalid results.<br />
</p>
</div>
</div>

<div id="outline-container-org1e8381d" class="outline-4">
<h4 id="org1e8381d">Types of sources</h4>
<div class="outline-text-4" id="text-org1e8381d">
<p>
To fulfill an analysis, you need to know what data sources to acquire from.<br />
</p>

<p>
Data can be either <b>structured</b> (fits neatly in fixed fields) or <b>unstructured</b> (like data lakes).<br />
</p>

<p>
The main objective is to <b>find correlations between data sources</b>.<br />
</p>
</div>

<div id="outline-container-org9ef3772" class="outline-5">
<h5 id="org9ef3772">Transactional Data</h5>
<div class="outline-text-5" id="text-org9ef3772">
<p>
One kind of data source.<br />
It&rsquo;s composed of structured informations capturing the characteristics of a transaction from a customer.<br />
</p>

<p>
This kind of data is usually summarized to extract the <b>RFM value</b> (recency, frequency and monetary factors):<br />
</p>
<ul class="org-ul">
<li>the Recency factor focuses on the time passed from a transaction to the one before<br /></li>
<li>the Frequency factor focuses on the number of transactions made in the past<br /></li>
<li>the Monetary factorfocuses on the amount of each transaction.<br /></li>
</ul>

<p>
These features can be used individually or jointly, and their interaction can be used to detect frauds.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org6576fa0" class="outline-4">
<h4 id="org6576fa0">Types of data elements</h4>
<div class="outline-text-4" id="text-org6576fa0">
<p>
You can either have continuous data or categorical data:<br />
</p>
<ul class="org-ul">
<li><b>Continuous</b> data<br />
data elements are defined on an <span class="underline">interval</span> (limited or unlimited) (the amount of a transaction or its timestamp is an example)<br /></li>
<li><b>Categorical</b> data<br />
<ul class="org-ul">
<li><span class="underline">Nominal</span>: data elements that are <span class="underline">limited on a set of values</span> without ordering (iban; IP; motivation; region)<br /></li>
<li><span class="underline">Ordinal</span>: data elements <span class="underline">limited on a set</span> <span class="underline">with an ordering</span><br /></li>
<li><span class="underline">Binary</span>: data elements that <span class="underline">can only take two values</span>.<br /></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-org46ee181" class="outline-4">
<h4 id="org46ee181">Sampling</h4>
<div class="outline-text-4" id="text-org46ee181">
<p>
Sampling consists in taking a subset of the dataset available to build our data model.<br />
This step is needed because we need to <b>generalize</b> and <b>model the future</b>, and to do so we need to <b>focus more on newer data</b> (by taking more samples from newer time frames). A good sample must be <span class="underline">representative for the future</span>.<br />
</p>

<p>
When selecting a sample, you have to select the optimal time window, with a tradeoff between quantity of data and how recent it is.<br />
</p>

<p>
Your <b>average period</b> (the time window you selected) must also be as unbiased as possible, even if it&rsquo;s not straightforward.<br />
</p>
</div>

<div id="outline-container-org4292a15" class="outline-5">
<h5 id="org4292a15">Bias example</h5>
<div class="outline-text-5" id="text-org4292a15">
<p>
In holidays, users change their spending pattern.<br />
Not only that, but also the types of goods bought are different.<br />
</p>

<p>
Each single month might deviate from the average model.<br />
</p>

<p>
To mitigate this issue, we can<br />
</p>
<ul class="org-ul">
<li>build different models <i>for each month</i>.<br />
This is a complex and demanding solution, that does not scale well, but you have an updated and precise model of the customer.<br /></li>
<li>Sample observations over a period covering a full business cycle and build a single model instead.<br /></li>
</ul>

<p>
Sampling has a direct impact on the fraud detection power.<br />
</p>
</div>
</div>

<div id="outline-container-orgb2cd4a1" class="outline-5">
<h5 id="orgb2cd4a1">Stratified sampling</h5>
<div class="outline-text-5" id="text-orgb2cd4a1">
<p>
To make a <i>stratified sample</i> means to <b>keep some properties</b> (found in the data) <b>valid</b> in the sample taken.<br />
</p>

<p>
When doing sampling, you might want to extract samples taking into consideration:<br />
</p>
<ul class="org-ul">
<li>a target for an indicator (<i>bank example</i>: private customer or company have different variability in their destination ibans; we might want to keep this variability intact after our sampling; <i>general example</i>: keep the percentage of fraudolent and non fraudolent transactions the same)<br /></li>
<li>a variable for a predictor<br /></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org6482603" class="outline-4">
<h4 id="org6482603">Visual data exploration</h4>
<div class="outline-text-4" id="text-org6482603">
<p>
First informal step after sampling.<br />
You basically analyze the distribution of data visually (through charts) to find its properties.<br />
</p>
</div>
</div>

<div id="outline-container-org5ec6e13" class="outline-4">
<h4 id="org5ec6e13">Exploratory statistical Analysis</h4>
<div class="outline-text-4" id="text-org5ec6e13">
<p>
Some <b>statistical measurements</b> (average, standard deviation etc.) can be made on the data to extract some properties.<br />
</p>

<p>
Some fitting of the distribution of the data can help to understand other characteristics about it.<br />
</p>
</div>
</div>

<div id="outline-container-org4edb166" class="outline-4">
<h4 id="org4edb166">Dealing with missing values</h4>
<div class="outline-text-4" id="text-org4edb166">
<p>
Missing values can either have been omitted (due to information being non applicable or undisclosed) or simply be missing due to an error.<br />
</p>

<p>
When an observation with missing values is encountered you can:<br />
</p>
<ul class="org-ul">
<li><span class="underline">Replace</span> the missing value with a default one.<br /></li>
<li><span class="underline">Delete</span> it, if the number of missing values is too high.<br /></li>
<li><span class="underline">Keep</span> the missing values, since they might have a relation with frauds.<br />
<ul class="org-ul">
<li>In this case, it should be tested wether the missing info is related to a variable (e.g: two factor authentication) or not.<br />
If it&rsquo;s not the case, another of the two methods can be applied.<br /></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgf0d1baf" class="outline-4">
<h4 id="orgf0d1baf">Outliers</h4>
<div class="outline-text-4" id="text-orgf0d1baf">
<p>
Outliers are extreme values that are dissimilar to the rest of the population.<br />
Some of these values might be legitimate (or they might be the result of invalid observations).<br />
The methods to find them will be described in more depth later on (see the sections on <a href="#org4990014">Outliers detection</a>)<br />
</p>

<p>
They can be either:<br />
</p>
<ul class="org-ul">
<li><span class="underline">Univariate</span>, if they are outlying on one dimension.<br />
<b>Visual data exploration</b> is able to find out most of this kind of outliers, through different views (histograms, box plots).<br />
One additional method is looking at <b>Z-scores</b>, an index that measure how many standard deviations an observation lies away from the mean.<br /></li>

<li><span class="underline">Multivariate</span>, if they are outlying on multiple dimensions.<br />
Other methods (namely fitting regression lines and mahalanobis distance) are used to find this kind of outlying values.<br /></li>
</ul>
</div>

<div id="outline-container-orga9b448b" class="outline-5">
<h5 id="orga9b448b">Outlier treatment</h5>
<div class="outline-text-5" id="text-orga9b448b">
<p>
If an outlier is an invalid observation, you can treat it as a missing value.<br />
For valid observation, you can impose a range of values that do not modify your mean too much and put the outlier at one of the extremes.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org0ae3f95" class="outline-4">
<h4 id="org0ae3f95">When invalid data is not outlying</h4>
<div class="outline-text-4" id="text-org0ae3f95">
<p>
Sometimes, invalid values are not outliers though.<br />
</p>

<p>
For example: a customer with birth date 01/01/1980 and classified as a child is not an outlier (there might be many child customers and many customers born the same day), but it is clearly an invalid value.<br />
</p>

<p>
To remove such inconsistencies, a set of checks is made to find wether your data is <span class="underline">coherent</span> or not.<br />
</p>

<p>
To impose these checks you need the help of experts.<br />
</p>
</div>
</div>

<div id="outline-container-org12ce6c8" class="outline-4">
<h4 id="org12ce6c8">Conclusion on outliers and invalid values</h4>
<div class="outline-text-4" id="text-org12ce6c8">
<p>
Every single time you have to treat outliers and invalid values you must be really cautious when using the previous techniques, since these methods will impact the performance of your system (by removing the outliers, for example, you could lose some frauds).<br />
</p>
</div>
</div>

<div id="outline-container-org5663310" class="outline-4">
<h4 id="org5663310">Standardization</h4>
<div class="outline-text-4" id="text-org5663310">
<p>
Standardizatoin consists in <b>scaling variables to a similar range</b>. This step is <span class="underline">heavily affected by outliers</span>.<br />
You must always use common standardization methods.<br />
</p>
</div>
</div>

<div id="outline-container-orgf957aad" class="outline-4">
<h4 id="orgf957aad">Categorization</h4>
<div class="outline-text-4" id="text-orgf957aad">
<p>
To confront <i><a href="#org6576fa0">categorical values</a></i> , they must first be <span class="underline">transformed</span> to reduce their number of categories.<br />
For example, IBANs and IPs could be categorized by their frequency (this process would make them comparable).<br />
</p>
</div>
</div>

<div id="outline-container-org8ba1d01" class="outline-4">
<h4 id="org8ba1d01">Variable Selection</h4>
<div class="outline-text-4" id="text-org8ba1d01">
<p>
A dataset is composed by hundreds of features.<br />
On a detection model, there are usually 10-15 of them.<br />
Which features to select in a model is a challenging task by itself.<br />
</p>
</div>

<div id="outline-container-orge86d461" class="outline-5">
<h5 id="orge86d461">Filters</h5>
<div class="outline-text-5" id="text-orge86d461">
<p>
Filters are used to <span class="underline">understand the informations each variable gives to the model</span>.<br />
They are standardized (pearson correlation, fisher score etc.), but they are not meant to be your only analysis step.<br />
</p>

<p>
Their main limitation is that you usually work variable by variable, without considering possible correlations between them.<br />
</p>
</div>
</div>

<div id="outline-container-orgc73e210" class="outline-5">
<h5 id="orgc73e210">Wrapper</h5>
<div class="outline-text-5" id="text-orgc73e210">
<p>
Instead of having to select my features at the beginning, I only give in input different set of features and see what the more promising sets are.<br />
</p>
</div>
</div>

<div id="outline-container-org58e392b" class="outline-5">
<h5 id="org58e392b">Principal Components Analysis</h5>
<div class="outline-text-5" id="text-org58e392b">
<p>
Try to reduce the number of variables by computing new variables, called <b>principal components</b>, that are <span class="underline">not correlated one another</span> and are <span class="underline">linear correlations of the original variables</span> .<br />
</p>

<p>
This transformation is extremely helpful for your analysis because they keep the informations of the variables while reducing the number of features to analyze.<br />
Moreover, even if they do not reduce the number of variables, they can bring out some more interesting features.<br />
</p>

<p>
PCA can help to make variables more robust.<br />
But the new variables made might be not as interpretable than the original ones.<br />
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgc8541b9" class="outline-3">
<h3 id="orgc8541b9">Descriptive analytics for fraud detection</h3>
<div class="outline-text-3" id="text-orgc8541b9">
<p>
<b>Unsupervised learning techniques</b> are used to <span class="underline">find anomalies</span> deviating from the norm. The main challenge is defining the norm; To do so, we use <b>descriptive analytics</b>.<br />
Two possibilities (with different levels of granularity):<br />
</p>
<ul class="org-ul">
<li>Behavior of the average customer (global perspective)<br /></li>
<li>average behavior of a given customer (local perspective)<br /></li>
</ul>

<p>
The <b>supervised learning technique</b> (based on <i>predictive analytics</i>), on the other hand, assumes you have labels available and can only detect known fraud patterns.<br />
Besides these limitations, they are usually useful to <span class="underline">understand the anomalies you found</span> on unsupervised analyses.<br />
</p>
</div>

<div id="outline-container-org3f48fe8" class="outline-4">
<h4 id="org3f48fe8">Relevant environments for Unsupervised learning</h4>
<div class="outline-text-4" id="text-org3f48fe8">
<p>
The use of Unsupervised learning techniques is particularly useful:<br />
</p>
<ul class="org-ul">
<li>In case of organizations <span class="underline">starting</span> to do fraud detection, with no data set available.<br /></li>
<li>When you have a dataset, but it is not labeled yet (the labeling process might take time).<br /></li>
<li>When fraud patterns change fast and are not reused commonly.<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org3cdc1d4" class="outline-4">
<h4 id="org3cdc1d4">Defining the norm</h4>
<div class="outline-text-4" id="text-org3cdc1d4">
<p>
<i>The norm</i> <b>depends on the context</b> you are analyzing.<br />
It is a boundary (a threshold) that, due to the nature of frauds (continuously changing), will have to adapt.<br />
Moreover, the boundary is not a clear cut: some anomalies might be legit transaction, while some apparently normal transactions might be frauds.<br />
</p>

<p>
Even if you obtain good results on the tests, you must be able to make your system evolve - and the norm will change with it.<br />
</p>
</div>
</div>

<div id="outline-container-org4990014" class="outline-4">
<h4 id="org4990014">Graphical outliers detection</h4>
<div class="outline-text-4" id="text-org4990014">
<p>
Ideal tools to explore the data and get preliminary insights.<br />
</p>

<p>
It has some disadvantages though:<br />
</p>
<ul class="org-ul">
<li>Unformal.<br /></li>
<li>Not easily automatable.<br /></li>
<li>Limited to few dimensions.<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org6c0a026" class="outline-4">
<h4 id="org6c0a026">Statistical outliers detection</h4>
<div class="outline-text-4" id="text-org6c0a026">
<p>
Some statistical methods are applied to detect frauds:<br />
</p>
<ul class="org-ul">
<li><b>Z-score</b><br />
Seen before when we talked about <a href="#orgf0d1baf">outliers</a>.<br /></li>
<li><b>Break point analysis</b><br />
Detects <span class="underline">intra-account</span> (in the same account) frauds<br /></li>
<li><b>Peer group analysis</b><br />
Detects <span class="underline">inter account</span> frauds<br /></li>
<li><b>Association rule</b><br />
Detects <span class="underline">single transaction</span> frauds<br />
Belongs mainly to the data mining world.<br /></li>
</ul>

<p>
These techniques are differentiated mainly by the granularity with wich you want to make the analysis.<br />
</p>
</div>

<div id="outline-container-orgf53bb67" class="outline-5">
<h5 id="orgf53bb67">Break point analysis</h5>
<div class="outline-text-5" id="text-orgf53bb67">
<p>
Detects sudden changes in the account behavior (called <b>Break point</b>).<br />
The method is quite simple:<br />
</p>
<ol class="org-ol">
<li>define a fixed time window<br /></li>
<li>split the parts into &ldquo;old&rdquo; and &ldquo;new&rdquo;<br /></li>
<li>compare them<br />
This comparation is usually made with <i>t-score</i>, a metric that measures how much (and how fast) a value changed in a time window.<br /></li>
</ol>
</div>
</div>

<div id="outline-container-org6b1b419" class="outline-5">
<h5 id="org6b1b419">Peer Group analysis</h5>
<div class="outline-text-5" id="text-org6b1b419">
<p>
The main goal is to define the <span class="underline">peer group</span> (group of <b>similarly behaving accounts</b>) of an account.<br />
</p>

<p>
When the behavior of the target deviates from his peer group, an anomaly is detected.<br />
</p>

<p>
It is <span class="underline">more computational intensive</span> than break point analysis.<br />
</p>

<p>
Peer group analysis <b>can help with new accounts</b>, by approximating their spending profile with their peer group.<br />
</p>

<p>
The update of the patterns is usually done weekly or monthly, due to the fraudolent pattern changing in a couple of months.<br />
</p>
</div>


<div id="outline-container-org6459af1" class="outline-6">
<h6 id="org6459af1">Identifying, sizing and comparing a peer group</h6>
<div class="outline-text-6" id="text-org6459af1">
<p>
To identify a peer group we can use 2 methods:<br />
</p>
<ul class="org-ul">
<li>exploit business knowledge.<br /></li>
<li>Define a statistical metric to define the peers<br /></li>
</ul>

<p>
How many peers should you consider?<br />
</p>
<ul class="org-ul">
<li>few peers: more scalable (the performance loss is quadratic to the number of peers), but sensitive to noise.<br /></li>
<li>many peers: less scalable, but less sensitive to noide (a group too broad can lead to insensitivity to the deviations).<br /></li>
</ul>

<p>
How do you compare the behavior of the target w.r.t. the peers?<br />
</p>
<ul class="org-ul">
<li>statistical test<br /></li>
<li>distance metric<br /></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org66617a6" class="outline-5">
<h5 id="org66617a6">Break point analysis vs peer group analysis</h5>
<div class="outline-text-5" id="text-org66617a6">
<p>
The two are complementary: you must use both at different times.<br />
E.g. for the holidays, break point analysis performs poorly: people spend more, resulting in an anomaly.<br />
With Peer group analysis, instead, all peers will shift to higher amounts, not causing an anomaly.<br />
</p>

<p>
Both these analyses, though, will <span class="underline">detect only local modifications</span> (local to an account/peer group).<br />
</p>
</div>
</div>

<div id="outline-container-orgdd5d78b" class="outline-5">
<h5 id="orgdd5d78b">Association rule analysis</h5>
<div class="outline-text-5" id="text-orgdd5d78b">
<p>
Detects frequent occurring <b>relationships between items</b>.<br />
An association rule is an implication X &rArr; Y, where both X and Y are subsets of data from the same set with <span class="underline">no common elements</span>.<br />
X is called <i>antecedent</i> and Y is called <i>consequent</i>.<br />
</p>

<p>
This kind of analysis was initially used for basket market<sup><a id="fnr.3" class="footref" href="#fn.3">3</a></sup> analysis, to understand which items were bough together.<br />
Supermarkets would decide which items to put near each other in an isle this way.<br />
</p>
</div>

<div id="outline-container-org057958d" class="outline-6">
<h6 id="org057958d">Support</h6>
<div class="outline-text-6" id="text-org057958d">
<p>
The frequency of an item set is measured by means of its <b>support</b>, which is the percentage of total transaction in the database that contains the item set.<br />
</p>
\begin{equation*}
support(x): \frac{\text{number of transactions that support } x}{\text{total number of transactions}}
\end{equation*}

<p>
Based on this function, we can identify the <b>frequent item set</b> , which will be then useful to derive the association rules.<br />
</p>
</div>
</div>

<div id="outline-container-orga783a0a" class="outline-6">
<h6 id="orga783a0a">Confidence</h6>
<div class="outline-text-6" id="text-orga783a0a">
<p>
Measures the <span class="underline">strength of the association</span>.<br />
It&rsquo;s defined as the probability of the rule consequent given the rule antecedent.<br />
</p>
\begin{equation*}
confidence(x \Rightarrow y): \frac{support(x \cup y)}{support (x)}
\end{equation*}
</div>
</div>
</div>
</div>
<div id="outline-container-org74119c4" class="outline-4">
<h4 id="org74119c4">Clustering</h4>
<div class="outline-text-4" id="text-org74119c4">
<p>
The goal of this analysis method is to <b>group the observations to find the norm</b>.<br />
These groups should maximize the <span class="underline">homogeneity between elements in the same group</span> and maximize the <span class="underline">etherogeneity between different groups</span>.<br />
</p>

<p>
The general idea is that the norm will be characterized by big dense clusters, while anomalies will be small clusters far from the normal ones.<br />
</p>
</div>

<div id="outline-container-orgc8c3c45" class="outline-5">
<h5 id="orgc8c3c45">Kinds of clusters</h5>
<div class="outline-text-5" id="text-orgc8c3c45">
<p>
Clusters can be either:<br />
</p>
<ul class="org-ul">
<li>Hierarchical<br />
<ul class="org-ul">
<li>Agglomerative<br /></li>
<li>Divisive<br /></li>
</ul></li>
<li>Nonhierarchical<br />
<ul class="org-ul">
<li>k-means<br /></li>
<li>Self Organizing Maps<br /></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-orgdab6fad" class="outline-5">
<h5 id="orgdab6fad">Measure the similarity of elements</h5>
<div class="outline-text-5" id="text-orgdab6fad">
<p>
To measure the similarity of elements <b>distance metrics</b> are used.<br />
There are many of them and it should be used whichever suits the dataset best.<br />
</p>

<p>
Euclidean distance is used commonly at the beginning for its simplicity.<br />
</p>
</div>
</div>

<div id="outline-container-org5aa9585" class="outline-5">
<h5 id="org5aa9585">Hierarchical clustering</h5>
<div class="outline-text-5" id="text-org5aa9585">
<p>
In <b>divisive clustering</b> techniques, the dataset is initially considered as a <span class="underline">unique cluster</span>, to be divided later on.<br />
In <b>agglomerative clustering</b> techniques, every element is considered as a <span class="underline">single point cluster</span>, to be aggregated with other clusters later on.<br />
</p>
</div>

<div id="outline-container-org8d00bf7" class="outline-6">
<h6 id="org8d00bf7">Distance between clusters</h6>
<div class="outline-text-6" id="text-org8d00bf7">
<p>
There are different ways to compute the <b>distance between clusters</b>, too.<br />
</p>
<ul class="org-ul">
<li><span class="underline">single linkage</span>: select the nearest points of two clusters and compute the distance.<br /></li>
<li><span class="underline">complete linkage</span>: select the farthest points of two clusters and compute the distance.<br /></li>
<li><span class="underline">average linkage</span>: average the distance of all the points of the two clusters.<br /></li>
<li><span class="underline">centroid linkage</span>: compute the distance of the centroid of the two clusters.<br /></li>
<li><span class="underline">\(d_{ward}\) distance</span>: compare the difference between the similarity of having the two clusters separated and having the two clusters joined.<br /></li>
</ul>

<p>
Depending on this selection, all your results will be different.<br />
</p>
</div>
</div>

<div id="outline-container-orgd7e3dca" class="outline-6">
<h6 id="orgd7e3dca">Select the number of clusters</h6>
<div class="outline-text-6" id="text-orgd7e3dca">
<p>
The selection of the number of clusters is <b>made through visualization</b>. Two techniques are used:<br />
</p>
<ul class="org-ul">
<li><span class="underline">dendograms</span>: temporal timeline of the construction of your clusters. You can cut the tree at the similarity level you want to have to generate your clusters.<br /></li>
<li><span class="underline">screen plot</span>: plot the distance at which clusters are merged and the number of clusters, then find the &ldquo;elbow&rdquo; of the curve: that point is where to stop.<br /></li>
</ul>
</div>
</div>

<div id="outline-container-orge4d58f3" class="outline-6">
<h6 id="orge4d58f3">Advantages and disadvantages</h6>
<div class="outline-text-6" id="text-orge4d58f3">
<p>
Advantages:<br />
</p>
<ul class="org-ul">
<li>the number of clusters does not need to be specified<br /></li>
</ul>

<p>
Disadvantages:<br />
</p>
<ul class="org-ul">
<li>the interpretation of the clusters must be made with knowledge of the business logic.<br /></li>
<li>these techniques do not scale really well with large clusters.<br /></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org337bb49" class="outline-5">
<h5 id="org337bb49">Nonhierarchical clustering</h5>
<div class="outline-text-5" id="text-org337bb49">
</div>

<div id="outline-container-org96c7640" class="outline-6">
<h6 id="org96c7640">k-means</h6>
<div class="outline-text-6" id="text-org96c7640">
<p>
Follow these steps:<br />
</p>
<ul class="org-ul">
<li>select k random observations (&ldquo;seeds&rdquo;) as &ldquo;centroids&rdquo; of the clusters you are going to create<br />
<ul class="org-ul">
<li>It is already evident a <i>problem</i>: how much is k? You have to choose it beforehand.<br /></li>
</ul></li>
<li>assign each observation to the cluster with the closest centroid<br /></li>
<li>when all observations are assigned, recalculate the centroids of each cluster and repeat the assignment.<br /></li>
<li>repeat until the centroids are stable or a limit is reached.<br /></li>
</ul>

<p>
This method is sensitive to outliers.<br />
</p>
</div>
</div>

<div id="outline-container-org8cd194e" class="outline-6">
<h6 id="org8cd194e">Self organizing maps</h6>
<div class="outline-text-6" id="text-org8cd194e">
<p>
Feed forward neural network with two layers (input and output).<br />
Allows to <span class="underline">visualize and cluster high dimensional nets on 2 layer neural networks</span>.<br />
</p>

<p>
Each input is connected to every possible output.<br />
When a training vector X is presented, it is compared to each neuron&rsquo;s training vector.<br />
The most similar neuron is the Best Matching Unit; It and its &ldquo;neighbors&rdquo; are &ldquo;adapted&rdquo;.<br />
The neighbors are defined with a function (\(h_{ci}\)).<br />
</p>

<p>
You&rsquo;re technically trying to update the network and aggregate the nearest points to the best matching unit.<br />
As always, you continue until your BMU remains stable or for a fixed number of iteration.<br />
</p>

<p>
They are quite helpful because:<br />
</p>
<ul class="org-ul">
<li>Once you have selected the output, they are basically automatic<br /></li>
<li>They allow you to represent the results you have obtained with two techniques:<br />
<ul class="org-ul">
<li>Unified distance Matrix (also called U-Matrix)<br />
visualizes the distance between a neuron and its neighbors; Large distances (darker colors) can be interpreted a cluster boundaries.<br /></li>
<li>Component plane<br />
visualizes the contribution of each input attribute to each neuron.<br /></li>
</ul></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org6329caf" class="outline-5">
<h5 id="org6329caf">Semi-Supervised clustering</h5>
<div class="outline-text-5" id="text-org6329caf">
<p>
Incorporates background knowledge to guide the clustering, by putting some constraints on how the clusters are formed.<br />
These can be put at different levels:<br />
</p>
<ul class="org-ul">
<li>observation-level constraints: put constraints between single entities (these entities must/mustn&rsquo;t link together)<br /></li>
<li>Cluster level constraints: impose a certain level of similarity between the clusters<br /></li>
<li>other constraints<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org5cb7fcd" class="outline-5">
<h5 id="org5cb7fcd">One-class SVM</h5>
<div class="outline-text-5" id="text-org5cb7fcd">
<p>
Try to maximize the distance between norm and anomalies: try to separate theme with a linear hyperplane (the anomalies are then the ones near the origin of your graph).<br />
</p>
</div>
</div>

<div id="outline-container-orgc6eae08" class="outline-5">
<h5 id="orgc6eae08">Evaluation of clustering solutions</h5>
<div class="outline-text-5" id="text-orgc6eae08">
<p>
There&rsquo;s <span class="underline">no universal criterion</span> to evaluate which clustering is better, but a commonly used solution is the <b>sum of Squared Errors</b>.<br />
</p>

<p>
Another one is to analyze them graphically and confront them.<br />
</p>

<p>
Finally, another one is to train a supervised learning method on the basis of the results of the unsupervised learning one.<br />
The unsupervised one will tell you the clustering, the supervised might lead you to the reasons behind those clusters.<br />
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orga913516" class="outline-3">
<h3 id="orga913516">Predictive analytics for fraud detection</h3>
<div class="outline-text-3" id="text-orga913516">
<p>
The aim of these analytics is to build a model to <b>predict a variable of interest</b> (it will be called <span class="underline">target variable</span> from now on).<br />
The real value that the target assumes from our prediction is then used to steer the learning process.<br />
</p>

<p>
This target variable is usually a fraud indicator (so the resulting model is trained to recognize frauds); This means it is inherently hard to obtain and determine.<br />
</p>

<p>
Two kinds of predictive analysis can be distinguished depending on the type of variable we want to predict:<br />
</p>
<ul class="org-ul">
<li><b>Regression</b>: used for <span class="underline">continuous</span> variables (with a possibly unlimited set of values).<br /></li>
<li><b>Classification</b>: used for <span class="underline">categorical</span> variables (but with a limited set of values).<br /></li>
</ul>
</div>

<div id="outline-container-orgb0a85f6" class="outline-4">
<h4 id="orgb0a85f6">Linear regression</h4>
<div class="outline-text-4" id="text-orgb0a85f6">
<p>
One of the many kinds of regression.<br />
</p>

<p>
The target variable is seen as a combination of <b>explanatory variables</b>, with a certain weigth \(\beta_{i}\) assigned to each of them that measures the impact of the explanatory variable on the target variable.<br />
</p>

<p>
These parameters \(\beta_{i}\) must be estimated through the <span class="underline">minimization of squared error function</span>, a function that gives you an indication of how wrong your prediction was w.r.t. the actual value of the target variable.<br />
</p>

<p>
It has some limitation though:<br />
</p>
<ul class="org-ul">
<li>The target variable is considered to be a continuous variable normally distributed, but it might not be (for example, it might be a boolean variable with a bernoully distribution)<br /></li>
<li>We might not have enough informations about the variable to move it to a continuous range (in the bernoulli case covered above, we could interpret it as a probability if we had enough informations about it).<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org653a6f9" class="outline-4">
<h4 id="org653a6f9">Logistic regression</h4>
<div class="outline-text-4" id="text-org653a6f9">
<p>
Another kind of regression.<br />
</p>

<p>
A <b>logistic regression</b> is just the <span class="underline">combination of a linear regression and a bounding function</span> (a function that limits the prediction values to a smaller interval).<br />
</p>

<p>
The parameters of a logistic regression model are estimated using a maximum likelihood optimization.<br />
</p>

<p>
With a logistic regression model we are able to predict boolean variables, such as a variable that represents the question &ldquo;<i>is this observation fraudolent?</i>&rdquo;.<br />
</p>

<p>
To decide wether a response is positive or not we use an <b>activation function</b>, that maps our obtained prediction (already bounded between 0 and 1 thanks to the bunding function) to a positive or a negative answer.<br />
</p>

<p>
By training our model through logistic regression on a labeled set, we can find the combinatoin of variables that gives us a response to the question accurately enough.<br />
</p>
</div>
</div>

<div id="outline-container-orgb5b5c7a" class="outline-4">
<h4 id="orgb5b5c7a">Decision trees</h4>
<div class="outline-text-4" id="text-orgb5b5c7a">
<p>
A classification method of training.<br />
We use a <b>tree like structure</b> to <span class="underline">label our observations</span>.<br />
In the leaf nodes you have the assignment of labels (fraud/not fraud).<br />
In each node you have a testing condition to move to lower nodes.<br />
</p>

<p>
Decision trees are defined by three &ldquo;decisions&rdquo; (<i>sorry for the play on words</i>):<br />
</p>
<ol class="org-ol">
<li><span class="underline">splitting decision</span> (which variable do we split? at which value?)<br /></li>
<li><span class="underline">stopping decision</span> (when do we add a leaf node?)<br /></li>
<li><span class="underline">assignment decision</span> (which label do you assign to the group in the current leaf?)<br /></li>
</ol>
</div>

<div id="outline-container-org41f0e05" class="outline-5">
<h5 id="org41f0e05">Splitting decision</h5>
<div class="outline-text-5" id="text-org41f0e05">
<p>
First of all, we define <b>impurity</b> as the diversity on our dataset.<br />
When our dataset is composed of half/half (of a specific condition), we have maximal impurity.<br />
When out dataset is composed of only one kind, we have minimal impurity.<br />
</p>

<p>
The variable to do the splitting decision on is chosen by looking at the <span class="underline">highest reduction of impurity</span>.<br />
</p>
</div>
</div>

<div id="outline-container-org5f80c15" class="outline-5">
<h5 id="org5f80c15">Stopping decision</h5>
<div class="outline-text-5" id="text-org5f80c15">
<p>
If we split too much, we tend to <span class="underline">overfit</span> (consider, other than the data we are interested in, also noise).<br />
</p>

<p>
To avoid overfitting and find the best spot to stop splitting, our dataset should be divided in:<br />
</p>
<ul class="org-ul">
<li>training set (on which we make the splitting decisions)<br /></li>
<li>validation set (a labeled sample to monitor the misclassification error)<br /></li>
<li>testing set (a independent sample to test our decision tree)<br /></li>
</ul>

<p>
You can then plot the misclassification error on the validation set wrt the number of tree nodes.<br />
Once the misclassification error is at its minimum, we can then say to stop the creation of new nodes at that point and, instead, start the creation of leaves.<br />
</p>
</div>
</div>

<div id="outline-container-orgd2cc20b" class="outline-5">
<h5 id="orgd2cc20b">Advantages</h5>
<div class="outline-text-5" id="text-orgd2cc20b">
<p>
Decision trees are useful because they are <span class="underline">easy to build</span>.<br />
Moreover, they are a <span class="underline">white-box method</span>: you can convert a decision tree into a set of <a href="#org8903fc1">decision rules</a> easily (the ones that fraud detection expert based systems use), since you have the conditions on each node.<br />
</p>
</div>
</div>

<div id="outline-container-org3cf328a" class="outline-5">
<h5 id="org3cf328a">Disadvantages</h5>
<div class="outline-text-5" id="text-org3cf328a">
<p>
Decision trees tends to overfit the data, but we could use cross validation to reduce this.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org70d8417" class="outline-4">
<h4 id="org70d8417">Regression trees</h4>
<div class="outline-text-4" id="text-org70d8417">
<p>
You can also predict continuous targets with decision trees (for example, you can give the <i>probability</i> of a transaction being a fraud) and transform them into a <span class="underline">regression method</span>.<br />
</p>
</div>
</div>

<div id="outline-container-org4bd7d25" class="outline-4">
<h4 id="org4bd7d25">Neural Networks</h4>
<div class="outline-text-4" id="text-org4bd7d25">
<p>
Generalization of existing statistical models.<br />
The basic element of a Neural network is the <b>neuron</b>: it takes an input, multiplies it by a weight and puts it into a <i>transformation function</i> (can be a logistic regression).<br />
</p>
</div>

<div id="outline-container-org9968353" class="outline-5">
<h5 id="org9968353">Layers</h5>
<div class="outline-text-5" id="text-org9968353">
<p>
The neural networks presented during lesson are composed of 3 layers:<br />
</p>
<ul class="org-ul">
<li><span class="underline">Input layer</span><br /></li>
<li><span class="underline">Hidden layer</span>, which combines the inputs into features.<br /></li>
<li><span class="underline">Output layer</span>, which linearly transforms the features given by the hidden layer.<br /></li>
</ul>

<p>
Usually, each layer has <span class="underline">its own transformation function</span> (common to all the nodes in the layer).<br />
Neural networks can be used both as a <span class="underline">regression analysis</span> method and a <span class="underline">classification analysis</span> method, depending on the transformation function used in the output layer.<br />
</p>
</div>
</div>

<div id="outline-container-orge25e6e2" class="outline-5">
<h5 id="orge25e6e2">Weigth learning</h5>
<div class="outline-text-5" id="text-orge25e6e2">
<p>
To optimize a neural network, we use an iterative algorithm that optimizes a <b>cost function</b> to find the best assignments to the weights of each neuron.<br />
</p>

<p>
The cost function used might have <span class="underline">multiple minimas</span>, that could get you stuck on a result that is not optimal.<br />
To avoid this, we usually do the optimization with <span class="underline">multiple initial random set of weigths</span> and select only the one with the global minimum after some steps.<br />
</p>
</div>
</div>

<div id="outline-container-org023a6dc" class="outline-5">
<h5 id="org023a6dc">How many hidden neurons?</h5>
<div class="outline-text-5" id="text-org023a6dc">
<p>
The number of hidden neurons to use depends on the non linearity of the dataset.<br />
The more complex are the patterns we need to model, the more neurons we will need.<br />
</p>

<p>
The procedure to select the number of neurons is basically the same seen to select the number of nodes in Decision trees (called, in that context, the <a href="#org5f80c15">stopping decision</a>):<br />
</p>
<ol class="org-ol">
<li>Split the data into <span class="underline">training</span>, <span class="underline">validation</span> and <span class="underline">test</span> set<br /></li>
<li>train multiple neural networks on the training set with different numbers of neurons.<br /></li>
<li>measure the performance of each network on the validation set.<br /></li>
<li>choose the most performant neural network<br /></li>
<li>measure its actual performance on the independent test set.<br /></li>
</ol>
</div>
</div>

<div id="outline-container-org1dd4255" class="outline-5">
<h5 id="org1dd4255">The overfitting problem</h5>
<div class="outline-text-5" id="text-org1dd4255">
<p>
To avoid overfitting, we can use two techniques<br />
</p>
<ul class="org-ul">
<li><span class="underline">Weigth regularization</span>: we put an upper bound on the weigths of the neural net.<br /></li>
<li>The usual method: we estimate the weigth and use independent data sets of the same pool to decide when to stop training to avoid overfitting.<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org82070ba" class="outline-5">
<h5 id="org82070ba">Neural Networks lack interpretability</h5>
<div class="outline-text-5" id="text-org82070ba">
<p>
It is extremely difficult to find out why a certain output is given from certain inputs, which makes the <span class="underline">extraction of rules complex</span>.<br />
</p>

<p>
They are, though, generally more performant than the other methods seen.<br />
</p>
</div>

<div id="outline-container-org4e52c4e" class="outline-6">
<h6 id="org4e52c4e">Variable selection in Neural Networks</h6>
<div class="outline-text-6" id="text-org4e52c4e">
<p>
To find out which variables contribute actively to the outputs of the neural network, we must visualize the interaction between the inputs (our variables, like &ldquo;the age of the customer&rdquo; and &ldquo;the amount claimed by the insurance company&rdquo;) and the rest of the network.<br />
</p>

<p>
To do so, we use <span class="underline">Hinton Diagrams</span>, where we visualize the weigths between inputs and hidden neurons as squares and interpret them.<br />
</p>

<p>
Another way is <span class="underline">Backward variable selection</span>:<br />
We build a neural network with all the variables in input, then we recreate the network with one variable less to see how much the performance is impacted (those variables that don&rsquo;t hinder the performance of the network can be removed, since they add complexity).<br />
</p>
</div>
</div>

<div id="outline-container-org8429ad9" class="outline-6">
<h6 id="org8429ad9">Extracting rules from Neural Networks</h6>
<div class="outline-text-6" id="text-org8429ad9">
<p>
To extract the rules to be fed to a rule based engine, we can use two techniques:<br />
</p>
<ul class="org-ul">
<li><span class="underline">Decompositional rule extraction</span>, where we find the activation values of the hidden neurons (with clustering, for example) and join them in a single boolean rule.<br /></li>
<li>Pedagogical rule extraction: use the labels produced by the Neural Network as the training set for a white box method (like decision trees), where the rules are simpler to extract.<br /></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org7de3f9e" class="outline-5">
<h5 id="org7de3f9e">Two stage model setup</h5>
<div class="outline-text-5" id="text-org7de3f9e">
<p>
Instead of directly using a Neural network, we can estimate a simpler model with a more interpretable method (like linear/logistic regression) and, then, use a neural network to predict the errors made by the model and adjust the parameters of the linear model.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org5b137bd" class="outline-4">
<h4 id="org5b137bd">Support Vector Machines</h4>
<div class="outline-text-4" id="text-org5b137bd">
<p>
Based on linear programming<sup><a id="fnr.4" class="footref" href="#fn.4">4</a></sup> (define an objective function and put some constraints on it).<br />
It&rsquo;s a <span class="underline">classification method</span>, but it can also be applied as a regression method.<br />
</p>
</div>

<div id="outline-container-org0b0a67b" class="outline-5">
<h5 id="org0b0a67b">Benefits</h5>
<div class="outline-text-5" id="text-org0b0a67b">
<p>
In linear programming, it&rsquo;s <span class="underline">easy to introduce business knowledge</span> (simply add constraints).<br />
</p>
</div>
</div>
<div id="outline-container-orgcc3e8e5" class="outline-5">
<h5 id="orgcc3e8e5">Problem</h5>
<div class="outline-text-5" id="text-orgcc3e8e5">
<ol class="org-ol">
<li>It can estimate <span class="underline">multiple optimal decision boundaries</span> for a linear separable case.<br />
We can avoid this problem by selecting the boundary that is maximally distant from the two classes.<br /></li>

<li>The system might be <b>non-separable</b> (we might not be able to find a linear boundary between two classes).<br />
In this case, we can introduce a <span class="underline">misclassification error</span>, which allows for wrong classification labels to happen.<br /></li>
</ol>
</div>
</div>

<div id="outline-container-org219bd6e" class="outline-5">
<h5 id="org219bd6e">Rule extraction and Variable selection</h5>
<div class="outline-text-5" id="text-org219bd6e">
<p>
To extract variables and rules from SVMs, we can use the same approaches seen for Neural Networks:<br />
</p>
<ul class="org-ul">
<li>for <span class="underline">variable selection</span> , the <a href="#org4e52c4e">backward variable selection</a> procedure can be used to reduce the input variables.<br /></li>
<li>for <span class="underline">rule extraction</span> , the SVM can be interpreted as a neural network and the <a href="#org8429ad9">same methods</a> can be applied.<br /></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org7b1981e" class="outline-4">
<h4 id="org7b1981e">Ensemble methods</h4>
<div class="outline-text-4" id="text-org7b1981e">
<p>
Ensembe methods aim at estimating <b>multiple analytical models</b> instead of only one; The models created can then be used to cover different parts of the data input.<br />
</p>
</div>

<div id="outline-container-org7cf8775" class="outline-5">
<h5 id="org7cf8775">Bagging</h5>
<div class="outline-text-5" id="text-org7cf8775">
<p>
The Baggin method is an ensemble method. It consists of two steps:<br />
</p>
<ol class="org-ol">
<li>Take N samples from your dataset.<br /></li>
<li>Build a model (also called <span class="underline">classifier</span> ) for each of these samples.<br /></li>
</ol>

<p>
A <span class="underline">classification</span> model is then built by letting the classifiers &ldquo;vote&rdquo; on the label to give.<br />
A <span class="underline">regression</span> model is built by averaging the outcome of the N models.<br />
</p>
</div>
</div>

<div id="outline-container-org4d1b083" class="outline-5">
<h5 id="org4d1b083">Boosting</h5>
<div class="outline-text-5" id="text-org4d1b083">
<p>
The Boosting method is an ensemble method. It estimates multiple models using a <span class="underline">weighted data sample</span>.<br />
</p>

<p>
The weights applied on the data change according to the classification errors made by the models, to allow difficult observations to get more attention.<br />
But this calls for a <b>drawback</b>: the models might become overfitted on the difficult observations.<br />
</p>

<p>
The final model used is a combination of all the individual models.<br />
</p>
</div>
</div>

<div id="outline-container-orgbd5ef72" class="outline-5">
<h5 id="orgbd5ef72">Random Forest&#xa0;&#xa0;&#xa0;<span class="tag"><span class="missing_informations">missing_informations</span></span></h5>
<div class="outline-text-5" id="text-orgbd5ef72">
<p>
We create a &ldquo;forest&rdquo; of decision trees, with random splitting decision variables for each tree.<br />
</p>

<p>
It&rsquo;s not clear how the final model is built from the set of decision trees.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orgfd499bf" class="outline-4">
<h4 id="orgfd499bf">Evaluating a fraud detection model</h4>
<div class="outline-text-4" id="text-orgfd499bf">
<p>
Two key decisions determine the effectiveness of the predictive models shown above:<br />
</p>
<ul class="org-ul">
<li>how to split the data set<br /></li>
<li>how we choose our performance metrics.<br /></li>
</ul>
</div>

<div id="outline-container-org8f16125" class="outline-5">
<h5 id="org8f16125">Splitting the data set</h5>
<div class="outline-text-5" id="text-org8f16125">
<p>
The training data set and the test dataset must be completely separated.<br />
The decision on how we split the set <b>depends on the size</b> of the dataset itself.<br />
</p>

<p>
When present, the validation sample (seen for <a href="#org5f80c15">decision trees</a> and <a href="#org023a6dc">neural networks</a>) should be separated, too, but the requirement is less strict.<br />
</p>

<p>
Sometimes, having the <span class="underline">same percentage of fraudsters</span> in each set can be useful; Such split-up is called a <b>stratified split-up</b>.<br />
</p>
</div>

<div id="outline-container-org04e20b5" class="outline-6">
<h6 id="org04e20b5">Small data sets</h6>
<div class="outline-text-6" id="text-org04e20b5">
<p>
When the data set is not big enough, two methods can be adopted to make the split:<br />
</p>
<ul class="org-ul">
<li><b>Cross-validation</b>:<br />
The data is split in K groups, then the model is trained on K-1 groups and tested on the remaining group.<br />
The process is then repeated for every possible validation group, resulting in K <span class="underline">performance estimates</span> (<i>aren&rsquo;t they also different models?</i>).<br /></li>
<li><b>Leave-one-out cross validation</b>:<br />
Every observation is left out in turn and a model is made from the remaining ones.<br /></li>
</ul>

<p>
The selection of the model can then be performed in different ways:<br />
</p>
<ul class="org-ul">
<li>randomly (common for leave-one-out cross validation, since every model changes by only an observation)<br /></li>
<li>a final model on all observation is built (taking into consideration the performances coming out of the cross validation process)<br /></li>
<li>an ensemble model is built with a voting procedure (similarly to what we have seen for <a href="#org7cf8775">bagging ensemble models</a>)<br /></li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgbc3870f" class="outline-5">
<h5 id="orgbc3870f">Performance metrics</h5>
<div class="outline-text-5" id="text-orgbc3870f">
<p>
The main performance metrics used to evaluate our analytical model are:<br />
</p>
<ul class="org-ul">
<li><b>classification accuracy</b> : \(\frac{\text{true positive } + \text{ true negative}}{\text{true positive }+\text{ false positive }+\text{ false negative }+\text{ true negative}}\), or the percentage of correctly classified observations.<br /></li>
<li><b>classification error</b> : \(\frac{\text{false positive } + \text{ false negative}}{\text{true positive }+\text{ false positive }+\text{ false negative }+\text{ true negative}}\), or the percentage of wrongly classified observations.<br /></li>
<li><b>sensitivity</b> (also called recall or hit rate) : \(\frac{\text{true positive}}{\text{true positive }+\text{ false negative}}\), or the percentage of fraudsters correctly labeled.<br /></li>
<li><b>specificity</b> : \(\frac{\text{true negative}}{\text{false positive }+\text{ true negative}}\), or the percentage of non-fraudsters correctly labeled.<br /></li>
<li><b>precision</b> : \(\frac{\text{true positive}}{\text{false positive }+\text{ true positive}}\), or the percentage of labeled fraudsters that are actually fraudsters.<br /></li>
</ul>
</div>
</div>


<div id="outline-container-orgccf91c6" class="outline-5">
<h5 id="orgccf91c6">Managing skewed datasets</h5>
<div class="outline-text-5" id="text-orgccf91c6">
<p>
With a skewed<sup><a id="fnr.2.100" class="footref" href="#fn.2">2</a></sup> dataset it might become difficult to make a valid model due to the missing observations labeled as frauds.<br />
Two transformations can be made to the dataset to make it less skewed:<br />
</p>
<ul class="org-ul">
<li><b>Oversampling</b> : replicate frauds to make the distribution less skewed.<br /></li>
<li><b>Undersampling</b> : remove some observations that aren&rsquo;t frauds.<br /></li>
</ul>

<p>
The two can also be combined, but usually undersampling yelds better results (since we don&rsquo;t put in the set forged observations).<br />
</p>

<p>
In general, it&rsquo;s suggested to <b>stay as close as possible to the original distribution</b> to avoid unnecessary bias.<br />
</p>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-orgf8d74bb" class="outline-2">
<h2 id="orgf8d74bb">Mobile Forensics&#xa0;&#xa0;&#xa0;<span class="tag"><span class="guest_lecture">guest_lecture</span></span></h2>
<div class="outline-text-2" id="text-orgf8d74bb">
<p>
Mobile devices use has increased between people and, in turn, mobile forensics investigation has gained importance.<br />
</p>

<p>
Mobile forensics is a branch of digital forensics, related to the recovery of digital evidence from a mobile device under <b>forensically sound conditions</b>.<br />
</p>
</div>

<div id="outline-container-org8135907" class="outline-3">
<h3 id="org8135907">Forensical soundness</h3>
<div class="outline-text-3" id="text-org8135907">
<p>
Forensically sound is a term used to justify the use of particular forensic technology or methodology.<br />
</p>

<p>
It doesn&rsquo;t have a specific definition (&ldquo;<i>it depends</i>&rdquo;), but we can say that a method is forensically sound when it <span class="underline">doesn&rsquo;t alter or destroy the evidence</span> and has been shown to be <span class="underline">consistently reliable</span>.<br />
</p>

<p>
For example, in computer forensics we use various ways to avoid altering the data on the system:<br />
On computers you are typically able to remove the hard drive, and if this option is not available you usually have a way to boot a live distribution to mount the hard drive on a read-only way (from a phisical perspective, we are able to have a 100% forensically sound approach).<br />
</p>

<p>
On mobile devices, this is extremely difficult to do, mostly because we are <span class="underline">limited in the use of our phone</span> (unless we are root, which is usually not the case) and because most elements (like memory) is soldered.<br />
Moreover, the memory in the phone is most of the time encrypted on some key stored on the motherboard or another chipset (see iOS devices and their enclave).<br />
</p>

<p>
When the acquisition of data is not possible without changing the configuration of the device (even booting the phone might change some things), the <span class="underline">procedure must be documented</span> and the <span class="underline">changes must be tested beforehand</span>.<br />
</p>
</div>

<div id="outline-container-org709cc0c" class="outline-4">
<h4 id="org709cc0c">Low Level Exploits</h4>
<div class="outline-text-4" id="text-org709cc0c">
<p>
In some phones, it&rsquo;s possible to obtain the best acquisition (full, unaltered) with <b>low level exploits</b>, which allow us to <span class="underline">obtain root privileges before the phone boots</span>; Such acquisitions are the nearest to forensically sound in mobile forensics.<br />
It&rsquo;s more common on Android devices.<br />
</p>
</div>
</div>

<div id="outline-container-org8ea43cb" class="outline-4">
<h4 id="org8ea43cb">Documentation is key</h4>
<div class="outline-text-4" id="text-org8ea43cb">
<p>
The key to forensic soundness is <b>documentation</b>. The acquisition process should change the original evidence as little as possible and any changes should be documented and assessed.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orgd3e9ed7" class="outline-3">
<h3 id="orgd3e9ed7">Challenges of mobile forensics</h3>
<div class="outline-text-3" id="text-orgd3e9ed7">
<p>
In the mobile world we have a <b>big market fragmentation</b>, with new devices added daily.<br />
</p>

<p>
Each and every device uses some kind of chipset (qualcomm, exynos, kirin etc.), and most exploits are available at the chipset level (sometimes also on software level, but rarely), which means we have to <b>undestand exactly the carachteristics of the device</b> in front of us.<br />
</p>

<p>
Digital forensic analysts must also <b>overcome difficult security measures</b> (e.g: limited tries pin codes) brought up by the phone manufacturers, sometimes without the help of the incrimined person (s/he might be dead or unwilling to help).<br />
</p>

<p>
Moreover, the <b>data of interest</b> for forensic analysts has <b>expanded to multiple applications</b> (where previously it was mostly sms and, sometimes, images).<br />
The <b>amount of memory</b> to analyze in a smartphone has increased a lot (up to 500 gigs as of now) which implies the need for new analysis methodologies (e.g: AI recognition).<br />
</p>

<p>
Finally, for some apps the data is stored not only on the phone but on the <b>cloud</b>, too, and to analyze those data you need access to the cloud account of the person, which:<br />
</p>
<ol class="org-ol">
<li>is difficult to do<br /></li>
<li>you must first get permission to do it<br /></li>
</ol>
</div>
</div>

<div id="outline-container-org7f0a7bf" class="outline-3">
<h3 id="org7f0a7bf">Operating system diversity</h3>
<div class="outline-text-3" id="text-org7f0a7bf">
<p>
In mobile, the most used OSes nowadays are <span class="underline">Android</span> and <span class="underline">iOS</span>, with the only additional (still being developed) OS being <span class="underline">KaiOS</span>.<br />
In Italy we use mostly Android, while in America iOS is dominant.<br />
As you can understand, most of the commercial companies are US based.<br />
</p>
</div>

<div id="outline-container-org6f55508" class="outline-4">
<h4 id="org6f55508">Android versions diversity</h4>
<div class="outline-text-4" id="text-org6f55508">
<p>
Android has multiple versions still being used by a wide audience, with the security patches providing an additional layer of diversification.<br />
</p>

<p>
When it comes to software level exploits, having knowledge of the version and which security patch is applied on the phone is the key point to choose your extraction methodology.<br />
</p>
</div>
</div>

<div id="outline-container-orgd3ae339" class="outline-4">
<h4 id="orgd3ae339">iOS versions diversity</h4>
<div class="outline-text-4" id="text-orgd3ae339">
<p>
Since iOS forces the updates on the phones, there&rsquo;s not the same diversity that you can find in the android market share.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org09410d8" class="outline-3">
<h3 id="org09410d8">Guidelines to follow</h3>
<div class="outline-text-3" id="text-org09410d8">
<p>
There are various guidelines documented online to follow.<br />
The one we will analyze is <a href="https://drive.google.com/file/d/1sVko_Uo7o6iootWwn9IoLJ3mrMVXqTDg/view">one from SWGDE</a>.<br />
</p>

<p>
It&rsquo;s organized in sections:<br />
</p>
</div>

<div id="outline-container-orgdd28150" class="outline-4">
<h4 id="orgdd28150">Evidence collection and preservation</h4>
<div class="outline-text-4" id="text-orgdd28150">
<p>
Tipically done by law enforcement.<br />
</p>
</div>

<div id="outline-container-orge0507c1" class="outline-5">
<h5 id="orge0507c1">Preparation</h5>
<div class="outline-text-5" id="text-orge0507c1">
<p>
You need to have the proper tools to do and document the steps you will take, and you need to have proper legal authority to collect the evidence<br />
</p>
</div>
</div>

<div id="outline-container-org67798ee" class="outline-5">
<h5 id="org67798ee">Documentation</h5>
<div class="outline-text-5" id="text-org67798ee">
<p>
Take notes of the collection location and the device state and characteristics at the time of collection.<br />
You have different things to identify and take as evidence, such as cables, phone boxes etc.<br />
</p>
</div>
</div>

<div id="outline-container-org40572f1" class="outline-5">
<h5 id="org40572f1">What to do first</h5>
<div class="outline-text-5" id="text-org40572f1">
<p>
Based on the state of the phone and its type, you have two options for the <b>preservation process</b> (what to do to preserve the integrity of the evidence and to work in a <span class="underline">forensically sound</span> way):<br />
</p>
<ul class="org-ul">
<li>If on:<br />
<ul class="org-ul">
<li>Keep it on. Making it turn off will almost certainly encrypt the phone<br /></li>
<li>If the phone is on and the passcode was not inserted since boot, the phone won&rsquo;t have unencrypted its data and won&rsquo;t have used its ram (true mostly for iOS).<br /></li>
<li>If we can access the settings, engage airplane mode, disable wifi, disable bluetooth and extend the display auto-lock.<br /></li>
<li>If the system cannot be accessed, put it in a faraday bag to <span class="underline">avoid outside connections</span> from happening.<br /></li>
</ul></li>
<li>If off:<br />
<ul class="org-ul">
<li>Don&rsquo;t turn it on<br /></li>
<li>Remove the battery if possible<br /></li>
</ul></li>
<li>In both cases, collect the device identifiers.<br /></li>
</ul>
</div>
</div>

<div id="outline-container-org5da814a" class="outline-5">
<h5 id="org5da814a">Check periferals</h5>
<div class="outline-text-5" id="text-org5da814a">
<p>
Check for any paired or linked devices, which might lead to backups or additional informations.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orga49290a" class="outline-4">
<h4 id="orga49290a">Evidence Handling</h4>
<div class="outline-text-4" id="text-orga49290a">
<p>
The steps to extract the data from your device without loss of digital or physical data (e.g: fingerprints).<br />
</p>
</div>

<div id="outline-container-orga613415" class="outline-5">
<h5 id="orga613415">Access devices</h5>
<div class="outline-text-5" id="text-orga613415">
<p>
Frequently, phones can be unlocked if you have access to a safe place of the owner or another smart tool (a smartwatch) or the body of the person itself.<br />
Be careful: don&rsquo;t try to guess the password, which might call procedures of the phone to provide additional security measures (like formatting the data partition of the phone).<br />
</p>
</div>
</div>

<div id="outline-container-orgca7ea28" class="outline-5">
<h5 id="orgca7ea28">Devices powered on and unlocked</h5>
<div class="outline-text-5" id="text-orgca7ea28">
<p>
Document as much as possible the content of the phone (also by taking pictures) without locking it accidentally.<br />
</p>

<p>
If the phone is an organization&rsquo;s device, an MDM (mobile device management) system might be in place which would require to seek help from the system administrator of the organization to extract data.<br />
</p>
</div>
</div>

<div id="outline-container-org38aab61" class="outline-5">
<h5 id="org38aab61">Encryption</h5>
<div class="outline-text-5" id="text-org38aab61">
<p>
Most of the devices nowadays use some form of encryption.<br />
iOS devices (mostly, but not only) have backup passwords.<br />
There are ways to bypass and reset these kind of passwords but this modifies the content of the phone, and as such must be documented and extensively tested.<br />
</p>
</div>
</div>

<div id="outline-container-org5edd1dd" class="outline-5">
<h5 id="org5edd1dd">Network Isolation</h5>
<div class="outline-text-5" id="text-org5edd1dd">
<p>
Any kind of connection can be dangerous for the phone.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-orgbe88cbc" class="outline-4">
<h4 id="orgbe88cbc">Evidence acquisition</h4>
<div class="outline-text-4" id="text-orgbe88cbc">
</div>
<div id="outline-container-org74359f6" class="outline-5">
<h5 id="org74359f6">Preparation</h5>
<div class="outline-text-5" id="text-org74359f6">
<p>
Prepare all the software applications, cables etc. to perform the acquisition.<br />
</p>

<p>
There are various tools (and there is a <a href="https://www.nist.gov/itl/ssd/software-quality-group/computer-forensics-tool-testing-program-cftt/cftt-technical/mobile">website</a>) to test and review various type of forensics tools.<br />
The number of tool vendors available is limited nowadays, and there&rsquo;s no single tool perfect for all scopes: we have to <span class="underline">use different tools for different devices</span>, and sometimes manual investigation is mandatory.<br />
</p>

<p>
Sometimes, exploit are not available at the time of the analysis, but they might become available later on (for example, Epifani told us about a time when the exploit was made available during a trial and they were able to analyze the phone at that point).<br />
</p>
</div>

<div id="outline-container-org28b14b0" class="outline-6">
<h6 id="org28b14b0">Tools for law enforcement and acquisition services</h6>
<div class="outline-text-6" id="text-org28b14b0">
<p>
Some of these tools are only <b>meant for law enforcement</b>.<br />
Most of the times though, police analysts use unlocking and decryption mechanisms <b>provided as a service</b>, where you send the phone to a lab and they unlock it through zero-days exploit that are not yet available to the public (and not yet tested).<br />
</p>

<p>
This methods must be carefully reviewed by a court of law, since the methods used are not reliable.<br />
</p>
</div>
</div>
</div>

<div id="outline-container-org36aa2bf" class="outline-5">
<h5 id="org36aa2bf">Device identification</h5>
<div class="outline-text-5" id="text-org36aa2bf">
<p>
To identify a device, you can use:<br />
</p>
<ul class="org-ul">
<li>its <b>IMEI</b>, a number to univocally identify it worldwide<br /></li>
<li>the model number<br /></li>
<li>the serial number<br /></li>
</ul>

<p>
Sometimes, the IMEI is written on the back of the phone, sometimes it is written in the simcard tray, sometimes on the packaging box of the phone, but it should always be accessible (on an unlocked and functioning device) by dialing <code>*#06#</code>.<br />
</p>

<p>
Once the IMEI is identified, you need to search and understand what characteristics the phone has based on it. You can use <a href="https://imei.info">this website</a> to find informations about it.<br />
Most importantly, the chipset must be known to understand which tool/technique to use to extract data from the phone.<br />
</p>

<p>
Another option is to <span class="underline">check the coverage of the warranty</span> of the phone (mainly for apple devices) through the serial number. This way you can undestrand wether the phone was recently purchased and, based on the informations acquired, you can ask apple (as a public prosecutor) to provide you informations about that phone.<br />
</p>
</div>
</div>

<div id="outline-container-orge568fd1" class="outline-5">
<h5 id="orge568fd1">Extraction methods</h5>
<div class="outline-text-5" id="text-orge568fd1">
<p>
As a general rule, you can obtain different level of extraction based on the kind of devices and the patches applied.<br />
</p>
</div>

<div id="outline-container-org739e4d5" class="outline-6">
<h6 id="org739e4d5">Physical acquisition</h6>
<div class="outline-text-6" id="text-org739e4d5">
<p>
Our goal is generally to obtain a physical, non invasive acquisition, which means we would use an exploit to obtain an image of the entire phone without phisically handling the phone (except for the insertion of a cable).<br />
</p>

<p>
On most Samsung, encryption is done using full disk encryption (and not file based encryption). In this cases, we can change the boot loader (the part of the OS responsible of starting the OS) to and &ldquo;engineering bootloader&rdquo; to be able to access the trusted zone of the phone and obtain the encryption keys.<br />
</p>

<p>
These engeneering bootloader must be signed by Samsung and be valid for the phone.<br />
</p>
</div>
</div>

<div id="outline-container-org2e51c09" class="outline-6">
<h6 id="org2e51c09">Logical acquisition</h6>
<div class="outline-text-6" id="text-org2e51c09">
<p>
When a physical acquisition is not possible we rely on smaller acquisitions or, sometimes, simple logical acquisitions (which means that we only take what is available to us as non-root users).<br />
</p>

<p>
Whit a logical aquisition we can tipically obtain native applications data but not third parti applications data (whatsapp, facebook etc.)<br />
</p>
</div>
</div>

<div id="outline-container-org5059dd1" class="outline-6">
<h6 id="org5059dd1">Partial filesystem aquisition</h6>
<div class="outline-text-6" id="text-org5059dd1">
<p>
Since we are mostly interested on third party applications, sometimes we might try some (software) invasive method to get those data, for example to downgrade the application to have a viable exploit to make.<br />
Take note that <b>this method is invasive</b>, since you are changing the state of the phone to do it.<br />
</p>
</div>
</div>

<div id="outline-container-orgb3249b3" class="outline-6">
<h6 id="orgb3249b3">Invasive acquisition</h6>
<div class="outline-text-6" id="text-orgb3249b3">
<p>
You can remove the chip from the device and try to analyze it, but most of the times nowadays you will get encrypted data.<br />
This is still a <span class="underline">great option for IoT devices</span>.<br />
</p>

<p>
On some android devices you can also simply remove external memories (sd cards and sim cards), even though sim cards don&rsquo;t contain much infos except for carrier informations.<br />
</p>
</div>
</div>
</div>
</div>
</div>

<div id="outline-container-org9114a02" class="outline-3">
<h3 id="org9114a02">Tool analysis: Autopsy</h3>
<div class="outline-text-3" id="text-org9114a02">
<p>
Autopsy is an open source tool to analyze machines (calls itself the &ldquo;premium forensic platform&rdquo;).<br />
For mobile forensics, it will need an image to analyze.<br />
It is centralized (in the organization, not globally), so its users users can share content.<br />
</p>
</div>

<div id="outline-container-org8f8d80f" class="outline-4">
<h4 id="org8f8d80f">Android analysis on Autopsy</h4>
<div class="outline-text-4" id="text-org8f8d80f">
<p>
Once you unzip the android file, you get two files:<br />
</p>
<ul class="org-ul">
<li>a 30gb file containing the dump of the rom memory of the file. That&rsquo;s a full <span class="underline">filesystem</span> image, with the partitioning schema included.<br /></li>
<li>another 4mb file<br /></li>
</ul>

<p>
Let&rsquo;s analyze the image by, first, creating a <i>case</i> and adding our image to it. The type of source should be DiskImage (not LogicalFiles, since we have available a filesystem with partitions).<br />
</p>

<p>
Then you select the timezone (UTC, we guess) and the tools to run on the image.<br />
The tools we are going to use are:<br />
</p>
<ul class="org-ul">
<li>File Type identification<br /></li>
<li>Extension mismatch detector<br /></li>
<li>Embedded files extractor (allows to check if there is a file containing other files, like zip files, documents with images etc.)<br /></li>
<li>Picture analyzer (checks internal metadata for pictures)<br /></li>
<li>Android analyzer<br /></li>
</ul>

<p>
The tool will start adding the data source to your case.<br />
</p>
</div>

<div id="outline-container-orgc8c7172" class="outline-5">
<h5 id="orgc8c7172">Image extraction</h5>
<div class="outline-text-5" id="text-orgc8c7172">
<p>
The extraction of the image must usually be done with commercial tools, like UFED for PC (from Cellebrite).<br />
The same company makes a commercial analyzer (like autopsy, but a bit more advanced).<br />
</p>

<p>
Image extraction on a locked phone is based on an exploit, and as usual this is risky.<br />
That&rsquo;s why you should know what are the risks of each image extraction method (there are multiple, that can extract different kinds of informations)<br />
</p>
</div>
</div>

<div id="outline-container-org60e3c85" class="outline-5">
<h5 id="org60e3c85">Image Analysis</h5>
<div class="outline-text-5" id="text-org60e3c85">
<p>
After having loaded the image, you can look at its contents through Autopsy.<br />
You can see, by looking at the data sources, the huge number of partitions in an android device.<br />
The most important ones are:<br />
</p>
<ul class="org-ul">
<li>The <b>system partition</b>, where the stock OS resides.<br />
<ul class="org-ul">
<li>The app folder in the system partition contains pre-installed apps, in particular the apk files to run them.<br /></li>
<li>This partition should not contain user data (unless the phone is rooted)<br /></li>
<li>The <code>build.prop</code> file in the root of the file system contains the the properties of this build of android (like versions).<br /></li>
</ul></li>
<li>The userdata partition.<br />
<ul class="org-ul">
<li>Contains user data, settings, applications installed via the play store etc<br /></li>
<li>You have an app folder here too, containing the apk files of the  applications installed by the user.<br /></li>
<li>Under the data folder, we have a folder for each package (com.whatsapp, for example) and this folder is the only one to which the application can write data to.<br />
The data organization in this folder is highly dependant on the application.<br /></li>
</ul></li>
<li>The misc folder.<br />
<ul class="org-ul">
<li>Contains mainly network configurations, which can tell us more on the locations the target visited.<br /></li>
</ul></li>
</ul>

<p>
The results of the analysis are in the &ldquo;Extracted Content&rdquo; submenu.<br />
We can see:<br />
</p>
<ul class="org-ul">
<li>Call logs, organized as databases, with cellular calls, facebook calls etc.<br />
To extract its contents we need to understand how its data is organized.<br /></li>
<li>Messages, organized in databases too, with SMS, whatsapp messages etc.<br />
These might not be all the messages saved on the phone! These are just the ones the tool was able to extract.<br /></li>
<li>Pictures, which can also be cached pictures.<br /></li>
<li>The list of installed applications<br /></li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-org528091d" class="outline-3">
<h3 id="org528091d">Android analysis with Physical analyzer (commercial tool)</h3>
<div class="outline-text-3" id="text-org528091d">
<p>
Built for mobile only.<br />
</p>

<p>
The unpacking of the image is done through layers: you start with the filesystem layer, then go to the volume layer, then to the file layer<br />
</p>

<p>
The difference with Autopsy is the number of applications data layouts recognized.<br />
For example, if we go to look at the call logs, they are many more than the ones we found in Autopsy, because it was able to fetch calls from more applications.<br />
You can also see the file where the information was extracted from, and the specific point of extraction.<br />
</p>

<p>
When you see a red number next to an entry you know that number of items where deleted by the user and recovered by the tool.<br />
</p>

<p>
Through the timeline, you can see every item with the timestamp of the last access/creation, with a graph showing the usage of the phone based on them.<br />
</p>

<p>
Moreover, you can also see the account tokens used in the phone (potentially having access to the account).<br />
</p>
</div>

<div id="outline-container-org9d4ab62" class="outline-4">
<h4 id="org9d4ab62">How to have a forensically resilient phone&#xa0;&#xa0;&#xa0;<span class="tag"><span class="in_class_question">in_class_question</span></span></h4>
<div class="outline-text-4" id="text-org9d4ab62">
<p>
To have a forensically resilient phone, the producer must limit the costumers on their use and set restrictions on the things they can do with the phone.<br />
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org129779e" class="outline-2">
<h2 id="org129779e">Malware Analysis&#xa0;&#xa0;&#xa0;<span class="tag"><span class="missing_informations">missing_informations</span>&#xa0;<span class="guest_lecture">guest_lecture</span></span></h2>
<div class="outline-text-2" id="text-org129779e">
<p>
There are two kinds of analysis (we will use both in the demo):<br />
</p>
<ul class="org-ul">
<li>static:<br />
The code is not executed; Avoids malicious behaviors, but might be slow.<br /></li>
<li>dynamic:<br />
Usually made through a debugger: You run the program and check its runtime behavior.<br />
<span class="underline">Can</span> be much faster than static analysis (but the malware might recognize it&rsquo;s being dynamically analyzed, or be dormiant)<br /></li>
</ul>

<p>
The <b>best strategy is doing both</b>.<br />
</p>

<p>
On windows, register entries are used by malwares to get persistency and stay hidden.<br />
</p>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
litigation can be translated in italian with &ldquo;fatto in esame&rdquo;.<br />
</p></div></div>

<div class="footdef"><sup><a id="fn.2" class="footnum" href="#fnr.2">2</a></sup> <div class="footpara"><p class="footpara">
Skewness, in this context, can be read as <b>asymmetry</b><br />
</p></div></div>

<div class="footdef"><sup><a id="fn.3" class="footnum" href="#fnr.3">3</a></sup> <div class="footpara"><p class="footpara">
Basket market can be translated with &ldquo;vendita al dettaglio&rdquo; in Italian.<br />
</p></div></div>

<div class="footdef"><sup><a id="fn.4" class="footnum" href="#fnr.4">4</a></sup> <div class="footpara"><p class="footpara">
If you have followed the course &ldquo;Foundations of Operation Research&rdquo;, you are already familiar with this concept.<br />
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: Tancredi Covioli</p>
<p class="date">Created: 2021-06-10 gio 19:40</p>
</div>
</body>
</html>
